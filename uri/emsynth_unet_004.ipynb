{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from torchvision.models import vgg16_bn\n",
    "import PIL\n",
    "import imageio\n",
    "from superres import *\n",
    "from scipy.ndimage.interpolation import zoom as npzoom\n",
    "from skimage.util import img_as_float32, img_as_ubyte\n",
    "from skimage.measure import compare_ssim, compare_psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = Path('/scratch/bpho/datasets/emsynth_003/')\n",
    "model_path = Path('/scratch/bpho/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_src():\n",
    "    hr_tifs = img_data/f'hr'\n",
    "    lr_tifs = img_data/f'lr_up'\n",
    "\n",
    "    def map_to_hr(x):\n",
    "        hr_name = x.relative_to(lr_tifs)\n",
    "        return hr_tifs/hr_name\n",
    "    print(lr_tifs)\n",
    "    src = (ImageImageList\n",
    "            .from_folder(lr_tifs)\n",
    "            .split_by_rand_pct()\n",
    "            .label_from_func(map_to_hr))\n",
    "    return src\n",
    "\n",
    "\n",
    "def get_data(bs, size, noise=None, max_zoom=1.1):\n",
    "    src = get_src()\n",
    "    tfms = get_transforms(flip_vert=True, max_zoom=max_zoom)\n",
    "    data = (src\n",
    "            .transform(tfms, size=size)\n",
    "            .transform_y(tfms, size=size)\n",
    "            .databunch(bs=bs).normalize(imagenet_stats, do_y=True))\n",
    "    data.c = 3\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    n,c,h,w = x.size()\n",
    "    x = x.view(n, c, -1)\n",
    "    return (x @ x.transpose(1,2))/(c*h*w)\n",
    "\n",
    "vgg_m = vgg16_bn(True).features.cuda().eval()\n",
    "requires_grad(vgg_m, False)\n",
    "blocks = [i-1 for i,o in enumerate(children(vgg_m)) if isinstance(o,nn.MaxPool2d)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_loss = F.l1_loss\n",
    "\n",
    "class FeatureLoss(nn.Module):\n",
    "    def __init__(self, m_feat, layer_ids, layer_wgts):\n",
    "        super().__init__()\n",
    "        self.m_feat = m_feat\n",
    "        self.loss_features = [self.m_feat[i] for i in layer_ids]\n",
    "        self.hooks = hook_outputs(self.loss_features, detach=False)\n",
    "        self.wgts = layer_wgts\n",
    "        self.metric_names = ['pixel',] + [f'feat_{i}' for i in range(len(layer_ids))\n",
    "              ] + [f'gram_{i}' for i in range(len(layer_ids))]\n",
    "\n",
    "    def make_features(self, x, clone=False):\n",
    "        self.m_feat(x)\n",
    "        return [(o.clone() if clone else o) for o in self.hooks.stored]\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        out_feat = self.make_features(target, clone=True)\n",
    "        in_feat = self.make_features(input)\n",
    "        self.feat_losses = [base_loss(input,target)]\n",
    "        self.feat_losses += [base_loss(f_in, f_out)*w\n",
    "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
    "        self.feat_losses += [base_loss(gram_matrix(f_in), gram_matrix(f_out))*w**2 * 5e3\n",
    "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
    "        self.metrics = dict(zip(self.metric_names, self.feat_losses))\n",
    "        return sum(self.feat_losses)\n",
    "    \n",
    "    def __del__(self): self.hooks.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_loss = FeatureLoss(vgg_m, blocks[2:5], [5,15,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/bpho/datasets/emsynth_003/lr_up\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ImageDataBunch;\n",
       "\n",
       "Train: LabelList (79998 items)\n",
       "x: ImageImageList\n",
       "Image (3, 128, 128),Image (3, 128, 128),Image (3, 128, 128),Image (3, 128, 128),Image (3, 128, 128)\n",
       "y: ImageList\n",
       "Image (3, 128, 128),Image (3, 128, 128),Image (3, 128, 128),Image (3, 128, 128),Image (3, 128, 128)\n",
       "Path: /scratch/bpho/datasets/emsynth_003/lr_up;\n",
       "\n",
       "Valid: LabelList (19999 items)\n",
       "x: ImageImageList\n",
       "Image (3, 128, 128),Image (3, 128, 128),Image (3, 128, 128),Image (3, 128, 128),Image (3, 128, 128)\n",
       "y: ImageList\n",
       "Image (3, 128, 128),Image (3, 128, 128),Image (3, 128, 128),Image (3, 128, 128),Image (3, 128, 128)\n",
       "Path: /scratch/bpho/datasets/emsynth_003/lr_up;\n",
       "\n",
       "Test: None"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 64\n",
    "size = 128\n",
    "data = get_data(bs, size, max_zoom=6)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(3, ds_type=DatasetType.Valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arch = models.resnet34\n",
    "wd = 1e-3\n",
    "learn = unet_learner(data, arch, wd=wd, loss_func=feat_loss, metrics=superres_metrics, \n",
    "                     callback_fns=LossMetrics, blur=True, norm_type=NormType.Weight, model_dir=model_path)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_fit(save_name, lrs=slice(lr), pct_start=0.9, cycle_len=10):\n",
    "    learn.fit_one_cycle(cycle_len, lrs, pct_start=pct_start)\n",
    "    learn.save(save_name)\n",
    "    num_rows = min(learn.data.batch_size, 3)\n",
    "    learn.show_results(rows=num_rows, imgsize=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='3', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      33.33% [1/3 46:39<1:33:19]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mse_loss</th>\n",
       "      <th>ssim</th>\n",
       "      <th>psnr</th>\n",
       "      <th>pixel</th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>gram_0</th>\n",
       "      <th>gram_1</th>\n",
       "      <th>gram_2</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.514454</td>\n",
       "      <td>1.370362</td>\n",
       "      <td>0.037342</td>\n",
       "      <td>0.672077</td>\n",
       "      <td>14.279596</td>\n",
       "      <td>0.151167</td>\n",
       "      <td>0.186773</td>\n",
       "      <td>0.213862</td>\n",
       "      <td>0.052719</td>\n",
       "      <td>0.249625</td>\n",
       "      <td>0.470949</td>\n",
       "      <td>0.045266</td>\n",
       "      <td>46:39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='152' class='' max='1249', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      12.17% [152/1249 04:26<32:02 1.5079]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "do_fit('emsynth_003_unet.0', lr, cycle_len=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit('emsynth_003_unet.1', slice(1e-5,lr), cycle_len=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 32\n",
    "size = 256\n",
    "data = get_data(bs, size)\n",
    "\n",
    "arch = models.resnet34\n",
    "wd = 1e-3\n",
    "learn = unet_learner(data, arch, wd=wd, loss_func=feat_loss, metrics=superres_metrics, \n",
    "                     callback_fns=LossMetrics, blur=True, norm_type=NormType.Weight, model_dir=model_path)\n",
    "gc.collect()\n",
    "\n",
    "learn = learn.load('emsynth_003_unet.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_fit('emsynth_003_unet.2', lr, cycle_len=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_fit('emsynth_003_unet.3', slice(1e-5,lr), cycle_len=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 4\n",
    "size = 512\n",
    "data = get_data(bs, size)\n",
    "\n",
    "arch = models.resnet34\n",
    "wd = 1e-3\n",
    "learn = unet_learner(data, arch, wd=wd, loss_func=feat_loss, metrics=superres_metrics, \n",
    "                     callback_fns=LossMetrics, blur=True, norm_type=NormType.Weight, model_dir=model_path)\n",
    "gc.collect()\n",
    "\n",
    "learn = learn.load('emsynth_003_unet.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_fit('emsynth_003_unet.4', lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "do_fit('emsynth_003_unet.5', slice(1e-5,lr), cycle_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 2\n",
    "size = 1024\n",
    "data = get_data(bs, size)\n",
    "\n",
    "arch = models.resnet34\n",
    "wd = 1e-3\n",
    "learn = unet_learner(data, arch, wd=wd, loss_func=feat_loss, metrics=superres_metrics, \n",
    "                     callback_fns=LossMetrics, blur=True, norm_type=NormType.Weight, model_dir=model_path)\n",
    "gc.collect()\n",
    "\n",
    "learn = learn.load('emsynth_003_unet5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit('emsynth_003_unet.6', lr/100000, cycle_len=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit('emsynth_003_unet.7', slice(1e-5,lr), cycle_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1\n",
    "size = 1024\n",
    "data = get_data(bs, size)\n",
    "\n",
    "arch = models.resnet34\n",
    "wd = 1e-3\n",
    "learn = unet_learner(data, arch, wd=wd, loss_func=feat_loss, metrics=superres_metrics, \n",
    "                     callback_fns=LossMetrics, blur=True, norm_type=NormType.Weight, model_dir=model_path)\n",
    "gc.collect()\n",
    "\n",
    "learn = learn.load('emsynth_003_unet.6').to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "do_fit('emsynth_003_unet.8', slice(1e-6,1e-5), cycle_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit('emsynth_003_unet.9', slice(1e-6,1e-5), cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combo002_unet.0.pth\t     nuloss.3.pth\r\n",
      "combo002_unet.1.pth\t     nuloss.4.pth\r\n",
      "combo002_unet.2.pth\t     nuloss.5.pth\r\n",
      "combo002_unet.3.pth\t     nuloss.6.pth\r\n",
      "combo002_unet.4.pth\t     nuloss.7.pth\r\n",
      "combo002_unet.5.pth\t     nuloss_nopt.1.pth\r\n",
      "combo002_unet.6.pth\t     nuloss_nopt.2.pth\r\n",
      "combo002_unet.7.pth\t     paired_001_unet.0.pth\r\n",
      "emsynth_002_unet.0.pth\t     paired_001_unet.1.pth\r\n",
      "emsynth_002_unet.1.pth\t     paired_001_unet.2.pth\r\n",
      "emsynth_002_unet.2.pth\t     paired_001_unet.3.pth\r\n",
      "emsynth_002_unet.3.pth\t     paired_001_unet.4.pth\r\n",
      "emsynth_002_unet.4.pth\t     paired_001_unet.5.pth\r\n",
      "emsynth_002_unet.5.pth\t     paired_001_unet.6.pth\r\n",
      "emsynth_002_unet.8.pth\t     paired_001_unet.7.pth\r\n",
      "emsynth_002_unet.9.pth\t     paired_001_unet.8.pkl\r\n",
      "emsynth_003_unet.0.pth\t     paired_001_unet.8.pth\r\n",
      "emsynth_003_unet.1.pth\t     paired_001_unet_lr2hr.0.pth\r\n",
      "emsynth_003_unet.2.pth\t     paired_001_unet_lr2hr.1.pth\r\n",
      "emsynth_003_unet.3.pth\t     paired_001_unet_lr2hr.2.pth\r\n",
      "emsynth_003_unet.4.pth\t     paired_001_unet_lr2hr.3.pkl\r\n",
      "mitomovies_001_unet.0.pth    paired_001_unet_lr2hr.3.pth\r\n",
      "mitomovies_001_unet.1.pth    paired_001_unet_lr2hr.4.pth\r\n",
      "mitomovies_001_unet.2.pth    paired_001_unet_lr2hr.5.pth\r\n",
      "mitomovies_001_unet.3.pth    paired_001_unet_lr2hr.6.pkl\r\n",
      "mitomovies_001_unet.4.pth    paired_001_unet_lr2hr.6.pth\r\n",
      "mitomovies_001_unet.5.pth    paired_001_unet_lr2hr.7.pth\r\n",
      "movies_001.0.pth\t     raw2proc_001_unet.0.pth\r\n",
      "movies_001.1.pth\t     raw2proc_001_unet.1.pth\r\n",
      "movies_002_unet.0.pth\t     raw2proc_001_unet.2.pth\r\n",
      "movies_002_unet.1.pth\t     raw2proc_001_unet.3.pth\r\n",
      "movies_002_unet.2.pth\t     raw2proc_001_unet.4.pkl\r\n",
      "movies_002_unet.3.pth\t     raw2proc_001_unet.4.pth\r\n",
      "movies_002_unet.4.pth\t     raw2proc_001_unet.5.pth\r\n",
      "movies_002_unet.5.pth\t     raw2proc_001_unet.6.pkl\r\n",
      "movies_002_unet-noise.0.pth  raw2proc_001_unet.6.pth\r\n",
      "movies_002_unet-noise.1.pth  synth002_unet.0.pth\r\n",
      "movies_002_unet-noise.2.pth  synth002_unet.1.pth\r\n",
      "movies_002_unet-noise.3.pth  synth002_unet.2.pth\r\n",
      "movies_002_unet-noise.4.pth  synth002_unet.3.pth\r\n",
      "movies_002_unet-noise.5.pth  synth002_unet.4.pth\r\n",
      "movies_rddb_001.0.pth\t     synth002_unet.5.pth\r\n",
      "movies_rddb_001.1.pth\t     synth002_unet.6.pth\r\n",
      "nuloss.0.pth\t\t     synth002_unet.7.pth\r\n",
      "nuloss.1.pth\t\t     tmp.pth\r\n",
      "nuloss.2.pth\r\n"
     ]
    }
   ],
   "source": [
    "!ls /scratch/bpho/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/bpho/datasets/emsynth_003/lr_up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fredmonroe/anaconda3/lib/python3.7/site-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type FeatureLoss. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "bs = 1\n",
    "size = 1920\n",
    "data = get_data(bs, size)\n",
    "\n",
    "arch = models.resnet34\n",
    "wd = 1e-3\n",
    "learn = unet_learner(data, arch, wd=wd, loss_func=feat_loss, metrics=superres_metrics, \n",
    "                     callback_fns=LossMetrics, blur=True, norm_type=NormType.Weight, model_dir=model_path)\n",
    "gc.collect()\n",
    "\n",
    "learn = learn.load('emsynth_003_unet.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = Path('/scratch/bpho/datasources/EM_manually_aquired_pairs_01242019/')\n",
    "test_hr = list((test_files/'aligned_hr').glob('*.tif'))\n",
    "test_lr = list((test_files/'aligned_lr').glob('*.tif'))\n",
    "results = Path('/scratch/bpho/results/emsynth_crap')\n",
    "\n",
    "if results.exists(): shutil.rmtree(results)\n",
    "results.mkdir(parents=True, mode=0o775, exist_ok=True)\n",
    "\n",
    "def get_key(fn):\n",
    "    return fn.stem[0:(fn.stem.find('Region')-1)]\n",
    "\n",
    "hr_map = { get_key(fn): fn for fn in test_hr }\n",
    "lr_map = { get_key(fn): fn for fn in test_lr }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='85' class='' max='85', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [85/85 02:03<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fredmonroe/anaconda3/lib/python3.7/site-packages/skimage/util/dtype.py:141: UserWarning: Possible precision loss when converting from float32 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    }
   ],
   "source": [
    "ssims = []\n",
    "psnrs = []\n",
    "for k in progress_bar(hr_map):\n",
    "    hr_fn, lr_fn = hr_map[k], lr_map[k]\n",
    "    hr_img = PIL.Image.open(hr_fn)\n",
    "    lr_img = PIL.Image.open(lr_fn)\n",
    "    lr_img_data = img_as_float32(lr_img)\n",
    "    lr_up_data = npzoom(lr_img_data, 4, order=1)\n",
    "    lr_up_img = Image(tensor(lr_up_data[None]))\n",
    "    hr_pred_img, aaa, bbb = learn.predict(lr_up_img)\n",
    "    pred_img = PIL.Image.fromarray(img_as_ubyte(np.array(hr_pred_img.data))[0,:,:])\n",
    "    \n",
    "    lr_img.save(results/f'{k}_orig.tif')\n",
    "    hr_img.save(results/f'{k}_truth.tif')\n",
    "    pred_img.save(results/f'{k}_pred.tif')\n",
    "    hr_img_data = np.array(hr_img)\n",
    "    \n",
    "    ssims.append(compare_ssim(img_as_float32(np.array(hr_img)), img_as_float32(np.array(pred_img))))\n",
    "    psnrs.append(compare_psnr(img_as_float32(np.array(hr_img)), img_as_float32(np.array(pred_img))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7273812282498017, 20.06313527537938)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(ssims).mean(), np.array(psnrs).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='85' class='' max='85', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [85/85 02:52<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.7273812282498016, 20.063135275379384, 'vs', 0.7308102850426267)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import skimage.io as io\n",
    "\n",
    "#target_path = Path('/DATA/Dropbox/bpho_movie_results/emsynth_003/')\n",
    "target_path = results\n",
    "\n",
    "orig,tru,pred = [list(target_path.glob(f'*{tag}*')) for tag in ['orig','tru','pred']]\n",
    "orig.sort()\n",
    "tru.sort()\n",
    "pred.sort()\n",
    "\n",
    "\n",
    "ssims = []\n",
    "c_ssims = []\n",
    "l_ssims = []\n",
    "psnrs = []\n",
    "c_psnrs = []\n",
    "l_psnrs = []\n",
    "\n",
    "for o, t,p in progress_bar(list(zip(orig, tru,pred))):\n",
    "    oimg, timg, pimg = [img_as_float32(io.imread(fn)) for fn in [o,t,p]]\n",
    "    if len(pimg.shape) == 3: pimg = pimg[:,:,0]\n",
    "    cimg = npzoom(oimg, 4)\n",
    "    limg = npzoom(oimg, 4, order=1)\n",
    "    \n",
    "    ssims.append(compare_ssim(timg, pimg))\n",
    "    c_ssims.append(compare_ssim(timg, cimg))\n",
    "    l_ssims.append(compare_ssim(timg, limg))\n",
    "    psnrs.append(compare_psnr(timg, pimg))\n",
    "    c_psnrs.append(compare_psnr(timg, cimg))\n",
    "    l_psnrs.append(compare_psnr(timg, limg))\n",
    "np.array(ssims).mean(), np.array(psnrs).mean(), \"vs\", np.array(l_ssims).mean(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(dict(ssim=ssims, psnr=psnrs, \n",
    "                        bicubic_ssim=c_ssims, bicubic_psnr=c_psnrs,\n",
    "                        bilinear_ssim=l_ssims, bilinear_psnr=l_psnrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ssim</th>\n",
       "      <th>psnr</th>\n",
       "      <th>bicubic_ssim</th>\n",
       "      <th>bicubic_psnr</th>\n",
       "      <th>bilinear_ssim</th>\n",
       "      <th>bilinear_psnr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.727381</td>\n",
       "      <td>20.063135</td>\n",
       "      <td>0.692300</td>\n",
       "      <td>19.892473</td>\n",
       "      <td>0.730810</td>\n",
       "      <td>20.155426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.030599</td>\n",
       "      <td>3.424989</td>\n",
       "      <td>0.036899</td>\n",
       "      <td>3.397313</td>\n",
       "      <td>0.036152</td>\n",
       "      <td>3.544903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.660067</td>\n",
       "      <td>13.204294</td>\n",
       "      <td>0.620273</td>\n",
       "      <td>14.207584</td>\n",
       "      <td>0.658729</td>\n",
       "      <td>14.275473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.704023</td>\n",
       "      <td>16.723397</td>\n",
       "      <td>0.662589</td>\n",
       "      <td>16.520311</td>\n",
       "      <td>0.702204</td>\n",
       "      <td>16.623836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.736428</td>\n",
       "      <td>19.753729</td>\n",
       "      <td>0.705555</td>\n",
       "      <td>19.531696</td>\n",
       "      <td>0.744095</td>\n",
       "      <td>19.738787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.753708</td>\n",
       "      <td>23.332377</td>\n",
       "      <td>0.724061</td>\n",
       "      <td>23.139879</td>\n",
       "      <td>0.761960</td>\n",
       "      <td>23.557128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.774032</td>\n",
       "      <td>24.473792</td>\n",
       "      <td>0.746718</td>\n",
       "      <td>24.248150</td>\n",
       "      <td>0.785502</td>\n",
       "      <td>24.759367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ssim       psnr  bicubic_ssim  bicubic_psnr  bilinear_ssim  \\\n",
       "count  85.000000  85.000000     85.000000     85.000000      85.000000   \n",
       "mean    0.727381  20.063135      0.692300     19.892473       0.730810   \n",
       "std     0.030599   3.424989      0.036899      3.397313       0.036152   \n",
       "min     0.660067  13.204294      0.620273     14.207584       0.658729   \n",
       "25%     0.704023  16.723397      0.662589     16.520311       0.702204   \n",
       "50%     0.736428  19.753729      0.705555     19.531696       0.744095   \n",
       "75%     0.753708  23.332377      0.724061     23.139879       0.761960   \n",
       "max     0.774032  24.473792      0.746718     24.248150       0.785502   \n",
       "\n",
       "       bilinear_psnr  \n",
       "count      85.000000  \n",
       "mean       20.155426  \n",
       "std         3.544903  \n",
       "min        14.275473  \n",
       "25%        16.623836  \n",
       "50%        19.738787  \n",
       "75%        23.557128  \n",
       "max        24.759367  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
