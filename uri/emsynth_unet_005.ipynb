{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from torchvision.models import vgg16_bn\n",
    "import PIL\n",
    "import imageio\n",
    "from superres import *\n",
    "from scipy.ndimage.interpolation import zoom as npzoom\n",
    "from skimage.util import img_as_float32, img_as_ubyte\n",
    "from skimage.measure import compare_ssim, compare_psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)\n",
    "nb_name='emsynth_005_unet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = Path('/scratch/bpho/datasets/emsynth_003/')\n",
    "model_path = Path('/scratch/bpho/models')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/bpho/models/emsynth_005_unet.0.pth\r\n",
      "/scratch/bpho/models/emsynth_005_unet.1.pth\r\n",
      "/scratch/bpho/models/emsynth_005_unet.3a.pth\r\n",
      "/scratch/bpho/models/emsynth_005_unet.3.pth\r\n"
     ]
    }
   ],
   "source": [
    "!ls {model_path}/{nb_name}*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_src():\n",
    "    hr_tifs = img_data/f'hr'\n",
    "    lr_tifs = img_data/f'lr_up'\n",
    "\n",
    "    def map_to_hr(x):\n",
    "        hr_name = x.relative_to(lr_tifs)\n",
    "        return hr_tifs/hr_name\n",
    "    print(lr_tifs)\n",
    "    src = (ImageImageList\n",
    "            .from_folder(lr_tifs)\n",
    "            .split_by_rand_pct()\n",
    "            .label_from_func(map_to_hr))\n",
    "    return src\n",
    "\n",
    "\n",
    "def get_data(bs, size, noise=None, max_zoom=1.1):\n",
    "    src = get_src()\n",
    "    tfms = get_transforms(flip_vert=True, max_zoom=max_zoom)\n",
    "    data = (src\n",
    "            .transform(tfms, size=size)\n",
    "            .transform_y(tfms, size=size)\n",
    "            .databunch(bs=bs).normalize(imagenet_stats, do_y=True))\n",
    "    data.c = 3\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    n,c,h,w = x.size()\n",
    "    x = x.view(n, c, -1)\n",
    "    return (x @ x.transpose(1,2))/(c*h*w)\n",
    "\n",
    "vgg_m = vgg16_bn(True).features.cuda().eval()\n",
    "requires_grad(vgg_m, False)\n",
    "blocks = [i-1 for i,o in enumerate(children(vgg_m)) if isinstance(o,nn.MaxPool2d)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_loss = F.l1_loss\n",
    "\n",
    "class FeatureLoss(nn.Module):\n",
    "    def __init__(self, m_feat, layer_ids, layer_wgts):\n",
    "        super().__init__()\n",
    "        self.m_feat = m_feat\n",
    "        self.loss_features = [self.m_feat[i] for i in layer_ids]\n",
    "        self.hooks = hook_outputs(self.loss_features, detach=False)\n",
    "        self.wgts = layer_wgts\n",
    "        self.metric_names = ['pixel',] + [f'feat_{i}' for i in range(len(layer_ids))\n",
    "              ] + [f'gram_{i}' for i in range(len(layer_ids))]\n",
    "\n",
    "    def make_features(self, x, clone=False):\n",
    "        self.m_feat(x)\n",
    "        return [(o.clone() if clone else o) for o in self.hooks.stored]\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        out_feat = self.make_features(target, clone=True)\n",
    "        in_feat = self.make_features(input)\n",
    "        self.feat_losses = [base_loss(input,target)]\n",
    "        self.feat_losses += [base_loss(f_in, f_out)*w\n",
    "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
    "        self.feat_losses += [base_loss(gram_matrix(f_in), gram_matrix(f_out))*w**2 * 5e3\n",
    "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
    "        self.metrics = dict(zip(self.metric_names, self.feat_losses))\n",
    "        return sum(self.feat_losses)\n",
    "    \n",
    "    def __del__(self): self.hooks.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_loss = FeatureLoss(vgg_m, blocks[2:5], [5,15,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bs = 64\n",
    "size = 128\n",
    "data = get_data(bs, size, max_zoom=6)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(3, ds_type=DatasetType.Valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = models.resnet34\n",
    "wd = 1e-3\n",
    "learn = unet_learner(data, arch, wd=wd, \n",
    "                     #loss_func=feat_loss,\n",
    "                     loss_func=F.mse_loss,\n",
    "                     metrics=superres_metrics, \n",
    "                     #callback_fns=LossMetrics, \n",
    "                     blur=True, norm_type=NormType.Weight, model_dir=model_path)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_fit(save_name, lrs=slice(lr), pct_start=0.9, cycle_len=10):\n",
    "    learn.fit_one_cycle(cycle_len, lrs, pct_start=pct_start)\n",
    "    learn.save(save_name)\n",
    "    num_rows = min(learn.data.batch_size, 3)\n",
    "    learn.show_results(rows=num_rows, imgsize=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit(f'{nb_name}.0', lr, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit(f'{nb_name}.1', slice(1e-5,lr), cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 16\n",
    "size = 256\n",
    "data = get_data(bs, size, max_zoom=3)\n",
    "\n",
    "arch = models.resnet34\n",
    "wd = 1e-3\n",
    "learn = unet_learner(data, arch, wd=wd, \n",
    "                     #loss_func=feat_loss,\n",
    "                     loss_func=F.mse_loss,\n",
    "                     metrics=superres_metrics, \n",
    "                     #callback_fns=LossMetrics, \n",
    "                     blur=True, norm_type=NormType.Weight, model_dir=model_path)\n",
    "gc.collect()\n",
    "\n",
    "learn = learn.load(f'{nb_name}.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_fit('emsynth_003_unet.2', lr, cycle_len=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_fit(f'{nb_name}.3a', slice(1e-5,lr), cycle_len=3)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('cool ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/bpho/datasets/emsynth_003/lr_up\n"
     ]
    }
   ],
   "source": [
    "bs = 8 \n",
    "size = 512\n",
    "data = get_data(bs, size, max_zoom=2.)\n",
    "\n",
    "arch = models.resnet34\n",
    "wd = 1e-3\n",
    "learn = unet_learner(data, arch, wd=wd, \n",
    "                     #loss_func=feat_loss,\n",
    "                     loss_func=F.mse_loss,\n",
    "                     metrics=superres_metrics, \n",
    "                     #callback_fns=LossMetrics, \n",
    "                     blur=True, norm_type=NormType.Weight, model_dir=model_path)\n",
    "gc.collect()\n",
    "\n",
    "learn = learn.load(f'{nb_name}.3a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_fit('{nb_name}.4', lr, cycle_len=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='3', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/3 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mse_loss</th>\n",
       "      <th>ssim</th>\n",
       "      <th>psnr</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='2383' class='' max='9999', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      23.83% [2383/9999 23:03<1:13:40 0.0530]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "do_fit(f'{nb_name}.5', slice(1e-5,lr/10), cycle_len=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 2\n",
    "size = 1024\n",
    "data = get_data(bs, size, max_zoom=1.5)\n",
    "\n",
    "arch = models.resnet34\n",
    "wd = 1e-3\n",
    "learn = unet_learner(data, arch, wd=wd, loss_func=feat_loss, metrics=superres_metrics, \n",
    "                     callback_fns=LossMetrics, blur=True, norm_type=NormType.Weight, model_dir=model_path)\n",
    "gc.collect()\n",
    "\n",
    "learn = learn.load(f'{nb_name}.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit(f'{nb_name}.6', lr/100000, cycle_len=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit(f'{nb_name}.7', slice(1e-5,lr), cycle_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1\n",
    "size = 1024\n",
    "data = get_data(bs, size)\n",
    "\n",
    "arch = models.resnet34\n",
    "wd = 1e-3\n",
    "learn = unet_learner(data, arch, wd=wd, loss_func=feat_loss, metrics=superres_metrics, \n",
    "                     callback_fns=LossMetrics, blur=True, norm_type=NormType.Weight, model_dir=model_path)\n",
    "gc.collect()\n",
    "\n",
    "learn = learn.load(f'{nb_name}.6').to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "do_fit(f'{nb_name}.8', slice(1e-6,1e-5), cycle_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit(f'{nb_name}.9', slice(1e-6,1e-5), cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /scratch/bpho/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1\n",
    "size = 1920\n",
    "data = get_data(bs, size)\n",
    "\n",
    "arch = models.resnet34\n",
    "wd = 1e-3\n",
    "learn = unet_learner(data, arch, wd=wd, loss_func=feat_loss, metrics=superres_metrics, \n",
    "                     callback_fns=LossMetrics, blur=True, norm_type=NormType.Weight, model_dir=model_path)\n",
    "gc.collect()\n",
    "\n",
    "learn = learn.load(f'{nb_name}.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = Path('/scratch/bpho/datasources/EM_manually_aquired_pairs_01242019/')\n",
    "test_hr = list((test_files/'aligned_hr').glob('*.tif'))\n",
    "test_lr = list((test_files/'aligned_lr').glob('*.tif'))\n",
    "results = Path('/scratch/bpho/results/emsynth_crap')\n",
    "\n",
    "if results.exists(): shutil.rmtree(results)\n",
    "results.mkdir(parents=True, mode=0o775, exist_ok=True)\n",
    "\n",
    "def get_key(fn):\n",
    "    return fn.stem[0:(fn.stem.find('Region')-1)]\n",
    "\n",
    "hr_map = { get_key(fn): fn for fn in test_hr }\n",
    "lr_map = { get_key(fn): fn for fn in test_lr }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssims = []\n",
    "psnrs = []\n",
    "for k in progress_bar(hr_map):\n",
    "    hr_fn, lr_fn = hr_map[k], lr_map[k]\n",
    "    hr_img = PIL.Image.open(hr_fn)\n",
    "    lr_img = PIL.Image.open(lr_fn)\n",
    "    lr_img_data = img_as_float32(lr_img)\n",
    "    lr_up_data = npzoom(lr_img_data, 4, order=1)\n",
    "    lr_up_img = Image(tensor(lr_up_data[None]))\n",
    "    hr_pred_img, aaa, bbb = learn.predict(lr_up_img)\n",
    "    pred_img = PIL.Image.fromarray(img_as_ubyte(np.array(hr_pred_img.data))[0,:,:])\n",
    "    \n",
    "    lr_img.save(results/f'{k}_orig.tif')\n",
    "    hr_img.save(results/f'{k}_truth.tif')\n",
    "    pred_img.save(results/f'{k}_pred.tif')\n",
    "    hr_img_data = np.array(hr_img)\n",
    "    \n",
    "    ssims.append(compare_ssim(img_as_float32(np.array(hr_img)), img_as_float32(np.array(pred_img))))\n",
    "    psnrs.append(compare_psnr(img_as_float32(np.array(hr_img)), img_as_float32(np.array(pred_img))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(ssims).mean(), np.array(psnrs).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "\n",
    "#target_path = Path('/DATA/Dropbox/bpho_movie_results/emsynth_003/')\n",
    "target_path = results\n",
    "\n",
    "orig,tru,pred = [list(target_path.glob(f'*{tag}*')) for tag in ['orig','tru','pred']]\n",
    "orig.sort()\n",
    "tru.sort()\n",
    "pred.sort()\n",
    "\n",
    "\n",
    "ssims = []\n",
    "c_ssims = []\n",
    "l_ssims = []\n",
    "psnrs = []\n",
    "c_psnrs = []\n",
    "l_psnrs = []\n",
    "\n",
    "for o, t,p in progress_bar(list(zip(orig, tru,pred))):\n",
    "    oimg, timg, pimg = [img_as_float32(io.imread(fn)) for fn in [o,t,p]]\n",
    "    if len(pimg.shape) == 3: pimg = pimg[:,:,0]\n",
    "    cimg = npzoom(oimg, 4)\n",
    "    limg = npzoom(oimg, 4, order=1)\n",
    "    \n",
    "    ssims.append(compare_ssim(timg, pimg))\n",
    "    c_ssims.append(compare_ssim(timg, cimg))\n",
    "    l_ssims.append(compare_ssim(timg, limg))\n",
    "    psnrs.append(compare_psnr(timg, pimg))\n",
    "    c_psnrs.append(compare_psnr(timg, cimg))\n",
    "    l_psnrs.append(compare_psnr(timg, limg))\n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(dict(ssim=ssims, psnr=psnrs, \n",
    "                        bicubic_ssim=c_ssims, bicubic_psnr=c_psnrs,\n",
    "                        bilinear_ssim=l_ssims, bilinear_psnr=l_psnrs))\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
