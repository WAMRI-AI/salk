{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from torchvision.models import vgg16_bn\n",
    "import PIL\n",
    "import imageio\n",
    "from superres import *\n",
    "import superres.rddb as rddb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data = Path('/scratch/bpho/datasets/movies_001/')\n",
    "model_path = Path('/scratch/bpho/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_src(scale_size):\n",
    "    cropped_hr = movie_data/f'roi_hr_{scale_size}'\n",
    "    cropped_lr = movie_data/f'roi_lr_small_{scale_size}'\n",
    "    def map_to_hr(x):\n",
    "        hr_name = x.relative_to(cropped_lr)\n",
    "        return cropped_hr/hr_name\n",
    "    src = (ImageImageList\n",
    "            .from_folder(cropped_lr)\n",
    "            .split_by_folder()\n",
    "            .label_from_func(map_to_hr))\n",
    "    return src\n",
    "\n",
    "\n",
    "def _gaussian_noise_gray(x, gauss_sigma=1.):\n",
    "    c,h,w = x.shape\n",
    "    noise = torch.zeros((1,h,w))\n",
    "    noise.normal_(0, gauss_sigma)\n",
    "    img_max = np.minimum(1.1 * x.max(), 1.)\n",
    "    x = np.minimum(np.maximum(0,x+noise.repeat((3,1,1))), img_max)\n",
    "    return x\n",
    "\n",
    "gaussian_noise_gray = TfmPixel(_gaussian_noise_gray)\n",
    "\n",
    "    \n",
    "\n",
    "def get_data(bs, size, scale, noise=0.05, tile_size=None):\n",
    "    scale_size = scale * size\n",
    "    if tile_size is None: tile_size = scale_size\n",
    "    src = get_src(tile_size)\n",
    "    tfms = get_transforms(flip_vert=True, max_zoom=0)\n",
    "    y_tfms = [[t for t in tfms[0]], [t for t in tfms[1]]]\n",
    "    tfms[0].append(gaussian_noise_gray(gauss_sigma=noise))\n",
    "    data = (src\n",
    "            .transform(tfms, size=size)\n",
    "            .transform_y(y_tfms, size=scale_size)\n",
    "            .databunch(bs=bs).normalize(imagenet_stats, do_y=True))\n",
    "    data.c = 3\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    n,c,h,w = x.size()\n",
    "    x = x.view(n, c, -1)\n",
    "    return (x @ x.transpose(1,2))/(c*h*w)\n",
    "\n",
    "vgg_m = vgg16_bn(True).features.cuda().eval()\n",
    "requires_grad(vgg_m, False)\n",
    "blocks = [i-1 for i,o in enumerate(children(vgg_m)) if isinstance(o,nn.MaxPool2d)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_loss = F.l1_loss\n",
    "\n",
    "class FeatureLoss(nn.Module):\n",
    "    def __init__(self, m_feat, layer_ids, layer_wgts):\n",
    "        super().__init__()\n",
    "        self.m_feat = m_feat\n",
    "        self.loss_features = [self.m_feat[i] for i in layer_ids]\n",
    "        self.hooks = hook_outputs(self.loss_features, detach=False)\n",
    "        self.wgts = layer_wgts\n",
    "        self.metric_names = ['pixel',] + [f'feat_{i}' for i in range(len(layer_ids))\n",
    "              ] + [f'gram_{i}' for i in range(len(layer_ids))]\n",
    "\n",
    "    def make_features(self, x, clone=False):\n",
    "        self.m_feat(x)\n",
    "        return [(o.clone() if clone else o) for o in self.hooks.stored]\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        out_feat = self.make_features(target, clone=True)\n",
    "        in_feat = self.make_features(input)\n",
    "        self.feat_losses = [base_loss(input,target)]\n",
    "        self.feat_losses += [base_loss(f_in, f_out)*w\n",
    "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
    "        self.feat_losses += [base_loss(gram_matrix(f_in), gram_matrix(f_out))*w**2 * 5e3\n",
    "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
    "        self.metrics = dict(zip(self.metric_names, self.feat_losses))\n",
    "        return sum(self.feat_losses)\n",
    "    \n",
    "    def __del__(self): self.hooks.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_loss = FeatureLoss(vgg_m, blocks[2:5], [5,15,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 8\n",
    "size = 128\n",
    "scale = 4\n",
    "data = get_data(bs, size, scale, noise=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feats = 64\n",
    "n_blocks = 20\n",
    "n_color = 3\n",
    "scale=4\n",
    "loss = feat_loss\n",
    "model = rddb.RRDB_Net(in_nc=n_color,out_nc=n_color,nf=n_feats,nb=n_blocks, upscale=scale)\n",
    "model = nn.DataParallel(model)\n",
    "learn = Learner(data, model, loss_func=loss, metrics=superres_metrics, \n",
    "                callback_fns=LossMetrics, model_dir=model_path)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_fit(learn, save_name, lrs=slice(lr), pct_start=0.9, cycle_len=10):\n",
    "    learn.to_fp16().fit_one_cycle(cycle_len, lrs, pct_start=pct_start)\n",
    "    learn.to_fp32()\n",
    "    learn.save(save_name)\n",
    "    learn.show_results(rows=3, imgsize=5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit(learn, 'movies_rddb_001.0', lr., cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load('movies_rddb_001.0')\n",
    "learn.show_results(rows=3, imgsize=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit(learn, 'movies_rddb_001.1', lr/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load('movies_rddb_001.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /scratch/bpho/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_files = list((movie_data/'test').glob('*.czi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = movie_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with czifile.CziFile(fn) as czi_f:\n",
    "    proc_axes, proc_shape = get_czi_shape_info(czi_f)\n",
    "    channels = proc_shape['C']\n",
    "    depths = proc_shape['Z']\n",
    "    times = proc_shape['T']\n",
    "    x,y = proc_shape['X'], proc_shape['Y']\n",
    "    data = czi_f.asarray()\n",
    "    preds = []\n",
    "    origs = []\n",
    "    idx = build_index(proc_axes, {'T': 0, 'C': 0, 'Z':0, 'X':slice(0,x),'Y':slice(0,y)})\n",
    "    img = data[idx].astype(np.float32)\n",
    "    img /= (img.max() * 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_from_tiles(learn, img, tile_sz=128, scale=4):\n",
    "    pimg = PIL.Image.fromarray((img*255).astype(np.uint8), mode='L').convert('RGB')\n",
    "    cur_size = pimg.size\n",
    "    new_size = (cur_size[0]*scale, cur_size[1]*scale)\n",
    "    in_img = Image(pil2tensor(pimg,np.float32).div_(255))\n",
    "    c, w, h = in_img.shape\n",
    "    \n",
    "    in_tile = torch.zeros((c,tile_sz,tile_sz))\n",
    "    out_img = torch.zeros((c,w*scale,h*scale))\n",
    "    \n",
    "    for x_tile in range(math.ceil(w/tile_sz)):\n",
    "        for y_tile in range(math.ceil(h/tile_sz)):\n",
    "            x_start = x_tile\n",
    "\n",
    "            x_start = x_tile*tile_sz\n",
    "            x_end = min(x_start+tile_sz, w)\n",
    "            y_start = y_tile*tile_sz\n",
    "            y_end = min(y_start+tile_sz, h)\n",
    "            \n",
    "            \n",
    "            in_tile[:,0:(x_end-x_start), 0:(y_end-y_start)] = in_img.data[:,x_start:x_end, y_start:y_end]\n",
    "            \n",
    "            out_tile,_,_ = learn.predict(Image(in_tile))\n",
    "\n",
    "            out_x_start = x_start*scale\n",
    "            out_x_end = x_end*scale\n",
    "            out_y_start = y_start*scale\n",
    "            out_y_end = y_end*scale\n",
    "\n",
    "            #print(\"out: \", out_x_start, out_y_start, \",\", out_x_end, out_y_end)\n",
    "            in_x_start = 0\n",
    "            in_y_start = 0\n",
    "            in_x_end = (x_end-x_start)*scale\n",
    "            in_y_end = (y_end-y_start)*scale\n",
    "            #print(\"tile: \",in_x_start, in_y_start, \",\", in_x_end, in_y_end)\n",
    "           \n",
    "            out_img[:,out_x_start:out_x_end, out_y_start:out_y_end] = out_tile.data[:,\n",
    "                                                                                  in_x_start:in_x_end, \n",
    "                                                                                  in_y_start:in_y_end]\n",
    "    return out_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def czi_predict_movie(learn, czi_in, orig_out='orig.tif', pred_out='pred.tif', size=128):\n",
    "    with czifile.CziFile(czi_in) as czi_f:\n",
    "        proc_axes, proc_shape = get_czi_shape_info(czi_f)\n",
    "        channels = proc_shape['C']\n",
    "        depths = proc_shape['Z']\n",
    "        times = proc_shape['T']\n",
    "        x,y = proc_shape['X'], proc_shape['Y']\n",
    "        data = czi_f.asarray()\n",
    "        preds = []\n",
    "        origs = []\n",
    "        img_max = None\n",
    "        for t in progress_bar(list(range(times))):\n",
    "            idx = build_index(proc_axes, {'T': t, 'C': 0, 'Z':0, 'X':slice(0,x),'Y':slice(0,y)})\n",
    "            img = data[idx].astype(np.float32)\n",
    "            if img_max is None: img_max = img.max() * 1.5\n",
    "            img /= img_max\n",
    "            out_img = image_from_tiles(learn, img, tile_sz=size).permute([1,2,0])\n",
    "            pred = (out_img[None]*255).cpu().numpy().astype(np.uint8)\n",
    "            preds.append(pred)\n",
    "            orig = (img[None]*255).astype(np.uint8)\n",
    "            origs.append(orig)\n",
    "\n",
    "        all_y = np.concatenate(preds)\n",
    "        #print(all_y.shape)\n",
    "        imageio.mimwrite(pred_out, all_y) #, fps=30, macro_block_size=None) # for mp4\n",
    "        all_y = np.concatenate(origs)\n",
    "        #print(all_y.shape)\n",
    "        imageio.mimwrite(orig_out, all_y) #, fps=30, macro_block_size=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1\n",
    "size = 256\n",
    "scale = 4\n",
    "\n",
    "data = get_data(bs, size, scale, noise=0.03, tile_size=128)\n",
    "\n",
    "n_feats = 64\n",
    "n_blocks = 20\n",
    "n_color = 3\n",
    "scale=4\n",
    "loss = feat_loss\n",
    "model = rddb.RRDB_Net(in_nc=n_color,out_nc=n_color,nf=n_feats,nb=n_blocks, upscale=scale)\n",
    "model = nn.DataParallel(model)\n",
    "learn = Learner(data, model, loss_func=loss, metrics=superres_metrics, \n",
    "                callback_fns=LossMetrics, model_dir=model_path)\n",
    "gc.collect()\n",
    "learn = learn.load('movies_rddb_001.1')\n",
    "\n",
    "# wd = 1e-3\n",
    "# learn = unet_learner(data, arch, wd=wd, loss_func=feat_loss, \n",
    "#                      callback_fns=LossMetrics, blur=True, norm_type=NormType.Weight, model_dir=model_path)\n",
    "# gc.collect()\n",
    "# learn = learn.load('movies_rddb_001.1')\n",
    "\n",
    "for fn in movie_files:\n",
    "    pred_name = f'{fn.stem}_pred.tif'\n",
    "    orig_name = f'{fn.stem}_orig.tif'\n",
    "    czi_predict_movie(learn, fn, size=size, orig_out=orig_name, pred_out=pred_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
