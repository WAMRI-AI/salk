{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.distributed import *\n",
    "from superres import superres_metrics, ssim, psnr\n",
    "from superres import RRDB_Net, MultiImageToMultiChannel, TwoXModel, TwoYLoss, MultiToMultiImageList, TransformableLists\n",
    "import czifile\n",
    "from superres.helpers import get_czi_shape_info, build_index\n",
    "import imageio\n",
    "import adabound\n",
    "\n",
    "datasetname = 'multiframe_002'\n",
    "data_path = Path('/scratch/bpho')\n",
    "datasets = data_path/'datasets'\n",
    "datasources = data_path/'datasources'\n",
    "dataset = datasets/datasetname\n",
    "\n",
    "hr_path = dataset/'hr'\n",
    "lr_path = dataset/'lr'\n",
    "lr_up_path = dataset/'lr_up'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numbers import Integral\n",
    "\n",
    "class MultiImage(ItemBase):\n",
    "    def __init__(self, img_list):\n",
    "        self.img_list = img_list\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'MultiImage: {[str(img) for img in self.img_list]}'\n",
    "\n",
    "    @property\n",
    "    def size(self):\n",
    "        return [img.size for img in self.img_list]\n",
    "    \n",
    "    @property\n",
    "    def data(self):\n",
    "        img_data = torch.stack([img.data for img in self.img_list])\n",
    "        num_img, c, h, w = img_data.shape\n",
    "        data = tensor(img_data.view(num_img*c, h, w))\n",
    "        return data\n",
    "\n",
    "    def apply_tfms(self, tfms, **kwargs):\n",
    "        first_time = True\n",
    "\n",
    "        save_img_list = []\n",
    "        for img in self.img_list:\n",
    "            new_img = img.apply_tfms(tfms, do_resolve=first_time, **kwargs)\n",
    "            first_time = False\n",
    "            save_img_list.append(new_img)\n",
    "        self.img_list = save_img_list\n",
    "        return self\n",
    "    \n",
    "    def _repr_png_(self): return self._repr_image_format('png')\n",
    "    def _repr_jpeg_(self): return self._repr_image_format('jpeg')\n",
    "\n",
    "    def _repr_image_format(self, format_str):\n",
    "        #return self.img_lists[0]._repr_image_format(format_str)\n",
    "        with BytesIO() as str_buffer:\n",
    "            img_data = np.concatenate([image2np(img.px) for img in self.img_list], axis=1)\n",
    "            plt.imsave(str_buffer, img_data, format=format_str)\n",
    "            return str_buffer.getvalue()\n",
    "\n",
    "    def show(self, **kwargs):\n",
    "        self.img_list[0].show(**kwargs)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "def multi_normalize(x:TensorImage, mean:FloatTensor,std:FloatTensor)->TensorImage:\n",
    "    \"Normalize `x` with `mean` and `std`.\"\n",
    "    return (x - mean) / std\n",
    "\n",
    "\n",
    "def multi_denormalize(x:TensorImage, mean:FloatTensor,std:FloatTensor, do_x:bool=True)->TensorImage:\n",
    "    \"Denormalize `x` with `mean` and `std`.\"\n",
    "    return x.cpu().float()*std + mean if do_x else x.cpu()\n",
    "\n",
    "def _multi_normalize_batch(b:Tuple[Tensor,Tensor], mean:FloatTensor, std:FloatTensor, do_x:bool=True, do_y:bool=False)->Tuple[Tensor,Tensor]:\n",
    "    \"`b` = `x`,`y` - normalize `x` array of imgs and `do_y` optionally `y`.\"\n",
    "    x,y = b\n",
    "    mean,std = mean.to(x.device),std.to(x.device)\n",
    "    if do_x: x = multi_normalize(x,mean,std)\n",
    "    if do_y and len(y.shape) == 4: y = multi_normalize(y,mean,std)\n",
    "    return x,y\n",
    "\n",
    "def multi_normalize_funcs(mean:FloatTensor, std:FloatTensor, do_x:bool=True, do_y:bool=False)->Tuple[Callable,Callable]:\n",
    "    \"Create normalize/denormalize func using `mean` and `std`, can specify `do_y` and `device`.\"\n",
    "    mean,std = tensor(mean),tensor(std)\n",
    "    return (partial(_multi_normalize_batch, mean=mean, std=std, do_x=do_x, do_y=do_y),\n",
    "            partial(multi_denormalize, mean=mean, std=std, do_x=do_x))\n",
    "        \n",
    "def multi_image_channel_view(x):\n",
    "    n_chan = 1\n",
    "    return x.transpose(0,1).contiguous().view(n_chan,-1)\n",
    "\n",
    "    \n",
    "\n",
    "class MultiImageDataBunch(ImageDataBunch):\n",
    "    def batch_stats(self, funcs:Collection[Callable]=None, ds_type:DatasetType=DatasetType.Train)->Tensor:\n",
    "        \"Grab a batch of data and call reduction function `func` per channel\"\n",
    "        funcs = ifnone(funcs, [torch.mean,torch.std])\n",
    "        x = self.one_batch(ds_type=ds_type, denorm=False)[0].cpu()\n",
    "        \n",
    "        return [func(multi_image_channel_view(x), 1) for func in funcs]\n",
    "\n",
    "    def normalize(self, stats:Collection[Tensor]=None, do_x:bool=True, do_y:bool=False)->None:\n",
    "        \"Add normalize transform using `stats` (defaults to `DataBunch.batch_stats`)\"\n",
    "        if getattr(self,'norm',False): raise Exception('Can not call normalize twice')\n",
    "        if stats is None: self.stats = self.batch_stats()\n",
    "        else:             self.stats = stats\n",
    "        self.norm,self.denorm = multi_normalize_funcs(*self.stats, do_x=do_x, do_y=do_y)\n",
    "        self.add_tfm(self.norm)\n",
    "        \n",
    "        return self\n",
    "\n",
    "\n",
    "\n",
    "class MultiImageList(ImageList):\n",
    "    \"`ItemList` suitable for computer vision.\"\n",
    "    _bunch,_square_show,_square_show_res = MultiImageDataBunch,True,True\n",
    "    def __init__(self, *args,  **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.channels = 1\n",
    "        \n",
    "    def open(self, fn):\n",
    "        img_data = np.load(fn)\n",
    "        \n",
    "        img_list = []\n",
    "        if len(img_data.shape) == 4:\n",
    "            for j in range(img_data.shape[0]):\n",
    "                for i in range(img_data.shape[1]):\n",
    "                    img_list.append(Image(tensor(img_data[j,i][None])))\n",
    "        else:\n",
    "            for i in range(img_data.shape[0]):\n",
    "                img_list.append(Image(tensor(img_data[i][None])))\n",
    "        \n",
    "        self.channels = img_list[0].data.shape[0]\n",
    "        return MultiImage(img_list)\n",
    "        \n",
    "    def reconstruct(self, t:Tensor):\n",
    "        #set_trace()\n",
    "        n, h, w = t.shape\n",
    "        n //= self.channels\n",
    "        one_img = t.view(self.channels,n*h,w)\n",
    "        return Image(one_img.float().clamp(min=0,max=1))\n",
    "\n",
    "class NpyRawImageList(ImageList):\n",
    "    def open(self, fn):\n",
    "        img_data = np.load(fn)\n",
    "        return Image(tensor(img_data[None]))\n",
    "\n",
    "    def analyze_pred(self, pred):\n",
    "        return pred[0:1]\n",
    "\n",
    "    def reconstruct(self, t):\n",
    "        return Image(t.float().clamp(min=0,max=1))                \n",
    "\n",
    "class MultiImageImageList(MultiImageList):\n",
    "    _label_cls,_square_show,_square_show_res = NpyRawImageList,False,False\n",
    "\n",
    "    def show_xys(self, xs, ys, imgsize:int=4, figsize:Optional[Tuple[int,int]]=None, **kwargs):\n",
    "        \"Show the `xs` (inputs) and `ys`(targets)  on a figure of `figsize`.\"\n",
    "        axs = subplots(len(xs), 2, imgsize=imgsize, figsize=figsize)\n",
    "        for i, (x,y) in enumerate(zip(xs,ys)):\n",
    "            x.show(ax=axs[i,0], **kwargs)\n",
    "            y.show(ax=axs[i,1], **kwargs)\n",
    "        plt.tight_layout()\n",
    "\n",
    "    def show_xyzs(self, xs, ys, zs, imgsize:int=4, figsize:Optional[Tuple[int,int]]=None, **kwargs):\n",
    "        \"Show `xs` (inputs), `ys` (targets) and `zs` (predictions) on a figure of `figsize`.\"\n",
    "        title = 'Input / Prediction / Target'\n",
    "        axs = subplots(len(xs), 3, imgsize=imgsize, figsize=figsize, title=title, weight='bold', size=14)\n",
    "        for i,(x,y,z) in enumerate(zip(xs,ys,zs)):\n",
    "            x.show(ax=axs[i,0], **kwargs)\n",
    "            y.show(ax=axs[i,2], **kwargs)\n",
    "            z.show(ax=axs[i,1], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_hr(x):\n",
    "    hr_name = x.relative_to(lr_path)\n",
    "    return hr_path/hr_name\n",
    "\n",
    "def get_src(size=128, scale=1):\n",
    "    if scale != 1: use_lr_path = lr_path\n",
    "    else: use_lr_path = lr_path\n",
    "        \n",
    "    def map_to_hr(x):\n",
    "        hr_name = x.relative_to(use_lr_path)\n",
    "        return hr_path/hr_name\n",
    "    \n",
    "    src = (MultiImageImageList\n",
    "            .from_folder(lr_path, extensions=['.npy'])\n",
    "            .split_by_folder()\n",
    "            .label_from_func(map_to_hr))\n",
    "    return src\n",
    "\n",
    "def get_data(bs, size, scale=1, max_zoom=1.):\n",
    "    src = get_src(size, scale=scale)    \n",
    "    tfms = get_transforms(flip_vert=True, max_zoom=max_zoom)\n",
    "    #tfms = [[],[]]\n",
    "    data = (src\n",
    "            .transform(tfms, size=size)\n",
    "            .transform_y(tfms, size=size*scale)\n",
    "            .databunch(bs=bs))#.normalize(do_y=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoXModel(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        num_img = x.shape[1] // 2\n",
    "        x1, x2 = x[:,0:num_img], x[:,num_img:]\n",
    "        y1 = self.model(x1)\n",
    "        y2 = self.model(x2)\n",
    "        return torch.cat((y1,y2),1)\n",
    "    \n",
    "    \n",
    "class TwoYLoss(nn.Module):\n",
    "    def __init__(self, base_loss=F.mse_loss, stable_wt=0.15):\n",
    "        super().__init__()\n",
    "        self.base_loss = base_loss\n",
    "        self.stable_wt = stable_wt\n",
    "        self.base_loss_wt = (1-stable_wt)/2\n",
    "        self.metric_names = ['pixel','stable','ssim','psnr']\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        base_loss = self.base_loss\n",
    "        y1 = input[:,0:1,:,:]\n",
    "        y2 = input[:,1:2,:,:]\n",
    "        base_1 = base_loss(y1, target)\n",
    "        base_2 = base_loss(y2, target)\n",
    "        stable_err = F.mse_loss(y1,y2)\n",
    "        loss = (base_1 * self.base_loss_wt +\n",
    "                base_2 * self.base_loss_wt +\n",
    "                stable_err * self.stable_wt)\n",
    "        self.metrics = {\n",
    "            'pixel': (base_1+base_2)/2,\n",
    "            'stable': stable_err,\n",
    "            'ssim': (ssim.ssim(y1, target)+ssim.ssim(y2,target))/2,\n",
    "            'psnr': (psnr(y1, target)+psnr(y2,target))/2\n",
    "        }\n",
    "        return loss\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 8\n",
    "size = 64\n",
    "data = get_data(bs, size, scale=4, max_zoom=1.2)\n",
    "\n",
    "in_c = 5\n",
    "out_c = 1\n",
    "nf = 16\n",
    "gcval = 16 # 32\n",
    "nb = 5 # 23\n",
    "\n",
    "#loss = TwoYLoss(F.mse_loss)\n",
    "loss = F.mse_loss\n",
    "\n",
    "#model = TwoXModel(RRDB_Net(in_c, out_c, nf, nb, gc=gcval))\n",
    "model = RRDB_Net(in_c, out_c, nf, nb, gc=gcval)\n",
    "model = nn.DataParallel(model)\n",
    "#opt_func = partial(adabound.AdaBound,  lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#learn = Learner(data, model, callback_fns=LossMetrics, loss_func=loss) #, opt_func=opt_func)\n",
    "learn = Learner(data, model, metrics=superres_metrics, loss_func=loss) #, opt_func=opt_func)\n",
    "\n",
    "learn = learn.to_fp16(loss_scale=64)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "_th_view is not implemented for type torch.HalfTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-949bbe2a2629>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/repos/fastai/fastai/basic_data.py\u001b[0m in \u001b[0;36mshow_batch\u001b[0;34m(self, rows, ds_type, reverse, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mn_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrows\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_square_show\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_items\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mn_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrab_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0;31m#TODO: get rid of has_arg if possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconstruct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/fastai/fastai/basic_data.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mn_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrows\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_square_show\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_items\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mn_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrab_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0;31m#TODO: get rid of has_arg if possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconstruct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-09fd8d78f232>\u001b[0m in \u001b[0;36mreconstruct\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m//=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mone_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: _th_view is not implemented for type torch.HalfTensor"
     ]
    }
   ],
   "source": [
    "learn.data.show_batch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if True:\n",
    "    learn.lr_find()\n",
    "    learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 05:44 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mse_loss</th>\n",
       "      <th>ssim</th>\n",
       "      <th>psnr</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>0.002780</td>\n",
       "      <td>0.002780</td>\n",
       "      <td>0.622081</td>\n",
       "      <td>25.804960</td>\n",
       "      <td>02:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.001830</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>0.657409</td>\n",
       "      <td>26.201838</td>\n",
       "      <td>01:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>0.001797</td>\n",
       "      <td>0.001797</td>\n",
       "      <td>0.719475</td>\n",
       "      <td>27.656281</td>\n",
       "      <td>01:49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(cyc_len=3, max_lr=5e-4)\n",
    "#learn.fit(4, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('multiimg.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 16\n",
    "size = 128\n",
    "data = get_data(bs, size, scale=4, max_zoom=1.2)\n",
    "learn = Learner(data, model, metrics=superres_metrics, loss_func=loss) #, opt_func=opt_func)\n",
    "learn = learn.load('multiimg.1').to_fp16(loss_scale=64)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 04:27 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mse_loss</th>\n",
       "      <th>ssim</th>\n",
       "      <th>psnr</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>0.421923</td>\n",
       "      <td>23.355743</td>\n",
       "      <td>01:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>0.671055</td>\n",
       "      <td>25.432692</td>\n",
       "      <td>01:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>0.002645</td>\n",
       "      <td>0.002645</td>\n",
       "      <td>0.621768</td>\n",
       "      <td>25.900215</td>\n",
       "      <td>01:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(cyc_len=3, max_lr=5e-4)\n",
    "learn.save('multiimg.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 16\n",
    "size = 256\n",
    "data = get_data(bs, size, scale=4, max_zoom=1.2)\n",
    "learn = Learner(data, model, metrics=superres_metrics, loss_func=loss) #, opt_func=opt_func)\n",
    "learn = learn.load('multiimg.2').to_fp16(loss_scale=64)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 13:19 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mse_loss</th>\n",
       "      <th>ssim</th>\n",
       "      <th>psnr</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.001833</td>\n",
       "      <td>0.002089</td>\n",
       "      <td>0.002089</td>\n",
       "      <td>0.557395</td>\n",
       "      <td>26.867685</td>\n",
       "      <td>04:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.002955</td>\n",
       "      <td>0.002955</td>\n",
       "      <td>0.677350</td>\n",
       "      <td>25.451344</td>\n",
       "      <td>04:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.001689</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.690127</td>\n",
       "      <td>25.585028</td>\n",
       "      <td>04:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(cyc_len=3, max_lr=5e-4)\n",
    "learn.save('multiimg.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 13:45 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mse_loss</th>\n",
       "      <th>ssim</th>\n",
       "      <th>psnr</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.001608</td>\n",
       "      <td>0.003160</td>\n",
       "      <td>0.003160</td>\n",
       "      <td>0.627223</td>\n",
       "      <td>25.169308</td>\n",
       "      <td>04:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>0.635291</td>\n",
       "      <td>25.965269</td>\n",
       "      <td>04:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.627847</td>\n",
       "      <td>25.933796</td>\n",
       "      <td>04:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(cyc_len=3, max_lr=1e-4)\n",
    "learn.save('multiimg.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 12\n",
    "size = 400\n",
    "data = get_data(bs, size, scale=4, max_zoom=1.2)\n",
    "learn = Learner(data, model, metrics=superres_metrics, loss_func=loss) #, opt_func=opt_func)\n",
    "learn = learn.load('multiimg.4').to_fp16(loss_scale=64)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 05:50 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mse_loss</th>\n",
       "      <th>ssim</th>\n",
       "      <th>psnr</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.564562</td>\n",
       "      <td>25.521790</td>\n",
       "      <td>02:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>0.002149</td>\n",
       "      <td>0.002149</td>\n",
       "      <td>0.630314</td>\n",
       "      <td>26.866238</td>\n",
       "      <td>01:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.650156</td>\n",
       "      <td>27.112223</td>\n",
       "      <td>01:43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(cyc_len=3, max_lr=1e-4)\n",
    "learn.save('multiimg.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='30' class='' max='50', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      60.00% [30/50 4:52:11<3:14:47]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mse_loss</th>\n",
       "      <th>ssim</th>\n",
       "      <th>psnr</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>0.002110</td>\n",
       "      <td>0.002110</td>\n",
       "      <td>0.692190</td>\n",
       "      <td>26.885107</td>\n",
       "      <td>09:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.002051</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.697314</td>\n",
       "      <td>26.947979</td>\n",
       "      <td>08:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>0.002051</td>\n",
       "      <td>0.002051</td>\n",
       "      <td>0.697099</td>\n",
       "      <td>27.003105</td>\n",
       "      <td>09:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.698040</td>\n",
       "      <td>27.071873</td>\n",
       "      <td>11:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.001956</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.693027</td>\n",
       "      <td>27.086325</td>\n",
       "      <td>13:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.690945</td>\n",
       "      <td>27.032358</td>\n",
       "      <td>11:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.002123</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>0.689338</td>\n",
       "      <td>26.816122</td>\n",
       "      <td>12:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.001956</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.684402</td>\n",
       "      <td>27.031591</td>\n",
       "      <td>11:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.687068</td>\n",
       "      <td>26.075083</td>\n",
       "      <td>10:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>0.676220</td>\n",
       "      <td>26.908092</td>\n",
       "      <td>09:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.659694</td>\n",
       "      <td>25.913647</td>\n",
       "      <td>09:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.002089</td>\n",
       "      <td>0.002120</td>\n",
       "      <td>0.002120</td>\n",
       "      <td>0.685540</td>\n",
       "      <td>26.866179</td>\n",
       "      <td>09:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>nan</td>\n",
       "      <td>-inf</td>\n",
       "      <td>09:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>09:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>09:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>09:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>09:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>09:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>09:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>09:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>09:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>09:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>09:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>09:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>08:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>08:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>08:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>08:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>08:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>08:55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='364', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with val_loss value: 0.002109932480379939.\n",
      "Better model found at epoch 1 with val_loss value: 0.002077897312119603.\n",
      "Better model found at epoch 2 with val_loss value: 0.0020514288917183876.\n",
      "Better model found at epoch 3 with val_loss value: 0.00201857415959239.\n",
      "Better model found at epoch 4 with val_loss value: 0.002010779455304146.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/fredmonroe/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a3c95f5738d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multiimg_best'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_fp16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multiimg.6'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/fastai/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     21\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/fastai/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/fastai/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/fastai/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_bwd\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn = Learner(data, model, \n",
    "                metrics=superres_metrics, \n",
    "                loss_func=loss,\n",
    "                callbacks=[SaveModelCallback(learn, name='multiimg_best')]\n",
    "               ) #, opt_func=opt_func)\n",
    "learn = learn.load('multiimg_best').to_fp16(loss_scale=64)\n",
    "\n",
    "learn.fit_one_cycle(cyc_len=50, max_lr=5e-6)\n",
    "learn.save('multiimg.6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.show_results(rows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 5, 64, 64]), torch.Size([8, 1, 256, 256]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = data.one_batch()\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 4\n",
    "size = 256\n",
    "data = get_data(bs, size, scale=4, max_zoom=1.2)\n",
    "in_c = 5\n",
    "out_c = 1\n",
    "nf = gcval = 16 # 32\n",
    "nb = 5 # 23\n",
    "\n",
    "model = TwoXModel(RRDB_Net(in_c, out_c, nf, nb, gc=gcval))\n",
    "model = RRDB_Net(in_c, out_c, nf, nb, gc=gcval)\n",
    "model = nn.DataParallel(model)\n",
    "learn = Learner(data, model, loss_func=loss) #, opt_func=opt_func)\n",
    "learn = learn.to_fp16()\n",
    "learn = learn.load('multiimg.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(2, max_lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('multiimg.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results(rows=3, imgsize=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_files = []\n",
    "#movie_files = list(Path('/scratch/bpho/datasets/movies_001/test').glob('*.czi'))\n",
    "#movie_files += list(Path('/scratch/bpho/datasources/low_res_test/').glob('low res confocal*.czi'))\n",
    "#movie_files += list(Path('/scratch/bpho/datasources/neuron_movies2/').glob('low*.*'))\n",
    "movie_files += list(Path('/DATA/Dropbox/bpho_DL_datasources/Live_Neuron_Data_redo_for_Gulcin_and_Fred/').glob('low res 300 time points 2*.czi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/DATA/Dropbox/bpho_DL_datasources/Live_Neuron_Data_redo_for_Gulcin_and_Fred/low res 300 time points 2.czi')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_from_tiles(learn, in_img, tile_sz=128, scale=4, wsize=3):\n",
    "    cur_size = in_img.shape[1:3]\n",
    "    c = in_img.shape[0]\n",
    "    new_size = (cur_size[0]*scale, cur_size[1]*scale)\n",
    "    w, h = cur_size\n",
    "    \n",
    "    in_tile = torch.zeros((c,tile_sz,tile_sz))\n",
    "    out_img = torch.zeros((1,w*scale,h*scale))\n",
    "    \n",
    "    for x_tile in range(math.ceil(w/tile_sz)):\n",
    "        for y_tile in range(math.ceil(h/tile_sz)):\n",
    "            x_start = x_tile\n",
    "\n",
    "            x_start = x_tile*tile_sz\n",
    "            x_end = min(x_start+tile_sz, w)\n",
    "            y_start = y_tile*tile_sz\n",
    "            y_end = min(y_start+tile_sz, h)\n",
    "            \n",
    "            \n",
    "            in_tile[:,0:(x_end-x_start), 0:(y_end-y_start)] = tensor(in_img[:,x_start:x_end, y_start:y_end])\n",
    "            \n",
    "            img_list = [Image(in_tile[i][None]) for i in range(wsize)]\n",
    "            #img_list += img_list\n",
    "            \n",
    "            tlist = MultiImage(img_list)\n",
    "            \n",
    "            out_tile,_,_ = learn.predict(tlist)\n",
    "            \n",
    "            out_x_start = x_start * scale\n",
    "            out_x_end = x_end * scale\n",
    "            out_y_start = y_start * scale\n",
    "            out_y_end = y_end * scale\n",
    "\n",
    "            #print(\"out: \", out_x_start, out_y_start, \",\", out_x_end, out_y_end)\n",
    "            in_x_start = 0\n",
    "            in_y_start = 0\n",
    "            in_x_end = (x_end-x_start) * scale\n",
    "            in_y_end = (y_end-y_start) * scale\n",
    "            #print(\"tile: \",in_x_start, in_y_start, \",\", in_x_end, in_y_end)\n",
    "           \n",
    "            out_img[:,out_x_start:out_x_end, out_y_start:out_y_end] = out_tile.data[:,\n",
    "                                                                                  in_x_start:in_x_end, \n",
    "                                                                                  in_y_start:in_y_end]\n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imsave\n",
    "\n",
    "def tif_predict_movie(learn, tif_in, orig_out='orig.tif', pred_out='pred.tif', size=128, wsize=3):\n",
    "    im = PIL.Image.open(tif_in)\n",
    "    im.load()\n",
    "    times = im.n_frames\n",
    "    #times = min(times,100)\n",
    "    imgs = []\n",
    "    for i in range(times):\n",
    "        im.seek(i)\n",
    "        imgs.append(np.array(im).astype(np.float32)/255.)\n",
    "    img_data = np.stack(imgs)\n",
    "    \n",
    "    def pull_frame(i):\n",
    "        im.seek(i)\n",
    "        im.load()\n",
    "        return np.array(im)\n",
    "    \n",
    "    folder = Path(pred_out).stem().mkdir()\n",
    "    \n",
    "    preds = []\n",
    "    origs = []\n",
    "    img_max = img_data.max()\n",
    "    print(img_max)\n",
    "    print('max: ', img_max)\n",
    "    for t in progress_bar(list(range(0,times-wsize+1))):\n",
    "        img = img_data[t:(t+wsize)].copy()\n",
    "        img /= img_max\n",
    "        \n",
    "        out_img = image_from_tiles(learn, img, tile_sz=size, wsize=wsize)\n",
    "        pred = (out_img*255).cpu().numpy().astype(np.uint8)\n",
    "        preds.append(pred)\n",
    "        orig = (img[1][None]*255).astype(np.uint8)\n",
    "        origs.append(orig)\n",
    "\n",
    "    all_y = np.concatenate(preds)\n",
    "    #print(all_y.shape)\n",
    "    imageio.mimwrite(pred_out, all_y, bigtiff=True) #, fps=30, macro_block_size=None) # for mp4\n",
    "    all_y = np.concatenate(origs)\n",
    "    #print(all_y.shape)\n",
    "    imageio.mimwrite(orig_out, all_y, bigtiff=True) #, fps=30, macro_block_size=None)\n",
    "\n",
    "\n",
    "def czi_predict_movie(learn, czi_in, orig_out='orig.tif', pred_out='pred.tif', size=128, wsize=3):\n",
    "    with czifile.CziFile(czi_in) as czi_f:\n",
    "        proc_axes, proc_shape = get_czi_shape_info(czi_f)\n",
    "        channels = proc_shape['C']\n",
    "        depths = proc_shape['Z']\n",
    "        times = proc_shape['T']\n",
    "        #times = min(times, 100)\n",
    "        x,y = proc_shape['X'], proc_shape['Y']\n",
    "        print(f'czi: x:{x} y:{y} t:{times} z:{depths}')\n",
    "        \n",
    "        #folder_name = Path(pred_out).stem\n",
    "        #folder = Path(folder_name)\n",
    "        #if folder.exists(): shutil.rmtree(folder)\n",
    "        #folder.mkdir()\n",
    "        \n",
    "        data = czi_f.asarray().astype(np.float32)/255.\n",
    "        preds = []\n",
    "        origs = []\n",
    "        \n",
    "        img_max = data.max()\n",
    "        print(img_max)\n",
    "        for t in progress_bar(list(range(0,times-wsize+1))):\n",
    "            idx = build_index(proc_axes, {'T': slice(t,t+wsize), 'C': 0, 'Z':0, 'X':slice(0,x),'Y':slice(0,y)})\n",
    "            img = data[idx].copy()\n",
    "            img /= img_max\n",
    "            \n",
    "            out_img = image_from_tiles(learn, img, tile_sz=size, wsize=wsize)\n",
    "            pred = (out_img*255).cpu().numpy().astype(np.uint8)\n",
    "            preds.append(pred)\n",
    "            #imsave(folder/f'{t}.tif', pred[0])\n",
    "            \n",
    "            orig = (img[1][None]*255).astype(np.uint8)\n",
    "            origs.append(orig)\n",
    "            \n",
    "        all_y = np.concatenate(preds)\n",
    "        #print(all_y.shape)\n",
    "        imageio.mimwrite(pred_out, all_y, bigtiff=True) #, fps=30, macro_block_size=None) # for mp4\n",
    "        all_y = np.concatenate(origs)\n",
    "        #print(all_y.shape)\n",
    "        imageio.mimwrite(orig_out, all_y, bigtiff=True) #, fps=30, macro_block_size=None)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 2\n",
    "size = 440\n",
    "data = get_data(bs, size, scale=4, max_zoom=1.2)\n",
    "in_c = 5\n",
    "out_c = 1\n",
    "nf = gcval = 16 # 32\n",
    "nb = 5 # 23\n",
    "\n",
    "#model = TwoXModel(RRDB_Net(in_c, out_c, nf, nb, gc=gcval))\n",
    "model = RRDB_Net(in_c, out_c, nf, nb, gc=gcval)\n",
    "loss = F.mse_loss\n",
    "\n",
    "model = nn.DataParallel(model)\n",
    "learn = Learner(data, model, callback_fns=LossMetrics, loss_func=loss) #, opt_func=opt_func)\n",
    "learn = learn.to_fp16()\n",
    "learn = learn.load('multiimg.5')\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 440, 440]) torch.Size([2, 1, 1760, 1760])\n"
     ]
    }
   ],
   "source": [
    "x,y = data.one_batch()\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:25<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "czi low res 300 time points 2\n",
      "czi: x:380 y:380 t:300 z:1\n",
      "0.29803923\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='296' class='' max='296', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [296/296 00:24<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fn in progress_bar(movie_files):\n",
    "    #try:\n",
    "        pred_name = f'{fn.stem}_pred.tif'\n",
    "        orig_name = f'{fn.stem}_orig.tif'\n",
    "        if not Path(pred_name).exists():\n",
    "            if fn.suffix == '.czi':\n",
    "                print(f'czi {fn.stem}')\n",
    "                czi_predict_movie(learn, fn, size=size, orig_out=orig_name, pred_out=pred_name, wsize=5)\n",
    "            elif fn.suffix == '.tif':\n",
    "                tif_predict_movie(learn, fn, size=size, orig_out=orig_name, pred_out=pred_name, wsize=5)\n",
    "                tif_fn = fn\n",
    "                print(f'tif {fn.stem}')\n",
    "        else:\n",
    "            print(f'skip: {fn.stem}')\n",
    "    #except:\n",
    "    #    print(f'err: {fn.stem}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
