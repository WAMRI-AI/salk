{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.distributed import *\n",
    "from superres import superres_metrics, ssim, psnr\n",
    "from superres import RRDB_Net, MultiImageToMultiChannel, TwoXModel, TwoYLoss, MultiToMultiImageList, TransformableLists\n",
    "import czifile\n",
    "from superres.helpers import get_czi_shape_info, build_index\n",
    "import imageio\n",
    "import adabound\n",
    "\n",
    "datasetname = 'multiframe_002'\n",
    "data_path = Path('/scratch/bpho')\n",
    "datasets = data_path/'datasets'\n",
    "datasources = data_path/'datasources'\n",
    "dataset = datasets/datasetname\n",
    "\n",
    "hr_path = dataset/'hr'\n",
    "lr_path = dataset/'lr'\n",
    "lr_up_path = dataset/'lr_up'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numbers import Integral\n",
    "\n",
    "class MultiImage(ItemBase):\n",
    "    def __init__(self, img_list):\n",
    "        self.img_list = img_list\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'MultiImage: {[str(img) for img in self.img_list]}'\n",
    "\n",
    "    @property\n",
    "    def size(self):\n",
    "        return [img.size for img in self.img_list]\n",
    "    \n",
    "    @property\n",
    "    def data(self):\n",
    "        img_data = torch.stack([img.data for img in self.img_list])\n",
    "        num_img, c, h, w = img_data.shape\n",
    "        data = tensor(img_data.view(num_img*c, h, w))\n",
    "        return data\n",
    "\n",
    "    def apply_tfms(self, tfms, **kwargs):\n",
    "        first_time = True\n",
    "\n",
    "        save_img_list = []\n",
    "        for img in self.img_list:\n",
    "            new_img = img.apply_tfms(tfms, do_resolve=first_time, **kwargs)\n",
    "            first_time = False\n",
    "            save_img_list.append(new_img)\n",
    "        self.img_list = save_img_list\n",
    "        return self\n",
    "    \n",
    "    def _repr_png_(self): return self._repr_image_format('png')\n",
    "    def _repr_jpeg_(self): return self._repr_image_format('jpeg')\n",
    "\n",
    "    def _repr_image_format(self, format_str):\n",
    "        #return self.img_lists[0]._repr_image_format(format_str)\n",
    "        with BytesIO() as str_buffer:\n",
    "            img_data = np.concatenate([image2np(img.px) for img in self.img_list], axis=1)\n",
    "            plt.imsave(str_buffer, img_data, format=format_str)\n",
    "            return str_buffer.getvalue()\n",
    "\n",
    "    def show(self, **kwargs):\n",
    "        self.img_list[0].show(**kwargs)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "def multi_normalize(x:TensorImage, mean:FloatTensor,std:FloatTensor)->TensorImage:\n",
    "    \"Normalize `x` with `mean` and `std`.\"\n",
    "    return (x - mean) / std\n",
    "\n",
    "\n",
    "def multi_denormalize(x:TensorImage, mean:FloatTensor,std:FloatTensor, do_x:bool=True)->TensorImage:\n",
    "    \"Denormalize `x` with `mean` and `std`.\"\n",
    "    return x.cpu().float()*std + mean if do_x else x.cpu()\n",
    "\n",
    "def _multi_normalize_batch(b:Tuple[Tensor,Tensor], mean:FloatTensor, std:FloatTensor, do_x:bool=True, do_y:bool=False)->Tuple[Tensor,Tensor]:\n",
    "    \"`b` = `x`,`y` - normalize `x` array of imgs and `do_y` optionally `y`.\"\n",
    "    x,y = b\n",
    "    mean,std = mean.to(x.device),std.to(x.device)\n",
    "    if do_x: x = multi_normalize(x,mean,std)\n",
    "    if do_y and len(y.shape) == 4: y = multi_normalize(y,mean,std)\n",
    "    return x,y\n",
    "\n",
    "def multi_normalize_funcs(mean:FloatTensor, std:FloatTensor, do_x:bool=True, do_y:bool=False)->Tuple[Callable,Callable]:\n",
    "    \"Create normalize/denormalize func using `mean` and `std`, can specify `do_y` and `device`.\"\n",
    "    mean,std = tensor(mean),tensor(std)\n",
    "    return (partial(_multi_normalize_batch, mean=mean, std=std, do_x=do_x, do_y=do_y),\n",
    "            partial(multi_denormalize, mean=mean, std=std, do_x=do_x))\n",
    "        \n",
    "def multi_image_channel_view(x):\n",
    "    n_chan = 1\n",
    "    return x.transpose(0,1).contiguous().view(n_chan,-1)\n",
    "\n",
    "    \n",
    "\n",
    "class MultiImageDataBunch(ImageDataBunch):\n",
    "    def batch_stats(self, funcs:Collection[Callable]=None, ds_type:DatasetType=DatasetType.Train)->Tensor:\n",
    "        \"Grab a batch of data and call reduction function `func` per channel\"\n",
    "        funcs = ifnone(funcs, [torch.mean,torch.std])\n",
    "        x = self.one_batch(ds_type=ds_type, denorm=False)[0].cpu()\n",
    "        \n",
    "        return [func(multi_image_channel_view(x), 1) for func in funcs]\n",
    "\n",
    "    def normalize(self, stats:Collection[Tensor]=None, do_x:bool=True, do_y:bool=False)->None:\n",
    "        \"Add normalize transform using `stats` (defaults to `DataBunch.batch_stats`)\"\n",
    "        if getattr(self,'norm',False): raise Exception('Can not call normalize twice')\n",
    "        if stats is None: self.stats = self.batch_stats()\n",
    "        else:             self.stats = stats\n",
    "        self.norm,self.denorm = multi_normalize_funcs(*self.stats, do_x=do_x, do_y=do_y)\n",
    "        self.add_tfm(self.norm)\n",
    "        \n",
    "        return self\n",
    "\n",
    "\n",
    "\n",
    "class MultiImageList(ImageList):\n",
    "    \"`ItemList` suitable for computer vision.\"\n",
    "    _bunch,_square_show,_square_show_res = MultiImageDataBunch,True,True\n",
    "    def __init__(self, *args,  **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.channels = 1\n",
    "        \n",
    "    def open(self, fn):\n",
    "        img_data = np.load(fn)\n",
    "        \n",
    "        img_list = []\n",
    "        if len(img_data.shape) == 4:\n",
    "            for j in range(img_data.shape[0]):\n",
    "                for i in range(img_data.shape[1]):\n",
    "                    img_list.append(Image(tensor(img_data[j,i][None])))\n",
    "        else:\n",
    "            for i in range(img_data.shape[0]):\n",
    "                img_list.append(Image(tensor(img_data[i][None])))\n",
    "        \n",
    "        self.channels = img_list[0].data.shape[0]\n",
    "        return MultiImage(img_list)\n",
    "        \n",
    "    def reconstruct(self, t:Tensor):\n",
    "        #set_trace()\n",
    "        n, h, w = t.shape\n",
    "        n //= self.channels\n",
    "        one_img = t.view(self.channels,n*h,w)\n",
    "        return Image(one_img.float().clamp(min=0,max=1))\n",
    "\n",
    "class NpyRawImageList(ImageList):\n",
    "    def open(self, fn):\n",
    "        img_data = np.load(fn)\n",
    "        return Image(tensor(img_data[None]))\n",
    "\n",
    "    def analyze_pred(self, pred):\n",
    "        return pred[0:1]\n",
    "\n",
    "    def reconstruct(self, t):\n",
    "        return Image(t.float().clamp(min=0,max=1))                \n",
    "\n",
    "class MultiImageImageList(MultiImageList):\n",
    "    _label_cls,_square_show,_square_show_res = NpyRawImageList,False,False\n",
    "\n",
    "    def show_xys(self, xs, ys, imgsize:int=4, figsize:Optional[Tuple[int,int]]=None, **kwargs):\n",
    "        \"Show the `xs` (inputs) and `ys`(targets)  on a figure of `figsize`.\"\n",
    "        axs = subplots(len(xs), 2, imgsize=imgsize, figsize=figsize)\n",
    "        for i, (x,y) in enumerate(zip(xs,ys)):\n",
    "            x.show(ax=axs[i,0], **kwargs)\n",
    "            y.show(ax=axs[i,1], **kwargs)\n",
    "        plt.tight_layout()\n",
    "\n",
    "    def show_xyzs(self, xs, ys, zs, imgsize:int=4, figsize:Optional[Tuple[int,int]]=None, **kwargs):\n",
    "        \"Show `xs` (inputs), `ys` (targets) and `zs` (predictions) on a figure of `figsize`.\"\n",
    "        title = 'Input / Prediction / Target'\n",
    "        axs = subplots(len(xs), 3, imgsize=imgsize, figsize=figsize, title=title, weight='bold', size=14)\n",
    "        for i,(x,y,z) in enumerate(zip(xs,ys,zs)):\n",
    "            x.show(ax=axs[i,0], **kwargs)\n",
    "            y.show(ax=axs[i,2], **kwargs)\n",
    "            z.show(ax=axs[i,1], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_hr(x):\n",
    "    hr_name = x.relative_to(lr_path)\n",
    "    return hr_path/hr_name\n",
    "\n",
    "def get_src(size=128, scale=1):\n",
    "    if scale != 1: use_lr_path = lr_path\n",
    "    else: use_lr_path = lr_path\n",
    "        \n",
    "    def map_to_hr(x):\n",
    "        hr_name = x.relative_to(use_lr_path)\n",
    "        return hr_path/hr_name\n",
    "    \n",
    "    src = (MultiImageImageList\n",
    "            .from_folder(lr_path, extensions=['.npy'])\n",
    "            .split_by_folder()\n",
    "            .label_from_func(map_to_hr))\n",
    "    return src\n",
    "\n",
    "def get_data(bs, size, scale=1, max_zoom=1.):\n",
    "    src = get_src(size, scale=scale)    \n",
    "    tfms = get_transforms(flip_vert=True, max_zoom=max_zoom)\n",
    "    #tfms = [[],[]]\n",
    "    data = (src\n",
    "            .transform(tfms, size=size)\n",
    "            .transform_y(tfms, size=size*scale)\n",
    "            .databunch(bs=bs).normalize(do_y=True))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 8\n",
    "size = 64\n",
    "data = get_data(bs, size, scale=4, max_zoom=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoXModel(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        num_img = x.shape[1] // 2\n",
    "        x1, x2 = x[:,0:num_img], x[:,num_img:]\n",
    "        y1 = self.model(x1)\n",
    "        y2 = self.model(x2)\n",
    "        return torch.cat((y1,y2),1)\n",
    "    \n",
    "    \n",
    "class TwoYLoss(nn.Module):\n",
    "    def __init__(self, base_loss=F.mse_loss, stable_wt=0.15):\n",
    "        super().__init__()\n",
    "        self.base_loss = base_loss\n",
    "        self.stable_wt = stable_wt\n",
    "        self.base_loss_wt = (1-stable_wt)/2\n",
    "        self.metric_names = ['pixel','stable','ssim','psnr']\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        base_loss = self.base_loss\n",
    "        y1 = input[:,0:1,:,:]\n",
    "        y2 = input[:,1:2,:,:]\n",
    "        base_1 = base_loss(y1, target)\n",
    "        base_2 = base_loss(y2, target)\n",
    "        stable_err = F.mse_loss(y1,y2)\n",
    "        loss = (base_1 * self.base_loss_wt +\n",
    "                base_2 * self.base_loss_wt +\n",
    "                stable_err * self.stable_wt)\n",
    "        self.metrics = {\n",
    "            'pixel': (base_1+base_2)/2,\n",
    "            'stable': stable_err,\n",
    "            'ssim': (ssim.ssim(y1, target)+ssim.ssim(y2,target))/2,\n",
    "            'psnr': (psnr(y1, target)+psnr(y2,target))/2\n",
    "        }\n",
    "        return loss\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 8\n",
    "size = 64\n",
    "data = get_data(bs, size, scale=4, max_zoom=1.2)\n",
    "\n",
    "in_c = 5\n",
    "out_c = 1\n",
    "nf = 16\n",
    "gcval = 16 # 32\n",
    "nb = 5 # 23\n",
    "\n",
    "#loss = TwoYLoss(F.mse_loss)\n",
    "loss = F.mse_loss\n",
    "\n",
    "#model = TwoXModel(RRDB_Net(in_c, out_c, nf, nb, gc=gcval))\n",
    "model = RRDB_Net(in_c, out_c, nf, nb, gc=gcval)\n",
    "model = nn.DataParallel(model)\n",
    "#opt_func = partial(adabound.AdaBound,  lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = data.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.min(), x.max(), x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.min(), y.max(), y.mean(), y.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn = Learner(data, model, callback_fns=LossMetrics, loss_func=loss) #, opt_func=opt_func)\n",
    "learn = Learner(data, model, loss_func=loss) #, opt_func=opt_func)\n",
    "\n",
    "learn = learn.to_fp16(loss_scale=64)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.data.show_batch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.lr_find()\n",
    "#learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(cyc_len=1, max_lr=1e-3)\n",
    "#learn.fit(4, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('multiimg.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results(rows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = data.one_batch()\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 4\n",
    "size = 256\n",
    "data = get_data(bs, size, scale=4, max_zoom=1.2)\n",
    "in_c = 5\n",
    "out_c = 1\n",
    "nf = gcval = 16 # 32\n",
    "nb = 5 # 23\n",
    "\n",
    "model = TwoXModel(RRDB_Net(in_c, out_c, nf, nb, gc=gcval))\n",
    "model = RRDB_Net(in_c, out_c, nf, nb, gc=gcval)\n",
    "model = nn.DataParallel(model)\n",
    "learn = Learner(data, model, loss_func=loss) #, opt_func=opt_func)\n",
    "learn = learn.to_fp16()\n",
    "learn = learn.load('multiimg.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(2, max_lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('multiimg.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results(rows=3, imgsize=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_files = []\n",
    "#movie_files = list(Path('/scratch/bpho/datasets/movies_001/test').glob('*.czi'))\n",
    "#movie_files += list(Path('/scratch/bpho/datasources/low_res_test/').glob('low res confocal*.czi'))\n",
    "movie_files += list(Path('/scratch/bpho/datasources/neuron_movies2/').glob('low*.*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movie_files = movie_files[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_from_tiles(learn, in_img, tile_sz=128, scale=4, wsize=3):\n",
    "    cur_size = in_img.shape[1:3]\n",
    "    c = in_img.shape[0]\n",
    "    new_size = (cur_size[0]*scale, cur_size[1]*scale)\n",
    "    w, h = cur_size\n",
    "    \n",
    "    in_tile = torch.zeros((c,tile_sz,tile_sz))\n",
    "    out_img = torch.zeros((1,w*scale,h*scale))\n",
    "    \n",
    "    for x_tile in range(math.ceil(w/tile_sz)):\n",
    "        for y_tile in range(math.ceil(h/tile_sz)):\n",
    "            x_start = x_tile\n",
    "\n",
    "            x_start = x_tile*tile_sz\n",
    "            x_end = min(x_start+tile_sz, w)\n",
    "            y_start = y_tile*tile_sz\n",
    "            y_end = min(y_start+tile_sz, h)\n",
    "            \n",
    "            \n",
    "            in_tile[:,0:(x_end-x_start), 0:(y_end-y_start)] = tensor(in_img[:,x_start:x_end, y_start:y_end])\n",
    "            \n",
    "            img_list = [Image(in_tile[i][None]) for i in range(wsize)]\n",
    "            #img_list += img_list\n",
    "            \n",
    "            tlist = MultiImage(img_list)\n",
    "            \n",
    "            out_tile,_,_ = learn.predict(tlist)\n",
    "            \n",
    "            out_x_start = x_start * scale\n",
    "            out_x_end = x_end * scale\n",
    "            out_y_start = y_start * scale\n",
    "            out_y_end = y_end * scale\n",
    "\n",
    "            #print(\"out: \", out_x_start, out_y_start, \",\", out_x_end, out_y_end)\n",
    "            in_x_start = 0\n",
    "            in_y_start = 0\n",
    "            in_x_end = (x_end-x_start) * scale\n",
    "            in_y_end = (y_end-y_start) * scale\n",
    "            #print(\"tile: \",in_x_start, in_y_start, \",\", in_x_end, in_y_end)\n",
    "           \n",
    "            out_img[:,out_x_start:out_x_end, out_y_start:out_y_end] = out_tile.data[:,\n",
    "                                                                                  in_x_start:in_x_end, \n",
    "                                                                                  in_y_start:in_y_end]\n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fredmonroe/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n"
     ]
    }
   ],
   "source": [
    "from skimage.io import imsave\n",
    "\n",
    "def tif_predict_movie(learn, tif_in, orig_out='orig.tif', pred_out='pred.tif', size=128, wsize=3):\n",
    "    im = PIL.Image.open(tif_in)\n",
    "    im.load()\n",
    "    times = im.n_frames\n",
    "    #times = min(times,100)\n",
    "    imgs = []\n",
    "    for i in range(times):\n",
    "        im.seek(i)\n",
    "        imgs.append(np.array(im).astype(np.float32)/255.)\n",
    "    img_data = np.stack(imgs)\n",
    "    \n",
    "    def pull_frame(i):\n",
    "        im.seek(i)\n",
    "        im.load()\n",
    "        return np.array(im)\n",
    "    \n",
    "    folder = Path(pred_out).stem().mkdir()\n",
    "    \n",
    "    preds = []\n",
    "    origs = []\n",
    "    img_max = img_data.max()\n",
    "    print(img_max)\n",
    "    print('max: ', img_max)\n",
    "    for t in progress_bar(list(range(0,times-wsize+1))):\n",
    "        img = img_data[t:(t+wsize)].copy()\n",
    "        img /= img_max\n",
    "        \n",
    "        out_img = image_from_tiles(learn, img, tile_sz=size, wsize=wsize)\n",
    "        pred = (out_img*255).cpu().numpy().astype(np.uint8)\n",
    "        preds.append(pred)\n",
    "        orig = (img[1][None]*255).astype(np.uint8)\n",
    "        origs.append(orig)\n",
    "\n",
    "    all_y = np.concatenate(preds)\n",
    "    #print(all_y.shape)\n",
    "    imageio.mimwrite(pred_out, all_y, imagej=True) #, fps=30, macro_block_size=None) # for mp4\n",
    "    all_y = np.concatenate(origs)\n",
    "    #print(all_y.shape)\n",
    "    imageio.mimwrite(orig_out, all_y, imagej=True) #, fps=30, macro_block_size=None)\n",
    "\n",
    "\n",
    "def czi_predict_movie(learn, czi_in, orig_out='orig.tif', pred_out='pred.tif', size=128, wsize=3):\n",
    "    with czifile.CziFile(czi_in) as czi_f:\n",
    "        proc_axes, proc_shape = get_czi_shape_info(czi_f)\n",
    "        channels = proc_shape['C']\n",
    "        depths = proc_shape['Z']\n",
    "        times = proc_shape['T']\n",
    "        #times = min(times, 100)\n",
    "        x,y = proc_shape['X'], proc_shape['Y']\n",
    "        print(f'czi: x:{x} y:{y} t:{times} z:{depths}')\n",
    "        \n",
    "        #folder_name = Path(pred_out).stem\n",
    "        #folder = Path(folder_name)\n",
    "        #if folder.exists(): shutil.rmtree(folder)\n",
    "        #folder.mkdir()\n",
    "        \n",
    "        data = czi_f.asarray().astype(np.float32)/255.\n",
    "        preds = []\n",
    "        origs = []\n",
    "        \n",
    "        img_max = data.max()\n",
    "        print(img_max)\n",
    "        for t in progress_bar(list(range(0,times-wsize+1))):\n",
    "            idx = build_index(proc_axes, {'T': slice(t,t+wsize), 'C': 0, 'Z':0, 'X':slice(0,x),'Y':slice(0,y)})\n",
    "            img = data[idx].copy()\n",
    "            img /= img_max\n",
    "            \n",
    "            out_img = image_from_tiles(learn, img, tile_sz=size, wsize=wsize)\n",
    "            pred = (out_img*255).cpu().numpy().astype(np.uint8)\n",
    "            preds.append(pred)\n",
    "            #imsave(folder/f'{t}.tif', pred[0])\n",
    "            \n",
    "            orig = (img[1][None]*255).astype(np.uint8)\n",
    "            origs.append(orig)\n",
    "            \n",
    "        all_y = np.concatenate(preds)\n",
    "        #print(all_y.shape)\n",
    "        imageio.mimwrite(pred_out, all_y) #, fps=30, macro_block_size=None) # for mp4\n",
    "        all_y = np.concatenate(origs)\n",
    "        #print(all_y.shape)\n",
    "        imageio.mimwrite(orig_out, all_y) #, fps=30, macro_block_size=None)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 2\n",
    "size = 440\n",
    "data = get_data(bs, size, scale=4, max_zoom=1.2)\n",
    "in_c = 5\n",
    "out_c = 1\n",
    "nf = gcval = 16 # 32\n",
    "nb = 5 # 23\n",
    "\n",
    "#model = TwoXModel(RRDB_Net(in_c, out_c, nf, nb, gc=gcval))\n",
    "model = RRDB_Net(in_c, out_c, nf, nb, gc=gcval)\n",
    "loss = F.mse_loss\n",
    "\n",
    "model = nn.DataParallel(model)\n",
    "learn = Learner(data, model, callback_fns=LossMetrics, loss_func=loss) #, opt_func=opt_func)\n",
    "learn = learn.to_fp16()\n",
    "learn = learn.load('multiimg.2')\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = data.one_batch()\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in progress_bar(movie_files):\n",
    "    #try:\n",
    "        pred_name = f'{fn.stem}_pred.tif'\n",
    "        orig_name = f'{fn.stem}_orig.tif'\n",
    "        if not Path(pred_name).exists():\n",
    "            if fn.suffix == '.czi':\n",
    "                print(f'czi {fn.stem}')\n",
    "                czi_predict_movie(learn, fn, size=size, orig_out=orig_name, pred_out=pred_name, wsize=5)\n",
    "            elif fn.suffix == '.tif':\n",
    "                tif_predict_movie(learn, fn, size=size, orig_out=orig_name, pred_out=pred_name, wsize=5)\n",
    "                tif_fn = fn\n",
    "                print(f'tif {fn.stem}')\n",
    "        else:\n",
    "            print(f'skip: {fn.stem}')\n",
    "    #except:\n",
    "    #    print(f'err: {fn.stem}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = PIL.Image.open(tif_fn)\n",
    "im.load()\n",
    "im.n_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im.seek(3)\n",
    "np.array(im).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = list(PIL.ImageSequence.Iterator(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_imgs = images[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.stack([np.array(img) for img in w_imgs]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_imgs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -hatlr *.tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc(conv_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
