{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from superres import superres_metrics, ssim, psnr\n",
    "\n",
    "datasetname = 'multiframe_001'\n",
    "data_path = Path('/scratch/bpho')\n",
    "datasets = data_path/'datasets'\n",
    "datasources = data_path/'datasources'\n",
    "dataset = datasets/datasetname\n",
    "\n",
    "hr_path = dataset/'hr'\n",
    "lr_path = dataset/'lr'\n",
    "lr_up_path = dataset/'lr_up'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpyRawImageList(ImageList):\n",
    "    def open(self, fn):\n",
    "        img_data = np.load(fn)\n",
    "        return Image(tensor(img_data[None]))\n",
    "\n",
    "class TransformableLists(ItemBase):\n",
    "    def __init__(self, img_lists):\n",
    "        self.img_lists = img_lists\n",
    "       \n",
    "    def __repr__(self):\n",
    "        return f'MultiImg: {len(self.img_lists)}'\n",
    "    \n",
    "    @property\n",
    "    def data(self):\n",
    "        img_data = torch.stack([torch.stack([img.data for img in img_list]) \n",
    "                                            for img_list in self.img_lists])\n",
    "        data = tensor(img_data)\n",
    "        return data\n",
    "    \n",
    "    def apply_tfms(self, tfms, **kwargs):\n",
    "        first_time = True\n",
    "        save_img_lists = []\n",
    "        for img_list in self.img_lists:\n",
    "            save_img_list = []\n",
    "            for img in img_list:\n",
    "                new_img = img.apply_tfms(tfms, do_resolve=first_time, **kwargs)\n",
    "                first_time = False\n",
    "                save_img_list.append(new_img)\n",
    "            save_img_lists.append(save_img_list)\n",
    "        self.img_lists = save_img_lists\n",
    "        return self\n",
    "    \n",
    "class MultiImageDataBunch(ImageDataBunch):\n",
    "    def batch_stats(self, funcs:Collection[Callable]=None)->Tensor:\n",
    "        \"Grab a batch of data and call reduction function `func` per channel\"\n",
    "        funcs = ifnone(funcs, [torch.mean,torch.std])\n",
    "        ds_type = DatasetType.Valid if self.valid_dl else DatasetType.Train\n",
    "        x = self.one_batch(ds_type=ds_type, denorm=False)[0].cpu()\n",
    "        def multi_channel_view(x):\n",
    "            return x.transpose(3,0).contiguous().view(x.shape[3],-1)\n",
    "        return [func(multi_channel_view(x), 1) for func in funcs]\n",
    "\n",
    "    def normalize(self, stats:Collection[Tensor]=None, do_x:bool=True, do_y:bool=False)->None:\n",
    "        \"Add normalize transform using `stats` (defaults to `DataBunch.batch_stats`)\"\n",
    "        if getattr(self,'norm',False): raise Exception('Can not call normalize twice')\n",
    "        if stats is None: self.stats = self.batch_stats()\n",
    "        else:             self.stats = stats\n",
    "        self.norm,self.denorm = normalize_funcs(*self.stats, do_x=do_x, do_y=do_y)\n",
    "        self.add_tfm(self.norm)\n",
    "        return self\n",
    "    \n",
    "class MultiImageList(ItemList):\n",
    "    _bunch = MultiImageDataBunch\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def open(self, fn):\n",
    "        img_data = np.load(fn)\n",
    "        img_lists = []\n",
    "        for j in range(img_data.shape[0]):\n",
    "            imgs = []\n",
    "            for i in range(img_data.shape[1]):\n",
    "                imgs.append(Image(tensor(img_data[j,i,:,:][None])))\n",
    "            img_lists.append(imgs)\n",
    "        return TransformableLists(img_lists)\n",
    "    \n",
    "    def get(self, i):\n",
    "        fn = super().get(i)\n",
    "        img_lists = self.open(fn)\n",
    "        return img_lists    \n",
    "    \n",
    "\n",
    "class MultiToMultiImageList(MultiImageList):\n",
    "    _label_cls = NpyRawImageList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_hr(x):\n",
    "    hr_name = x.relative_to(lr_path)\n",
    "    return hr_path/hr_name\n",
    "\n",
    "def get_src(size=128, scale=1):\n",
    "    if scale != 1: use_lr_path = lr_path\n",
    "    else: use_lr_path = lr_up_path\n",
    "        \n",
    "    def map_to_hr(x):\n",
    "        hr_name = x.relative_to(use_lr_path)\n",
    "        return hr_path/hr_name\n",
    "    \n",
    "    src = (MultiToMultiImageList.from_folder(use_lr_path, extensions=['.npy'])\n",
    "           .split_by_folder()\n",
    "           .label_from_func(map_to_hr))\n",
    "    return src\n",
    "\n",
    "def get_data(bs, size, scale=1, max_zoom=1.):\n",
    "    src = get_src(size, scale=scale)    \n",
    "    tfms = get_transforms(flip_vert=True, max_zoom=max_zoom)\n",
    "    data = (src\n",
    "            .transform(tfms, size=size)\n",
    "            .transform_y(tfms, size=size*scale)\n",
    "            .databunch(bs=bs).normalize(do_y=True))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cool\n"
     ]
    }
   ],
   "source": [
    "print('cool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoXModel(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1, x2 = x[:,0], x[:,1]\n",
    "        y1 = self.model(x1)\n",
    "        y2 = self.model(x2)\n",
    "        return torch.stack([y1,y2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShortcutBlock(nn.Module):\n",
    "    #Elementwise sum the output of a submodule to its input\n",
    "    def __init__(self, submodule):\n",
    "        super(ShortcutBlock, self).__init__()\n",
    "        self.sub = submodule\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = x + self.sub(x)\n",
    "        return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        tmpstr = 'Identity + \\n|'\n",
    "        modstr = self.sub.__repr__().replace('\\n', '\\n|')\n",
    "        tmpstr = tmpstr + modstr\n",
    "        return tmpstr\n",
    "\n",
    "\n",
    "def sequential(*args):\n",
    "    # Flatten Sequential. It unwraps nn.Sequential.\n",
    "    if len(args) == 1:\n",
    "        if isinstance(args[0], OrderedDict):\n",
    "            raise NotImplementedError('sequential does not support OrderedDict input.')\n",
    "        return args[0]  # No sequential is needed.\n",
    "    modules = []\n",
    "    for module in args:\n",
    "        if isinstance(module, nn.Sequential):\n",
    "            for submodule in module.children():\n",
    "                modules.append(submodule)\n",
    "        elif isinstance(module, nn.Module):\n",
    "            modules.append(module)\n",
    "    return nn.Sequential(*modules)\n",
    "\n",
    "\n",
    "class ResidualDenseBlock_5C(nn.Module):\n",
    "    def __init__(self, nc, gc=32):\n",
    "        super().__init__()\n",
    "        # gc: growth channel, i.e. intermediate channels\n",
    "        self.conv1 = conv_layer(nc, gc, norm_type=NormType.Weight, leaky=0.2)\n",
    "        self.conv2 = conv_layer(nc+gc, gc, norm_type=NormType.Weight, leaky=0.2)\n",
    "        self.conv3 = conv_layer(nc+2*gc, gc, norm_type=NormType.Weight, leaky=0.2)\n",
    "        self.conv4 = conv_layer(nc+3*gc, gc, norm_type=NormType.Weight, leaky=0.2)\n",
    "        # turn off activation?\n",
    "        self.conv5 = conv_layer(nc+4*gc, gc, norm_type=NormType.Weight, leaky=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(torch.cat((x, x1), 1))\n",
    "        x3 = self.conv3(torch.cat((x, x1, x2), 1))\n",
    "        x4 = self.conv4(torch.cat((x, x1, x2, x3), 1))\n",
    "        x5 = self.conv5(torch.cat((x, x1, x2, x3, x4), 1))\n",
    "        return x5.mul(0.2) + x\n",
    "    \n",
    "class RRDB(nn.Module):\n",
    "    def __init__(self, nc, gc=32):\n",
    "        super(RRDB, self).__init__()\n",
    "        self.RDB1 = ResidualDenseBlock_5C(nc, gc)\n",
    "        self.RDB2 = ResidualDenseBlock_5C(nc, gc)\n",
    "        self.RDB3 = ResidualDenseBlock_5C(nc, gc)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.RDB1(x)\n",
    "        out = self.RDB2(out)\n",
    "        out = self.RDB3(out)\n",
    "        return out.mul(0.2) + x\n",
    "    \n",
    "class RRDB_Net(nn.Module):\n",
    "    def __init__(self, in_nc, out_nc, nf, nb, gc=32, upscale=4):\n",
    "        super(RRDB_Net, self).__init__()\n",
    "        n_upscale = int(math.log(upscale, 2))\n",
    "        if upscale == 3:\n",
    "            n_upscale = 1\n",
    "        \n",
    "        fea_conv = conv_layer(in_nc, nf, norm_type=None, use_activ=False)\n",
    "        rb_blocks = [RRDB(nf, gc=32) for _ in range(nb)]\n",
    "        LR_conv = conv_layer(nf, nf, leaky=0.2)\n",
    "        \n",
    "        if upscale == 3:\n",
    "            upsampler = PixelShuffle_ICNR(nf, blur=True, leaky=0.2, scale=3)\n",
    "        else:\n",
    "            upsampler = [PixelShuffle_ICNR(nf, blur=True, leaky=0.2) for _ in range(n_upscale)]\n",
    "\n",
    "\n",
    "            \n",
    "        HR_conv0 = conv_layer(nf, nf, leaky=0.2)\n",
    "        HR_conv1 = conv_layer(nf, out_nc, norm_type=None, use_activ=False)\n",
    "\n",
    "        self.model = sequential(\n",
    "            fea_conv, \n",
    "            ShortcutBlock(sequential(*rb_blocks, LR_conv)),\\\n",
    "            *upsampler, HR_conv0, HR_conv1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "class MultiImageToMultiChannel(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        new_x = x.view(x.shape[0],-1,x.shape[-2], x.shape[-1])\n",
    "        return self.model(new_x)\n",
    "    \n",
    "class TwoYLoss(nn.Module):\n",
    "    def __init__(self, base_loss=F.mse_loss, stable_wt=0.15):\n",
    "        super().__init__()\n",
    "        self.base_loss = base_loss\n",
    "        self.stable_wt = stable_wt\n",
    "        self.base_loss_wt = (1-stable_wt)/2\n",
    "        self.metric_names = ['pixel_1','pixel_2','stable','ssim','psnr']\n",
    "        \n",
    "\n",
    "    def forward(self, input, target):\n",
    "        base_loss = self.base_loss\n",
    "        y1,y2 = input[0], input[1]\n",
    "        \n",
    "        base_1 = base_loss(y1, target)\n",
    "        base_2 = base_loss(y2, target)\n",
    "        stable_err = F.mse_loss(y1,y2)\n",
    "        loss = (base_1 * self.base_loss_wt +\n",
    "                base_2 * self.base_loss_wt +\n",
    "                stable_err * self.stable_wt)\n",
    "        self.metrics = {\n",
    "            'pixel_1': base_1,\n",
    "            'pixel_2': base_2,\n",
    "            'stable': stable_err,\n",
    "            'ssim': (ssim.ssim(y1, target)+ssim.ssim(y2,target))/2,\n",
    "            'psnr': (psnr(y1, target)+psnr(y2,target))/2\n",
    "        }\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 8\n",
    "size = 128\n",
    "data = get_data(bs, size, scale=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_c = 3\n",
    "out_c = 1\n",
    "nf = 32\n",
    "nb = 5\n",
    "loss = TwoYLoss()\n",
    "model = TwoXModel(MultiImageToMultiChannel(RRDB_Net(3, 1, nf, nb )))\n",
    "learn = Learner(data, model, callback_fns=LossMetrics, loss_func=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 01:48 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>pixel_1</th>\n",
       "      <th>pixel_2</th>\n",
       "      <th>stable</th>\n",
       "      <th>ssim</th>\n",
       "      <th>psnr</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.152352</td>\n",
       "      <td>0.137330</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.150756</td>\n",
       "      <td>0.061452</td>\n",
       "      <td>0.209416</td>\n",
       "      <td>8.265573</td>\n",
       "      <td>01:48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, max_lr=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, max_lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "loss = TwoYLoss()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc(learn.fit_one_cycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim.ssim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
