{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "datasetname = 'multiframe_001'\n",
    "data_path = Path('/scratch/bpho')\n",
    "datasets = data_path/'datasets'\n",
    "datasources = data_path/'datasources'\n",
    "dataset = datasets/datasetname\n",
    "\n",
    "hr_path = dataset/'hr'\n",
    "lr_path = dataset/'lr'\n",
    "lr_up_path = dataset/'lr_up'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpyRawImageList(ImageList):\n",
    "    def open(self, fn):\n",
    "        img_data = np.load(fn)\n",
    "        return Image(tensor(img_data[None]))\n",
    "\n",
    "class TransformableLists(ItemBase):\n",
    "    def __init__(self, img_lists):\n",
    "        self.img_lists = img_lists\n",
    "       \n",
    "    def __repr__(self):\n",
    "        return f'MultiImg: {len(self.img_lists)}'\n",
    "    \n",
    "    @property\n",
    "    def data(self):\n",
    "        img_data = torch.stack([torch.stack([img.data for img in img_list]) \n",
    "                                            for img_list in self.img_lists])\n",
    "        data = tensor(img_data)\n",
    "        return data\n",
    "    \n",
    "    def apply_tfms(self, tfms, **kwargs):\n",
    "        first_time = True\n",
    "        save_img_lists = []\n",
    "        for img_list in self.img_lists:\n",
    "            save_img_list = []\n",
    "            for img in img_list:\n",
    "                new_img = img.apply_tfms(tfms, do_resolve=first_time, **kwargs)\n",
    "                first_time = False\n",
    "                save_img_list.append(new_img)\n",
    "            save_img_lists.append(save_img_list)\n",
    "        self.img_lists = save_img_lists\n",
    "        return self\n",
    "    \n",
    "class MultiImageDataBunch(ImageDataBunch):\n",
    "    def batch_stats(self, funcs:Collection[Callable]=None)->Tensor:\n",
    "        \"Grab a batch of data and call reduction function `func` per channel\"\n",
    "        funcs = ifnone(funcs, [torch.mean,torch.std])\n",
    "        ds_type = DatasetType.Valid if self.valid_dl else DatasetType.Train\n",
    "        x = self.one_batch(ds_type=ds_type, denorm=False)[0].cpu()\n",
    "        def multi_channel_view(x):\n",
    "            return x.transpose(3,0).contiguous().view(x.shape[3],-1)\n",
    "        return [func(multi_channel_view(x), 1) for func in funcs]\n",
    "\n",
    "    def normalize(self, stats:Collection[Tensor]=None, do_x:bool=True, do_y:bool=False)->None:\n",
    "        \"Add normalize transform using `stats` (defaults to `DataBunch.batch_stats`)\"\n",
    "        if getattr(self,'norm',False): raise Exception('Can not call normalize twice')\n",
    "        if stats is None: self.stats = self.batch_stats()\n",
    "        else:             self.stats = stats\n",
    "        self.norm,self.denorm = normalize_funcs(*self.stats, do_x=do_x, do_y=do_y)\n",
    "        self.add_tfm(self.norm)\n",
    "        return self\n",
    "    \n",
    "class MultiImageList(ItemList):\n",
    "    _bunch = MultiImageDataBunch\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def open(self, fn):\n",
    "        img_data = np.load(fn)\n",
    "        img_lists = []\n",
    "        for j in range(img_data.shape[0]):\n",
    "            imgs = []\n",
    "            for i in range(img_data.shape[1]):\n",
    "                imgs.append(Image(tensor(img_data[j,i,:,:][None])))\n",
    "            img_lists.append(imgs)\n",
    "        return TransformableLists(img_lists)\n",
    "    \n",
    "    def get(self, i):\n",
    "        fn = super().get(i)\n",
    "        img_lists = self.open(fn)\n",
    "        return img_lists    \n",
    "    \n",
    "\n",
    "class MultiToMultiImageList(MultiImageList):\n",
    "    _label_cls = NpyRawImageList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_hr(x):\n",
    "    hr_name = x.relative_to(lr_path)\n",
    "    return hr_path/hr_name\n",
    "\n",
    "def get_src(size=128, scale=1):\n",
    "    if scale != 1: use_lr_path = lr_path\n",
    "    else: use_lr_path = lr_up_path\n",
    "        \n",
    "    def map_to_hr(x):\n",
    "        hr_name = x.relative_to(use_lr_path)\n",
    "        return hr_path/hr_name\n",
    "    \n",
    "    src = (MultiToMultiImageList.from_folder(use_lr_path, extensions=['.npy'])\n",
    "           .split_by_folder()\n",
    "           .label_from_func(map_to_hr))\n",
    "    return src\n",
    "\n",
    "def get_data(bs, size, scale=1, max_zoom=1.):\n",
    "    src = get_src(size, scale=scale)    \n",
    "    tfms = get_transforms(flip_vert=True, max_zoom=max_zoom)\n",
    "    data = (src\n",
    "            .transform(tfms, size=size)\n",
    "            .transform_y(tfms, size=size*scale)\n",
    "            .databunch(bs=bs).normalize(do_y=True))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 24\n",
    "size = 128\n",
    "data = get_data(bs, size, scale=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cool\n"
     ]
    }
   ],
   "source": [
    "print('cool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.4 ms, sys: 690 ms, total: 732 ms\n",
      "Wall time: 4.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x,y = next(iter(data.train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 1, 128, 128]), torch.Size([1, 512, 512]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape, y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
