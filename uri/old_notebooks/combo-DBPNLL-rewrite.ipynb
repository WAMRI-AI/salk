{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai import *          # Quick access to most common functionality\n",
    "from fastai.vision import *   # Quick access to computer vision functionality\n",
    "from fastai.layers import Lambda\n",
    "from fastai.callbacks import *\n",
    "import pytorch_ssim as ssim\n",
    "from superres import *\n",
    "from torchvision.models import vgg16_bn\n",
    "import czifile\n",
    "import shutil\n",
    "import numbers\n",
    "from fastai.vision.image import TfmPixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.set_device(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = Path('/DATA/WAMRI/salk/uri')\n",
    "train_hr = path_data/'Image_restoration_data/train_HR'\n",
    "train_lr = path_data/'Image_restoration_data/train_HR'\n",
    "path_test_lr = path_data/'test_imgs'\n",
    "path_test2_lr = path_data/'newimg'\n",
    "path_models = Path('/DATA/WAMRI/salk/uri/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def pull_id(fn):\n",
    "    return fn.split('#')[-1].split('.')[0]\n",
    "\n",
    "def match_hr_fn(x):\n",
    "    return hr_names_by_id[pull_id(x.name)]\n",
    "\n",
    "lr_names_full = list(train_lr.glob('*.tif'))\n",
    "lr_names_full.sort()\n",
    "hr_names_by_id = {pull_id(hrfn.name):hrfn for hrfn in train_hr.glob('*.tif')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(fnames))\n",
    "# for fn in progress_bar(fnames):\n",
    "#     process_src(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = (GrayImageItemList\n",
    "       .from_folder(train_lr, '*.tif', label_class=GrayImageItemList)\n",
    "       .split_by_valid_func(lambda x: x.stem[-3] == '0')\n",
    "       .label_from_func(match_hr_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def charbonnier_loss(inputs, targets):\n",
    "    eps = 1e-6;\n",
    "    d = inputs - targets\n",
    "    e = torch.sqrt(d**2 + eps)\n",
    "    return e.mean()\n",
    "\n",
    "\n",
    "class GaussianSmoothing(nn.Module):\n",
    "    \"\"\"\n",
    "    Apply gaussian smoothing on a\n",
    "    1d, 2d or 3d tensor. Filtering is performed seperately for each channel\n",
    "    in the input using a depthwise convolution.\n",
    "    Arguments:\n",
    "        channels (int, sequence): Number of channels of the input tensors. Output will\n",
    "            have this number of channels as well.\n",
    "        kernel_size (int, sequence): Size of the gaussian kernel.\n",
    "        sigma (float, sequence): Standard deviation of the gaussian kernel.\n",
    "        dim (int, optional): The number of dimensions of the data.\n",
    "            Default value is 2 (spatial).\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, kernel_size, sigma, dim=2):\n",
    "        super(GaussianSmoothing, self).__init__()\n",
    "        if isinstance(kernel_size, numbers.Number):\n",
    "            kernel_size = [kernel_size] * dim\n",
    "        if isinstance(sigma, numbers.Number):\n",
    "            sigma = [sigma] * dim\n",
    "\n",
    "        # The gaussian kernel is the product of the\n",
    "        # gaussian function of each dimension.\n",
    "        kernel = 1\n",
    "        meshgrids = torch.meshgrid(\n",
    "            [\n",
    "                torch.arange(size, dtype=torch.float32)\n",
    "                for size in kernel_size\n",
    "            ]\n",
    "        )\n",
    "        for size, std, mgrid in zip(kernel_size, sigma, meshgrids):\n",
    "            mean = (size - 1) / 2\n",
    "            kernel *= 1 / (std * math.sqrt(2 * math.pi)) * \\\n",
    "                      torch.exp(-((mgrid - mean) / (2 * std)) ** 2)\n",
    "\n",
    "        # Make sure sum of values in gaussian kernel equals 1.\n",
    "        kernel = kernel / torch.sum(kernel)\n",
    "\n",
    "        # Reshape to depthwise convolutional weight\n",
    "        kernel = kernel.view(1, 1, *kernel.size())\n",
    "        kernel = kernel.repeat(channels, *[1] * (kernel.dim() - 1))\n",
    "\n",
    "        self.register_buffer('weight', kernel)\n",
    "        self.groups = channels\n",
    "\n",
    "        if dim == 1:\n",
    "            self.conv = F.conv1d\n",
    "        elif dim == 2:\n",
    "            self.conv = F.conv2d\n",
    "        elif dim == 3:\n",
    "            self.conv = F.conv3d\n",
    "        else:\n",
    "            raise RuntimeError(\n",
    "                'Only 1, 2 and 3 dimensions are supported. Received {}.'.format(dim)\n",
    "            )\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Apply gaussian filter to input.\n",
    "        Arguments:\n",
    "            input (torch.Tensor): Input to apply gaussian filter on.\n",
    "        Returns:\n",
    "            filtered (torch.Tensor): Filtered output.\n",
    "        \"\"\"\n",
    "        return self.conv(input, weight=self.weight, groups=self.groups)\n",
    "    \n",
    "    \n",
    "class Blur(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.smoothing = GaussianSmoothing(1, 5, 1)\n",
    "        self.pad = nn.ReflectionPad2d(2)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return self.smoothing(self.pad(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = charbonnier_loss\n",
    "#loss = F.mse_loss\n",
    "scale=4\n",
    "model = DBPNLL(num_channels=1, base_filter=8, feat = 256, num_stages=10, scale_factor=scale)\n",
    "#model = nn.Sequential(model, Blur())\n",
    "\n",
    "#model = DBPNLL(num_channels=1, base_filter=16, feat = 256, num_stages=10, scale_factor=scale)\n",
    "model = nn.DataParallel(model, [0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz_lr = 64\n",
    "scale,bs = 4,16\n",
    "sz_hr = sz_lr*scale\n",
    "\n",
    "learn = build_learner(model, bs, sz_lr, sz_hr, src, loss=loss, model_dir=path_models) #, callback_fns=LossMetrics)\n",
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz_lr = 64\n",
    "scale,bs = 4,16\n",
    "sz_hr = sz_lr*scale\n",
    "epochs, lr = 5, 1e-3\n",
    "learn = batch_learn(model, bs, sz_lr, sz_hr, lr, epochs, src, \n",
    "                    save='combo_1.0_small', \n",
    "                    loss=loss, model_dir=path_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz_lr = 96\n",
    "scale,bs = 4,16\n",
    "sz_hr = sz_lr*scale\n",
    "\n",
    "epochs, lr = 5, 5e-4\n",
    "learn = batch_learn(model, bs, sz_lr, sz_hr, lr, epochs, src, model_dir=path_models,\n",
    "                    load='combo_1.0_small', save='combo_1.1_small', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz_lr = 128\n",
    "scale,bs = 4,8\n",
    "sz_hr = sz_lr*scale\n",
    "\n",
    "epochs, lr = 5, 2e-4\n",
    "learn = batch_learn(model, bs, sz_lr, sz_hr, lr, epochs, src, model_dir=path_models,\n",
    "                    load='combo_1.1_small', save='combo_1.2_small', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz_lr = 256\n",
    "scale,bs = 4,4\n",
    "sz_hr = sz_lr*scale\n",
    "\n",
    "epochs, lr = 5, 1e-4\n",
    "learn = batch_learn(model, bs, sz_lr, sz_hr, lr, epochs, src, model_dir=path_models,\n",
    "                    load='combo_1.2_small', save='combo_1.3_small', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_pred(self, item:ItemBase, **kwargs):\n",
    "    self.callbacks.append(RecordOnCPU())\n",
    "    batch = self.data.one_item(item)\n",
    "    batch = to_half(batch)\n",
    "    res = self.pred_batch(batch=batch)\n",
    "    pred = res[0]\n",
    "    x = self.callbacks[-1].input\n",
    "    x = x.float()\n",
    "    pred = pred.float()\n",
    "    norm = getattr(self.data,'norm',False)\n",
    "    if norm:\n",
    "        x = self.data.denorm(x)\n",
    "        if norm.keywords.get('do_y',False): pred = self.data.denorm(pred)\n",
    "    self.callbacks = self.callbacks[:-1]\n",
    "    ds = self.data.single_ds\n",
    "    pred = ds.y.analyze_pred(pred, **kwargs)\n",
    "    out = ds.y.reconstruct(pred, ds.x.reconstruct(x[0])) if has_arg(ds.y.reconstruct, 'x') else ds.y.reconstruct(pred)\n",
    "    return out, pred, res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = charbonnier_loss\n",
    "# scale=4\n",
    "# n_resblocks=128\n",
    "# n_feats=32\n",
    "# res_scale= 0.1\n",
    "# model = WDSR(scale, n_resblocks, n_feats, res_scale, n_colors_in=1)\n",
    "\n",
    "test_fns = list(path_test_lr.iterdir())\n",
    "lil = []\n",
    "big = []\n",
    "for fn in test_fns:\n",
    "    learn = None\n",
    "    gc.collect()\n",
    "    img = open_grayscale(fn)\n",
    "    \n",
    "    scale,bs = 4,4\n",
    "    sz_lr = max(img.shape)\n",
    "    sz_lr = min(int(sz_lr), 400)\n",
    "    sz_hr = sz_lr*scale\n",
    "    print(sz_lr, sz_hr)\n",
    "    data = get_data(src, bs, sz_lr, sz_hr)\n",
    "    learn = Learner(data, model, loss_func=F.mse_loss, model_dir=path_models).to_fp16().load('combo_1.0_small_best')\n",
    "    a,b,c = my_pred(learn, img)\n",
    "    img_big = Image(a.data[0:1,:,:])\n",
    "    lr_fn = Path(fn.stem + '_LR.png')\n",
    "    img.save(lr_fn)\n",
    "    hr_fn = Path(fn.stem + '_HR.png')\n",
    "    img_big.save(hr_fn)\n",
    "    lil.append(img)\n",
    "    big.append(img_big)\n",
    "    print(lr_fn, hr_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=3\n",
    "l,b = lil[idx], big[idx]\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
