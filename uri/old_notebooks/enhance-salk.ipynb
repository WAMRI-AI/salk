{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai import *          # Quick access to most common functionality\n",
    "from fastai.vision import *   # Quick access to computer vision functionality\n",
    "import PIL\n",
    "import pytorch_ssim as ssim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/DATA/WAMRI/SALK/uri/Image_restoration_data/')\n",
    "train_lr = path/'train_LR'\n",
    "train_hr = path/'train_HR'\n",
    "test_lr = path/'test_LR'\n",
    "test_hr = path/'test_HR'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_id(fn):\n",
    "    return fn.split('#')[-1].split('.')[0]\n",
    "\n",
    "\n",
    "lr_names_full = list(train_lr.glob('*.tif'))\n",
    "hr_names_by_id = {pull_id(hrfn.name):hrfn for hrfn in train_hr.glob('*.tif')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageFileList' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ea0e3daf1a18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvalid_pct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m src = (ImageFileList\n\u001b[0m\u001b[1;32m      7\u001b[0m       \u001b[0;34m.\u001b[0m\u001b[0mfrom_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_names_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0;34m.\u001b[0m\u001b[0mlabel_from_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhr_names_by_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpull_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ImageFileList' is not defined"
     ]
    }
   ],
   "source": [
    "def open_grayscale(fn):\n",
    "    x = PIL.Image.open(fn)\n",
    "    return Image(pil2tensor(x,np.float32).div_(255)[0:1])        \n",
    "\n",
    "valid_pct = 0.10\n",
    "src = (ImageFileList\n",
    "      .from_df(pd.DataFrame(lr_names_full), 0)\n",
    "      .label_from_func(lambda x: hr_names_by_id[pull_id(x.name)])\n",
    "      .random_split_by_pct(valid_pct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageToImageDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a5ad174f3153>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mGrayImageToImageDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImageToImageDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFilePathList\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFilePathList\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_opener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen_grayscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ImageToImageDataset' is not defined"
     ]
    }
   ],
   "source": [
    "class GrayImageToImageDataset(ImageToImageDataset):\n",
    "    def __init__(self, x:FilePathList=[], y:FilePathList=[], **kwargs):\n",
    "        super().__init__(x=x,y=y,**kwargs)\n",
    "        self.image_opener = open_grayscale\n",
    "\n",
    "def get_sr_transforms():\n",
    "    res = []\n",
    "    res.append(dihedral_affine(p=0.5))\n",
    "    return (res, [])\n",
    "\n",
    "\n",
    "def get_data(src, bs, sz_lr, scale=4, tfms=None, **kwargs):\n",
    "    sz_hr = sz_lr*scale\n",
    "    salk_stats = ( [0.10], [0.20])\n",
    "    if tfms is None: tfms = get_transforms() \n",
    "    data = (src.datasets(GrayImageToImageDataset)\n",
    "            #.transform(get_sr_transforms(), y_kwargs={'size': sz_hr}, size=sz_lr, tfm_y=True)\n",
    "            .transform(tfms, y_kwargs={'size': sz_hr}, size=sz_lr, tfm_y=True)\n",
    "            .databunch(bs=bs, **kwargs) #, num_workers=0)\n",
    "            .normalize(salk_stats, tfm_y=True)\n",
    "           )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(ni, nf, kernel_size=3, actn=True):\n",
    "    layers = [nn.Conv2d(ni, nf, kernel_size, padding=kernel_size//2)]\n",
    "    if actn: layers.append(nn.ReLU(True))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResSequential(nn.Module):\n",
    "    def __init__(self, layers, res_scale=1.0):\n",
    "        super().__init__()\n",
    "        self.res_scale = res_scale\n",
    "        self.m = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.m(x) * self.res_scale\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_block(nf):\n",
    "    return ResSequential(\n",
    "        [conv(nf, nf), conv(nf, nf, actn=False)],\n",
    "        0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(ni, nf, scale):\n",
    "    layers = []\n",
    "    for i in range(int(math.log(scale,2))):\n",
    "        layers += [conv(ni, nf*4), nn.PixelShuffle(2)]\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SrResnet(nn.Module):\n",
    "    def __init__(self, n_feats, n_res, n_colors, scale ):\n",
    "        super().__init__()\n",
    "        features = [conv(n_colors, n_feats)]\n",
    "        for i in range(n_res): features.append(res_block(n_feats))\n",
    "        features += [conv(n_feats,n_feats), upsample(n_feats, n_feats, scale),\n",
    "                     nn.BatchNorm2d(n_feats),\n",
    "                     conv(n_feats, n_colors, actn=False)]\n",
    "        self.features = nn.Sequential(*features)\n",
    "        \n",
    "    def forward(self, x): return self.features(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr(pred, targs):\n",
    "    mse = F.mse_loss(pred, targs)\n",
    "    return 20 * torch.log10(1./torch.sqrt(mse))\n",
    "\n",
    "def psnr_loss(pred, targs):\n",
    "    mse = F.mse_loss(pred, targs)\n",
    "    return -20 * torch.log10(1./torch.sqrt(mse))\n",
    "\n",
    "ssim_loss = ssim.SSIM(mult=-1.)\n",
    "ssim_loss_2 = ssim.SSIM(window_size=3, mult=-1.)\n",
    "ssim_loss_3 = ssim.SSIM(window_size=32, mult=-1.)\n",
    "\n",
    "def combo_loss(pred, targs):\n",
    "    return (3 + \n",
    "            ssim_loss(pred, targs) + \n",
    "            ssim_loss_2(pred, targs) + \n",
    "            ssim_loss_3(pred, targs) + \n",
    "            F.mse_loss(pred, targs)\n",
    "           )\n",
    "    #return ssim_loss(pred, targs) + psnr_loss(pred, targs)/50. # + F.l1_loss(pred, targs)\n",
    "    \n",
    "metrics = [F.mse_loss, \n",
    "           ssim.ssim,\n",
    "           partial(ssim.ssim, window_size=3),\n",
    "           partial(ssim.ssim, window_size=32),\n",
    "           psnr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 16\n",
    "lr_sz = 32\n",
    "scale=4\n",
    "data = get_data(src, bs, lr_sz, scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(data.valid_dl))\n",
    "x.shape, y.shape\n",
    "#data.show_batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feats = 8\n",
    "n_res = 64\n",
    "n_color = 1\n",
    "# 64,4,1\n",
    "model = SrResnet(n_feats, n_res, n_color, scale)\n",
    "model = nn.DataParallel(model).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ImageLearner(data, model, loss_func=combo_loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ImageLearner(data, model, loss_func=combo_loss, metrics=metrics)\n",
    "lr = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('enhance1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('enhance1')\n",
    "learn.fit_one_cycle(5, lr/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('enhance1.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 16\n",
    "lr_sz = 32*2\n",
    "scale=4\n",
    "data = get_data(src, bs, lr_sz, scale=scale)\n",
    "learn = ImageLearner(data, model, loss_func=combo_loss, metrics=metrics)\n",
    "learn = learn.load('enhance1.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "learn.fit_one_cycle(10, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('enhance2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 8\n",
    "lr_sz = 32*2*2\n",
    "scale=4\n",
    "data = get_data(src, bs, lr_sz, scale=scale)\n",
    "learn = ImageLearner(data, model, loss_func=combo_loss, metrics=metrics)\n",
    "learn = learn.load('enhance2')\n",
    "lr = 1e-2\n",
    "learn.fit_one_cycle(10, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('enhance3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 8\n",
    "lr_sz = 503\n",
    "scale=4\n",
    "data = get_data(src, bs, lr_sz, scale=scale)\n",
    "learn = ImageLearner(data, model, loss_func=combo_loss, metrics=metrics)\n",
    "learn = learn.load('enhance1')\n",
    "\n",
    "#lr = 1e-3\n",
    "#learn.fit_one_cycle(1, lr)\n",
    "\n",
    "idx = 0\n",
    "m_bilin = partial(nn.functional.interpolate, scale_factor=4, mode='bilinear', align_corners=True)\n",
    "y_preds, ys = learn.get_preds(DatasetType.Valid)\n",
    "y_pred = y_preds[idx]\n",
    "y = ys[idx]\n",
    "\n",
    "#x,y = dl.dataset[idx]\n",
    "#xn, yn = learn.data.norm((x.data,y.data))\n",
    "#pred = dl.reconstruct_output(preds[idx], x)\n",
    "#if learn.data.denorm and learn.data.tfm_y and isinstance(pred, Image):\n",
    "#    pred = Image(learn.data.denorm(pred.data[0]))\n",
    "#pred_bilin = Image(learn.data.denorm(m_bilin(xn[None]))[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_denorm = y_pred.mul(0.20) + tensor(0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(y_denorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image(pred_bilin.data[0][None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = pred_bilin.data[None], y.data[None]\n",
    "ssim.ssim(*imgs),psnr(*imgs), F.mse_loss(*imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = pred.data[None], y.data[None]\n",
    "ssim.ssim(*imgs),psnr(*imgs), F.mse_loss(*imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lr_fns = list((path/'newman').glob('*.tif'))\n",
    "test_hr_fns = list((path/'newman').glob('*.tif'))\n",
    "test_lr_fns.sort()\n",
    "test_hr_fns.sort()\n",
    "bs = 3\n",
    "lr_sz = 512\n",
    "scale=4\n",
    "test_lr_fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_name = { lr.name:hr for lr,hr in zip(test_lr_fns, test_hr_fns)}\n",
    "\n",
    "test_src = (ImageFileList\n",
    "            .from_df(pd.DataFrame(test_lr_fns), 0)\n",
    "            .label_from_func(lambda x: hr_name[x.name])\n",
    "            .split_by_valid_func(lambda x: False))\n",
    "\n",
    "test_data = get_data(test_src, bs, lr_sz, scale=scale, tfms=[[crop_pad()],[crop_pad()]], shuffle=False)\n",
    "test_learn = ImageLearner(test_data, model, loss_func=combo_loss, metrics=metrics)\n",
    "test_learn = test_learn.load('enhance3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_denorm(xn):\n",
    "    salk_stats = ( [0.10], [0.20])\n",
    "    return xn * tensor(salk_stats[1][0]) - tensor(salk_stats[0][0])\n",
    "\n",
    "x,y = next(iter(test_learn.data.train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdn = my_denorm(x).detach()\n",
    "ydn = my_denorm(y).detach()\n",
    "y_pred = test_learn.model(x)\n",
    "y_pred_dn = my_denorm(y_pred).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_learn.data.denorm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_imgs = []\n",
    "for i in range(y_pred_dn.shape[0]):\n",
    "    x_img = Image(xdn[i]*255)\n",
    "    y_img = Image(ydn[i]*255)\n",
    "    y_pred_img = Image(y_pred_dn[i])\n",
    "    pred_imgs.append((x_img, y_img, y_pred_img))\n",
    "    print(i)\n",
    "    x_img.save(f'gen_tiffs/{i+1}_x.tif')\n",
    "    y_img.save(f'gen_tiffs/{i+1}_y.tif')\n",
    "    y_pred_img.save(f'gen_tiffs/{i+1}_sr.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img.data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_imgs[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2\n",
    "x,y = test_learn.data.train_ds[idx]\n",
    "xn, yn = test_learn.data.norm((x.data,y.data))\n",
    "test_pred = test_dl.reconstruct_output(test_preds[idx], x)\n",
    "if test_learn.data.denorm and test_learn.data.tfm_y and isinstance(test_pred, Image):\n",
    "    test_pred = Image(test_learn.data.denorm(test_pred.data[0]))\n",
    "m_bilin = partial(nn.functional.interpolate, scale_factor=4, mode='bilinear', align_corners=True)\n",
    "test_pred_bilin = Image(test_learn.data.denorm(m_bilin(xn[None]))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(test_pred.data[0][None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(test_pred_bilin.data[0][None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = test_pred.data[None], y.data[None]\n",
    "ssim.ssim(*imgs),psnr(*imgs), F.mse_loss(*imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = test_pred_bilin.data[None], y.data[None]\n",
    "ssim.ssim(*imgs),psnr(*imgs), F.mse_loss(*imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.save('lr_orig.tif')\n",
    "y.save('hr_orig.tif')\n",
    "Image(pred_bilin.data[0][None]).save('bilin.tif')\n",
    "Image(pred.data[0][None]).save('resnet.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "503*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
