{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai import *          # Quick access to most common functionality\n",
    "from fastai.vision import *   # Quick access to computer vision functionality\n",
    "import PIL\n",
    "import shutil\n",
    "from fastprogress import progress_bar, master_bar\n",
    "import pytorch_ssim as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/DATA/WAMRI/SALK/uri/Image_restoration_data/')\n",
    "train_lr = path/'train_LR'\n",
    "train_hr = path/'train_HR'\n",
    "test_lr = path/'test_LR'\n",
    "test_hr = path/'test_HR'\n",
    "\n",
    "train_lr_patches = path/'train_LR_patch'\n",
    "train_hr_patches = path/'train_HR_patch'\n",
    "train_lr_cropped = path/'train_LR_crop'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_id(fn):\n",
    "    return fn.split('#')[-1].split('.')[0]\n",
    "\n",
    "def open_grayscale(fn):\n",
    "    x = PIL.Image.open(fn).convert('L')\n",
    "    return Image(pil2tensor(x,np.float32).div_(255))        \n",
    "\n",
    "def build_cropped(src_path, dst_path, crop_size, force=False):\n",
    "    if not dst_path.exists() or force:\n",
    "        shutil.rmtree(dst_path, ignore_errors=True)\n",
    "        dst_path.mkdir()\n",
    "        fns = list(src_path.glob('*.tif'))\n",
    "        for fn in fns:\n",
    "            img = open_grayscale(fn)\n",
    "            img = crop(img, crop_size)\n",
    "            img.save(dst_path/fn.name)\n",
    "            \n",
    "def build_patches(src_path, dst_path, scale, force=False, crop_size=None):\n",
    "    if not dst_path.exists() or force:\n",
    "        shutil.rmtree(dst_path, ignore_errors=True)\n",
    "        dst_path.mkdir()\n",
    "        fns = list(src_path.glob('*.tif'))\n",
    "        for fn in master_bar(fns):\n",
    "            img_id = pull_id(fn.name)\n",
    "            img = open_grayscale(fn)\n",
    "            if not crop_size is None:\n",
    "                img = crop(img, crop_size)\n",
    "            c, h, w = img.shape\n",
    "            patch_h = h // scale\n",
    "            patch_w = w // scale\n",
    "            for row in range(8):\n",
    "                for col in range(8):\n",
    "                    r_start = row*patch_h\n",
    "                    r_end = r_start + patch_h\n",
    "                    c_start = col*patch_w\n",
    "                    c_end = c_start + patch_w\n",
    "                    patch = img.data[:, r_start:r_end, c_start:c_end]\n",
    "                    patch_fn = f'{img_id}_{row}_{col}.tif'\n",
    "                    Image(patch).save(dst_path/patch_fn)\n",
    "                    \n",
    "build_patches(train_lr, train_lr_patches, 8, crop_size=(506,506))\n",
    "build_patches(train_hr, train_hr_patches, 8, crop_size=(2016,2016))\n",
    "build_cropped(train_lr, train_lr_cropped, crop_size=(506,506))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRtoHRDataset(DatasetBase):\n",
    "    def __init__(self, xfns:FilePathList, yfns:FilePathList, id_fn = pull_id):\n",
    "        self.x = {id_fn(xfn.name):xfn for xfn in xfns}\n",
    "        self.y = {id_fn(yfn.name):yfn for yfn in yfns}\n",
    "        self.ids = list(self.x.keys())\n",
    "        self.ids.sort()\n",
    "    \n",
    "    def __getitem__(self, i:int)->[Image, Image]:\n",
    "        fnID = self.ids[i]\n",
    "        x_fn = self.x[fnID]\n",
    "        y_fn = self.y[fnID]\n",
    "        ximg = open_grayscale(x_fn)\n",
    "        yimg = open_grayscale(y_fn)\n",
    "        return ximg, yimg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    lr_names_full = list(train_lr_cropped.glob('*.tif'))\n",
    "    valid_pct = 0.10\n",
    "    train_fns, valid_fns = random_split(valid_pct, lr_names_full)\n",
    "    train_fns = train_fns[0]\n",
    "    valid_fns = valid_fns[0]\n",
    "    hr_fns = list(train_hr.glob('*.tif'))\n",
    "\n",
    "    train_ds = LRtoHRDataset(train_fns, hr_fns)\n",
    "    valid_ds = LRtoHRDataset(valid_fns, hr_fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_names_full = list(train_lr_patches.glob('*.tif'))\n",
    "valid_pct = 0.10\n",
    "train_fns, valid_fns = random_split(valid_pct, lr_names_full)\n",
    "train_fns = train_fns[0]\n",
    "valid_fns = valid_fns[0]\n",
    "hr_fns = list(train_hr_patches.glob('*.tif'))\n",
    "\n",
    "train_ds = LRtoHRDataset(train_fns, hr_fns, id_fn= lambda x: x)\n",
    "valid_ds = LRtoHRDataset(valid_fns, hr_fns, id_fn= lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 256\n",
    "\n",
    "def get_sr_transforms():\n",
    "    res = []\n",
    "    res.append(dihedral_affine())\n",
    "    return (res, [])\n",
    "\n",
    "train_tfms,valid_tfms = get_sr_transforms()\n",
    "train_tds = DatasetTfm(train_ds, train_tfms, tfm_y=True)\n",
    "valid_tds = DatasetTfm(valid_ds, valid_tfms, tfm_y=True)\n",
    "data = ImageDataBunch.create(train_tds, valid_tds, bs=bs, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(train_ds[0][0]), show_image(train_ds[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, conv, n_feats, kernel_size,\n",
    "        bias=True, bn=False, act=nn.ReLU(True), res_scale=1):\n",
    "\n",
    "        super(ResBlock, self).__init__()\n",
    "        m = []\n",
    "        for i in range(2):\n",
    "            m.append(conv(n_feats, n_feats, kernel_size, bias=bias))\n",
    "            if bn: m.append(nn.BatchNorm2d(n_feats))\n",
    "            if i == 0: m.append(act)\n",
    "\n",
    "        self.body = nn.Sequential(*m)\n",
    "        self.res_scale = res_scale\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.body(x).mul(self.res_scale)\n",
    "        res += x\n",
    "        return res\n",
    "    \n",
    "class Upsampler(nn.Sequential):\n",
    "    def __init__(self, conv, scale, n_feats, bn=False, act=False, bias=True):\n",
    "\n",
    "        m = []\n",
    "        if (scale & (scale - 1)) == 0:    # Is scale = 2^n?\n",
    "            for _ in range(int(math.log(scale, 2))):\n",
    "                m.append(conv(n_feats, 4 * n_feats, 3, bias))\n",
    "                m.append(nn.PixelShuffle(2))\n",
    "                if bn: m.append(nn.BatchNorm2d(n_feats))\n",
    "\n",
    "                if act == 'relu':\n",
    "                    m.append(nn.ReLU(True))\n",
    "                elif act == 'prelu':\n",
    "                    m.append(nn.PReLU(n_feats))\n",
    "\n",
    "        elif scale == 3:\n",
    "            m.append(conv(n_feats, 9 * n_feats, 3, bias))\n",
    "            m.append(nn.PixelShuffle(3))\n",
    "            if bn: m.append(nn.BatchNorm2d(n_feats))\n",
    "\n",
    "            if act == 'relu':\n",
    "                m.append(nn.ReLU(True))\n",
    "            elif act == 'prelu':\n",
    "                m.append(nn.PReLU(n_feats))\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        super(Upsampler, self).__init__(*m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feats = 64\n",
    "kernel_size =3\n",
    "n_colors = 1\n",
    "res_scale = 1\n",
    "act = 'relu'\n",
    "n_resblocks = 32 #16\n",
    "\n",
    "def conv(in_channels, out_channels, kernel_size, bias=True):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size,\n",
    "                     padding=(kernel_size//2), bias=bias)\n",
    "\n",
    "\n",
    "def head():\n",
    "    return [conv(1, n_feats, kernel_size)]\n",
    "\n",
    "def body():\n",
    "    body_layers = [\n",
    "        ResBlock(conv, n_feats, kernel_size, res_scale=res_scale) \n",
    "        for _ in range(n_resblocks)\n",
    "    ]\n",
    "    body_layers.append(conv(n_feats, n_feats, kernel_size))\n",
    "    return body_layers\n",
    "\n",
    "def tail(scale):\n",
    "    layers = [\n",
    "            Upsampler(conv, scale, n_feats, act=False),\n",
    "            conv(n_feats, n_colors, kernel_size)\n",
    "    ]\n",
    "    return layers\n",
    "\n",
    "class EDSR(nn.Module):\n",
    "    def __init__(self, scale):\n",
    "        super(EDSR,self).__init__()\n",
    "        self.head = nn.Sequential(*head())\n",
    "        self.body = nn.Sequential(*body())\n",
    "        self.tail = nn.Sequential(*tail(scale))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.head(x)\n",
    "        res = self.body(x)\n",
    "        res += x\n",
    "        x = self.tail(res)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.DataParallel(EDSR(4)).cuda()\n",
    "#model = EDSR(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr(pred, targs):\n",
    "    mse = F.mse_loss(pred, targs)\n",
    "    return 20 * torch.log10(1./torch.sqrt(mse))\n",
    "\n",
    "def psnr_loss(pred, targs):\n",
    "    mse = F.mse_loss(pred, targs)\n",
    "    return -20 * torch.log10(1./torch.sqrt(mse))\n",
    "\n",
    "ssim_loss = ssim.SSIM(mult=-1.)\n",
    "\n",
    "def combo_loss(pred, targs):\n",
    "    return ssim_loss(pred, targs) + psnr_loss(pred, targs)/50. # + F.l1_loss(pred, targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=[psnr, ssim.ssim, F.l1_loss, F.mse_loss]\n",
    "learn = Learner(data, model, loss_func=combo_loss, metrics=metrics)#.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(50,lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('esdr_combo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('esdr_combo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(50,lr/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('esdr_combo2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('esdr_combo2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=3e-5\n",
    "learn.fit_one_cycle(50,lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('esdr_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx, by = next(iter(data.train_dl))\n",
    "ypred = model(bx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgdata = ypred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = imgdata.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image(imgdata.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(by[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(bx[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilinear = nn.UpsamplingBilinear2d(scale_factor=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blin_y = bilinear(bx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(blin_y, by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(blin_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_blin = partial(nn.functional.interpolate, scale_factor=4, mode='bilinear', align_corners=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_to_hr(lr_fn, model, patch=63, crop_size=(506,506)):\n",
    "    lr_img = open_grayscale(lr_fn)\n",
    "    #print(lr_img.shape)\n",
    "    lr_crop = crop(lr_img, crop_size)\n",
    "    hr_patches = []\n",
    "    hr_image = torch.zeros((1,8*patch*4,8*patch*4))\n",
    "    for row in range(8):\n",
    "        for col in range(8):\n",
    "            hr_patch_size = patch*4\n",
    "            \n",
    "            r_start = row*patch\n",
    "            r_end = r_start + patch\n",
    "            c_start = col*patch\n",
    "            c_end = c_start + patch\n",
    "            \n",
    "            img_patch = lr_img.data[:,r_start:r_end,c_start:c_end]\n",
    "            #print(r_start,r_end,c_start,c_end,img_patch.shape)\n",
    "            img_t = tensor(img_patch)\n",
    "            hr_img_t = model(img_t[None])\n",
    "            hr_patches.append(hr_img_t[0])\n",
    "    \n",
    "    for row in range(8):\n",
    "        for col in range(8):\n",
    "            hr_patch_size = patch*4\n",
    "            r_start = row*hr_patch_size\n",
    "            r_end = r_start + hr_patch_size\n",
    "            c_start = col*hr_patch_size\n",
    "            c_end = c_start + hr_patch_size\n",
    "            hr_image[0,r_start:r_end,c_start:c_end] = hr_patches[row*8 + col]\n",
    "    return hr_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_names = list(test_lr.glob('*#01*.tif'))\n",
    "hr_image = lr_to_hr(lr_names[0], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(hr_image.detach())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = open_grayscale(list(test_hr.glob('*1_3*.tif'))[0])\n",
    "gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilin_image = lr_to_hr(lr_names[0], m_blin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(bilin_image.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = (bilin_image + hr_image)/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(final.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ssim.ssim(hr_image.detach()[None], crop(gt,(2016,2016)).data[None]),\n",
    "psnr(hr_image.detach()[None], crop(gt,(2016,2016)).data[None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ssim.ssim(bilin_image.detach()[None], crop(gt,(2016,2016)).data[None]),\n",
    "psnr(bilin_image.detach()[None], crop(gt,(2016,2016)).data[None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ssim.ssim(final.detach()[None], crop(gt,(2016,2016)).data[None]),\n",
    "psnr(final.detach()[None], crop(gt,(2016,2016)).data[None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
