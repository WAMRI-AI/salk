{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from torchvision.models import vgg16_bn\n",
    "import PIL\n",
    "import imageio\n",
    "from superres import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Path('/scratch/bpho/datasets/paired_001/')\n",
    "model_path = Path('/scratch/bpho/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_src():\n",
    "    hr_tifs = data/'hr'\n",
    "    lr_tifs = data/'lr_up'\n",
    "\n",
    "    def map_to_hr(x):\n",
    "        hr_name = x.relative_to(lr_tifs)\n",
    "        return hr_tifs/hr_name\n",
    "    \n",
    "    src = (ImageImageList\n",
    "            .from_folder(lr_tifs)\n",
    "            .split_by_folder()\n",
    "            .label_from_func(map_to_hr))\n",
    "    return src\n",
    "\n",
    "def _gaussian_noise_gray(x, gauss_sigma=1.):\n",
    "    c,h,w = x.shape\n",
    "    noise = torch.zeros((1,h,w))\n",
    "    noise.normal_(0, gauss_sigma)\n",
    "    img_max = np.minimum(1.1 * x.max(), 1.)\n",
    "    x = np.minimum(np.maximum(0,x+noise.repeat((3,1,1))), img_max)\n",
    "    return x\n",
    "\n",
    "gaussian_noise_gray = TfmPixel(_gaussian_noise_gray)\n",
    "\n",
    "\n",
    "def get_data(bs, size, noise=0.15):\n",
    "    src = get_src()\n",
    "    \n",
    "    tfms = [[rand_crop(size=size)],[]]\n",
    "    tfms = get_transforms(flip_vert=True, max_zoom=2)\n",
    "    y_tfms = [[t for t in tfms[0]], [t for t in tfms[1]]]\n",
    "    #tfms[0].append(gaussian_noise_gray(gauss_sigma=noise))\n",
    "    data = (src\n",
    "            .transform(tfms, size=size)\n",
    "            .transform_y(y_tfms, size=size)\n",
    "            .databunch(bs=bs).normalize(imagenet_stats, do_y=True))\n",
    "    data.c = 3\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    n,c,h,w = x.size()\n",
    "    x = x.view(n, c, -1)\n",
    "    return (x @ x.transpose(1,2))/(c*h*w)\n",
    "\n",
    "vgg_m = vgg16_bn(True).features.cuda().eval()\n",
    "requires_grad(vgg_m, False)\n",
    "blocks = [i-1 for i,o in enumerate(children(vgg_m)) if isinstance(o,nn.MaxPool2d)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_loss = F.l1_loss\n",
    "\n",
    "class FeatureLoss(nn.Module):\n",
    "    def __init__(self, m_feat, layer_ids, layer_wgts):\n",
    "        super().__init__()\n",
    "        self.m_feat = m_feat\n",
    "        self.loss_features = [self.m_feat[i] for i in layer_ids]\n",
    "        self.hooks = hook_outputs(self.loss_features, detach=False)\n",
    "        self.wgts = layer_wgts\n",
    "        self.metric_names = ['pixel',] + [f'feat_{i}' for i in range(len(layer_ids))\n",
    "              ] + [f'gram_{i}' for i in range(len(layer_ids))]\n",
    "\n",
    "    def make_features(self, x, clone=False):\n",
    "        self.m_feat(x)\n",
    "        return [(o.clone() if clone else o) for o in self.hooks.stored]\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        out_feat = self.make_features(target, clone=True)\n",
    "        in_feat = self.make_features(input)\n",
    "        self.feat_losses = [base_loss(input,target)]\n",
    "        self.feat_losses += [base_loss(f_in, f_out)*w\n",
    "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
    "        self.feat_losses += [base_loss(gram_matrix(f_in), gram_matrix(f_out))*w**2 * 5e3\n",
    "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
    "        self.metrics = dict(zip(self.metric_names, self.feat_losses))\n",
    "        return sum(self.feat_losses)\n",
    "    \n",
    "    def __del__(self): self.hooks.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_loss = FeatureLoss(vgg_m, blocks[2:5], [5,15,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "size = 128\n",
    "data = get_data(bs, size)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1\n",
    "size = 1920\n",
    "data = get_data(bs, size)\n",
    "data\n",
    "\n",
    "arch = models.resnet34\n",
    "wd = 1e-3\n",
    "learn = unet_learner(data, arch, wd=wd, loss_func=feat_loss, metrics=superres_metrics, \n",
    "                     callback_fns=LossMetrics, blur=True, norm_type=NormType.Weight, model_dir=model_path)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_fit(save_name, lrs=slice(lr), pct_start=0.9, cycle_len=10):\n",
    "    learn.fit_one_cycle(cycle_len, lrs, pct_start=pct_start)\n",
    "    learn.save(save_name)\n",
    "    learn.show_results(rows=3, imgsize=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit('movies_002_unet.0', slice(lr*10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit('movies_002_unet.1', slice(1e-5,lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1\n",
    "size = 1920\n",
    "data = get_data(bs, size)\n",
    "\n",
    "arch = models.resnet34\n",
    "wd = 1e-3\n",
    "learn = unet_learner(data, arch, wd=wd, loss_func=feat_loss, metrics=superres_metrics, \n",
    "                     callback_fns=LossMetrics, blur=True, norm_type=NormType.Weight, model_dir=model_path)\n",
    "gc.collect()\n",
    "\n",
    "learn = learn.load('movies_002_unet.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_fit('movies_002_unet.2', lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit('movies_002_unet.3', slice(1e-5,lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 4\n",
    "size = 512\n",
    "data = get_data(bs, size)\n",
    "\n",
    "arch = models.resnet34\n",
    "wd = 1e-3\n",
    "learn = unet_learner(data, arch, wd=wd, loss_func=feat_loss, metrics=superres_metrics, \n",
    "                     callback_fns=LossMetrics, blur=True, norm_type=NormType.Weight, model_dir=model_path)\n",
    "gc.collect()\n",
    "\n",
    "learn = learn.load('movies_002_unet.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_fit('movies_002_unet.4', lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit('movies_002_unet.5', slice(1e-5,lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /scratch/bpho/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_files = list((movie_data/'test').glob('*.czi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = movie_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with czifile.CziFile(fn) as czi_f:\n",
    "    proc_axes, proc_shape = get_czi_shape_info(czi_f)\n",
    "    channels = proc_shape['C']\n",
    "    depths = proc_shape['Z']\n",
    "    times = proc_shape['T']\n",
    "    x,y = proc_shape['X'], proc_shape['Y']\n",
    "    data = czi_f.asarray()\n",
    "    preds = []\n",
    "    origs = []\n",
    "    idx = build_index(proc_axes, {'T': 0, 'C': 0, 'Z':0, 'X':slice(0,x),'Y':slice(0,y)})\n",
    "    img = data[idx].astype(np.float32)\n",
    "    img /= (img.max() * 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_from_tiles(learn, img, tile_sz=128, scale=4):\n",
    "    pimg = PIL.Image.fromarray((img*255).astype(np.uint8), mode='L').convert('RGB')\n",
    "    cur_size = pimg.size\n",
    "    new_size = (cur_size[0]*scale, cur_size[1]*scale)\n",
    "    in_img = Image(pil2tensor(pimg.resize(new_size, resample=PIL.Image.BICUBIC),np.float32).div_(255))\n",
    "    c, w, h = in_img.shape\n",
    "    \n",
    "    in_tile = torch.zeros((c,tile_sz,tile_sz))\n",
    "    out_img = torch.zeros((c,w,h))\n",
    "    \n",
    "    for x_tile in range(math.ceil(w/tile_sz)):\n",
    "        for y_tile in range(math.ceil(h/tile_sz)):\n",
    "            x_start = x_tile\n",
    "\n",
    "            x_start = x_tile*tile_sz\n",
    "            x_end = min(x_start+tile_sz, w)\n",
    "            y_start = y_tile*tile_sz\n",
    "            y_end = min(y_start+tile_sz, h)\n",
    "            \n",
    "            \n",
    "            in_tile[:,0:(x_end-x_start), 0:(y_end-y_start)] = in_img.data[:,x_start:x_end, y_start:y_end]\n",
    "            \n",
    "            out_tile,_,_ = learn.predict(Image(in_tile))\n",
    "\n",
    "            out_x_start = x_start\n",
    "            out_x_end = x_end\n",
    "            out_y_start = y_start\n",
    "            out_y_end = y_end\n",
    "\n",
    "            #print(\"out: \", out_x_start, out_y_start, \",\", out_x_end, out_y_end)\n",
    "            in_x_start = 0\n",
    "            in_y_start = 0\n",
    "            in_x_end = x_end-x_start\n",
    "            in_y_end = y_end-y_start\n",
    "            #print(\"tile: \",in_x_start, in_y_start, \",\", in_x_end, in_y_end)\n",
    "           \n",
    "            out_img[:,out_x_start:out_x_end, out_y_start:out_y_end] = out_tile.data[:,\n",
    "                                                                                  in_x_start:in_x_end, \n",
    "                                                                                  in_y_start:in_y_end]\n",
    "    return out_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def czi_predict_movie(learn, czi_in, orig_out='orig.tif', pred_out='pred.tif', size=128):\n",
    "    with czifile.CziFile(czi_in) as czi_f:\n",
    "        proc_axes, proc_shape = get_czi_shape_info(czi_f)\n",
    "        channels = proc_shape['C']\n",
    "        depths = proc_shape['Z']\n",
    "        times = proc_shape['T']\n",
    "        x,y = proc_shape['X'], proc_shape['Y']\n",
    "        data = czi_f.asarray()\n",
    "        preds = []\n",
    "        origs = []\n",
    "        img_max = None\n",
    "        for t in progress_bar(list(range(times))):\n",
    "            idx = build_index(proc_axes, {'T': t, 'C': 0, 'Z':0, 'X':slice(0,x),'Y':slice(0,y)})\n",
    "            img = data[idx].astype(np.float32)\n",
    "            if img_max is None: img_max = img.max() * 1.5\n",
    "            img /= img_max\n",
    "            out_img = image_from_tiles(learn, img, tile_sz=size).permute([1,2,0])\n",
    "            pred = (out_img[None]*255).cpu().numpy().astype(np.uint8)\n",
    "            preds.append(pred)\n",
    "            orig = (img[None]*255).astype(np.uint8)\n",
    "            origs.append(orig)\n",
    "\n",
    "        all_y = np.concatenate(preds)\n",
    "        #print(all_y.shape)\n",
    "        imageio.mimwrite(pred_out, all_y) #, fps=30, macro_block_size=None) # for mp4\n",
    "        all_y = np.concatenate(origs)\n",
    "        #print(all_y.shape)\n",
    "        imageio.mimwrite(orig_out, all_y) #, fps=30, macro_block_size=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=1\n",
    "size=920\n",
    "scale = 4\n",
    "\n",
    "data = get_data(bs, size)\n",
    "\n",
    "wd = 1e-3\n",
    "learn = unet_learner(data, arch, wd=wd, loss_func=feat_loss, \n",
    "                     callback_fns=LossMetrics, blur=True, norm_type=NormType.Weight, model_dir=model_path)\n",
    "gc.collect()\n",
    "learn = learn.load('movies_002_unet.5')\n",
    "\n",
    "for fn in movie_files:\n",
    "    pred_name = f'{fn.stem}_pred.tif'\n",
    "    orig_name = f'{fn.stem}_orig.tif'\n",
    "    czi_predict_movie(learn, fn, size=size, orig_out=orig_name, pred_out=pred_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
