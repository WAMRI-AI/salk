{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fredmonroe/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n"
     ]
    }
   ],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.distributed import *\n",
    "from fastai.vision.models.xresnet import *\n",
    "from fastai.vision.models.unet import DynamicUnet\n",
    "from bpho import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetname = 'combo_001'\n",
    "data_path = Path('.')\n",
    "datasets = data_path/'datasets'\n",
    "datasources = data_path/'data'\n",
    "dataset = datasets/datasetname\n",
    "\n",
    "test_files = dataset/'test'\n",
    "hr_tifs = dataset/'hr'\n",
    "lr_tifs = dataset/'lr'\n",
    "lr_up_tifs = dataset/'lr_up'\n",
    "\n",
    "mname = 'combo'\n",
    "model_dir = 'models'\n",
    "\n",
    "loss = F.mse_loss\n",
    "metrics = sr_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_src(x_data, y_data_):\n",
    "    def map_to_hr(x):\n",
    "        hr_name = x.relative_to(x_data)\n",
    "        return y_data_/hr_name\n",
    "    src = (ImageImageList\n",
    "            .from_folder(x_data, convert_mode='L')\n",
    "            .split_by_rand_pct()\n",
    "            .label_from_func(map_to_hr, convert_mode='L'))\n",
    "    return src\n",
    "\n",
    "\n",
    "def get_data(bs, size, x_data, y_data, max_zoom=1.1):\n",
    "    src = get_src(x_data, y_data)\n",
    "    tfms = get_transforms(flip_vert=True, max_zoom=max_zoom)\n",
    "    data = (src\n",
    "            .transform(tfms, size=size)\n",
    "            .transform_y(tfms, size=size)\n",
    "            .databunch(bs=bs))\n",
    "    data.c = 3\n",
    "    return data\n",
    "\n",
    "def do_fit(learn, save_name, lrs=slice(1e-3), pct_start=0.9, cycle_len=10):\n",
    "    learn.to_fp16().fit_one_cycle(cycle_len, lrs, pct_start=pct_start)\n",
    "    learn.save(save_name)\n",
    "    print(f'saved: {save_name}')\n",
    "    num_rows = min(learn.data.batch_size, 3)\n",
    "    learn.to_fp32().show_results(rows=num_rows, imgsize=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    learn.lr_find()\n",
    "    learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     8
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step = 0\n",
    "lr = 1e-3\n",
    "cycles = 2\n",
    "loss = F.mse_loss\n",
    "metrics = sr_metrics\n",
    "\n",
    "\n",
    "bs = 16\n",
    "size = 256\n",
    "max_zoom = 6\n",
    "arch = xresnet34\n",
    "\n",
    "data = get_data(bs, size, lr_up_tifs, hr_tifs, max_zoom=max_zoom)\n",
    "learn = xres_unet_learner(data, arch, loss_func=loss, metrics=metrics, model_dir=model_dir)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='2', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/2 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>ssim</th>\n",
       "      <th>psnr</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='109' class='' max='364', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      29.95% [109/364 01:34<03:40 0.0318]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "do_fit(learn, f'{mname}.{step:02d}', lrs=lr, cycle_len=cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 1\n",
    "lr = 1e-4\n",
    "cycles = 2\n",
    "loss = F.mse_loss\n",
    "metrics = sr_metrics\n",
    "\n",
    "\n",
    "bs = 8\n",
    "size = 512\n",
    "max_zoom = 4\n",
    "arch = xresnet34\n",
    "\n",
    "data = get_data(bs, size, lr_up_multi_tifs, hr_multi_tifs, max_zoom=max_zoom)\n",
    "learn = xres_unet_learner(data, arch, loss_func=loss, metrics=metrics, model_dir=model_dir)\n",
    "learn.load(f'{mname}.{(step-1):02d}')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit(learn, f'{mname}.{step:02d}', lrs=lr, cycle_len=cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 2\n",
    "lr = 1e-4\n",
    "cycles = 2\n",
    "loss = F.mse_loss\n",
    "metrics = sr_metrics\n",
    "\n",
    "\n",
    "bs = 2\n",
    "size = 1024\n",
    "max_zoom = 2\n",
    "arch = xresnet34\n",
    "\n",
    "data = get_data(bs, size, lr_up_multi_tifs, hr_multi_tifs, max_zoom=max_zoom)\n",
    "learn = xres_unet_learner(data, arch, loss_func=loss, metrics=metrics, model_dir=model_dir)\n",
    "learn.load(f'{mname}.{(step-1):02d}')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit(learn, f'{mname}.{step:02d}', lrs=lr, cycle_len=cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 1\n",
    "lr = 1e-3\n",
    "cycles = 3\n",
    "\n",
    "bs = 20\n",
    "size = 256\n",
    "max_zoom = 8\n",
    "arch = xresnet34\n",
    "\n",
    "data = get_data(bs, size, hr_tifs, lr_up_tifs, max_zoom=max_zoom)\n",
    "learn = xres_unet_learner(data, arch, loss_func=loss, metrics=metrics, model_dir=model_dir)\n",
    "gc.collect()\n",
    "\n",
    "if Path(f'{mname}.{(step-1):02d}').exists(): \n",
    "    print('loading', f'{mname}.{(step-1):02d}')\n",
    "    learn.load(f'{mname}.{(step-1):02d}')\n",
    "\n",
    "do_fit(learn, f'{mname}.{step:02d}', lrs=lr, cycle_len=cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fns = []\n",
    "test_fns += list(datasources.glob('**/test/*.tif'))\n",
    "test_fns += list(datasources.glob('**/test/*.czi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fns = []\n",
    "test_fns += list(test_files.glob('**/*.tif'))\n",
    "test_fns += list(test_files.glob('**/*.czi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in test_fns:\n",
    "    category = fn.parts[-4]\n",
    "    group = fn.parts[-3]\n",
    "    name = fn.stem\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category, group, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_files = []\n",
    "movie_files = list(Path('/scratch/bpho/datasets/movies_001/test').glob('*05*.czi'))\n",
    "#movie_files += list(Path('/scratch/bpho/datasources/low_res_test/').glob('low res confocal*.czi'))\n",
    "#movie_files += list(Path('/scratch/bpho/datasources/neuron_movies2/').glob('low*.*'))\n",
    "#movie_files += list(Path('/DATA/WAMRI/salk/uri/bpho/datasources/neuron_movies/').glob('low res 300 time points 2*.czi'))\n",
    "#movie_files += list(Path('/DATA/WAMRI/salk/uri/bpho/datasources/neuron_movies/').glob('*time points 2*.tif'))\n",
    "#movie_files = list(Path('/DATA/donow/').glob('*.czi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 1\n",
    "lr = 1e-3\n",
    "cycles = 3\n",
    "\n",
    "bs = 1\n",
    "size = 256*6\n",
    "max_zoom = 1\n",
    "arch = xresnet34\n",
    "\n",
    "data = get_data(bs, size, hr_tifs, lr_up_tifs, max_zoom=max_zoom)\n",
    "learn = xres_unet_learner(data, arch, loss_func=loss, metrics=metrics, model_dir=model_dir)\n",
    "gc.collect()\n",
    "\n",
    "print(model_dir)\n",
    "print(mname)\n",
    "learn = learn.load('/home/fredmonroe/repos/salk/uri/paper/datasets/combo_001/lr_up/models/combo.1')\n",
    "learn = learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tif_predict_images(learn, czi_in, dest, category, tag=None, size=128):\n",
    "    under_tag = f'_' if tag is None else f'_{tag}_'\n",
    "    pred_out = dest_folder/f'{czi_in.stem}{under_tag}pred.tif'\n",
    "    orig_out = dest_folder/f'{czi_in.stem}{under_tag}orig.tif'\n",
    "\n",
    "    im = PIL.Image.open(tif_in)\n",
    "    im.load()\n",
    "    times = im.n_frames\n",
    "    imgs = []\n",
    "\n",
    "\n",
    "    for i in range(times):\n",
    "        im.seek(i)\n",
    "        im.load()\n",
    "        imgs.append(np.array(im).astype(np.float32)/255.)\n",
    "    img_data = np.stack(imgs)\n",
    "\n",
    "    preds = []\n",
    "    origs = []\n",
    "    img_max = img_data.max()\n",
    "\n",
    "    x,y = im.size\n",
    "    print(f'tif: x:{x} y:{y} t:{times}')\n",
    "    for t in progress_bar(list(range(0,times-wsize+1))):\n",
    "        img = img_data[t:(t+wsize)].copy()\n",
    "        img /= img_max\n",
    "\n",
    "        out_img = unet_image_from_tiles(learn, img, tile_sz=size, wsize=wsize)\n",
    "        pred = (out_img*255).cpu().numpy().astype(np.uint8)\n",
    "        preds.append(pred)\n",
    "        orig = (img[1][None]*255).astype(np.uint8)\n",
    "        origs.append(orig)\n",
    "        \n",
    "    if len(preds) > 0:\n",
    "        all_y = np.concatenate(preds)\n",
    "        imageio.mimwrite(pred_out, all_y, bigtiff=True)\n",
    "        all_y = np.concatenate(origs)\n",
    "        imageio.mimwrite(orig_out, all_y, bigtiff=True)\n",
    "\n",
    "\n",
    "def czi_predict_images(learn, czi_in, dest, category, tag=None, size=128):\n",
    "    with czifile.CziFile(czi_in) as czi_f:\n",
    "        \n",
    "        under_tag = f'_' if tag is None else f'_{tag}_'\n",
    "        \n",
    "        proc_axes, proc_shape = get_czi_shape_info(czi_f)\n",
    "        channels = proc_shape['C']\n",
    "        depths = proc_shape['Z']\n",
    "        times = proc_shape['T']\n",
    "\n",
    "        x,y = proc_shape['X'], proc_shape['Y']\n",
    "        dest_folder = Path(dest/category)\n",
    "        dest_folder.mkdir(exist_ok=True, parents=True)\n",
    "        \n",
    "        data = czi_f.asarray().astype(np.float32)/255.\n",
    "        \n",
    "        pred_out = dest_folder/f'{czi_in.stem}{under_tag}pred.tif'\n",
    "        orig_out = dest_folder/f'{czi_in.stem}{under_tag}orig.tif'\n",
    "        \n",
    "        preds = []\n",
    "        origs = []\n",
    "\n",
    "        img_max = data.max()\n",
    "        print(img_max)\n",
    "        for t in progress_bar(list(range(0,times))):\n",
    "            idx = build_index(proc_axes, {'T': t, 'C': 0, 'Z':0, 'X':slice(0,x),'Y':slice(0,y)})\n",
    "            img = data[idx].copy()\n",
    "            img /= img_max\n",
    "\n",
    "            out_img = unet_image_from_tiles(learn, img, tile_sz=size, wsize=1)\n",
    "            pred = (out_img*255).cpu().numpy().astype(np.uint8)\n",
    "            preds.append(pred)\n",
    "            #imsave(folder/f'{t}.tif', pred[0])\n",
    "\n",
    "            orig = (img[wsize//2][None]*255).astype(np.uint8)\n",
    "            origs.append(orig)\n",
    "        \n",
    "        if len(preds) > 0:\n",
    "            all_y = np.concatenate(preds)\n",
    "            imageio.mimwrite(pred_out, all_y, bigtiff=True)\n",
    "            all_y = np.concatenate(origs)\n",
    "            imageio.mimwrite(orig_out, all_y, bigtiff=True)\n",
    "\n",
    "\n",
    "\n",
    "def generate_tifs(src, dest, learn, size, tag=None):\n",
    "    for fn in progress_bar(src):\n",
    "        category = fn.parts[-3]\n",
    "        pred_name = f'{fn.stem}_pred.tif'\n",
    "        orig_name = f'{fn.stem}_orig.tif'\n",
    "        if not Path(pred_name).exists():\n",
    "            if fn.suffix == '.czi':\n",
    "                czi_predict_images(learn, fn, dest, category, size=size, tag=tag)\n",
    "            elif fn.suffix == '.tif':\n",
    "                tif_predict_images(learn, fn, dest, category, size=size, tag=tag)\n",
    "        else:\n",
    "            print(f'skip: {fn.stem} - doesn\\'t exist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
