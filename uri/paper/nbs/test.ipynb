{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from torchvision.models import vgg16_bn\n",
    "import PIL\n",
    "import imageio\n",
    "from utils import *\n",
    "import skimage\n",
    "import libtiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = Path('/scratch/bpho/datasets/transfer_learning_neuron_002/')\n",
    "model_path = Path('/scratch/bpho/models')\n",
    "model_name = \"transfer_learning_neuron_002_unet_mse\"\n",
    "model_version = \"7\"\n",
    "model = model_name+\".\"+model_version\n",
    "\n",
    "test_path = Path('/home/bpho/Documents/test/ddd/')\n",
    "test_files = list(test_path.glob('*.tif'))\n",
    "test_files\n",
    "\n",
    "results = test_path/f'{model_name}_{model_version}_pred'\n",
    "\n",
    "if results.exists(): shutil.rmtree(results)\n",
    "results.mkdir(parents=True, mode=0o775, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_src(size=128):\n",
    "    hr_tifs = img_data/f'hr'\n",
    "    lr_tifs = img_data/f'lr_up'\n",
    "\n",
    "    def map_to_hr(x):\n",
    "        hr_name = x.relative_to(lr_tifs)\n",
    "        return hr_tifs/hr_name\n",
    "    print(lr_tifs)\n",
    "    src = (ImageImageList\n",
    "            .from_folder(lr_tifs)\n",
    "            .split_by_folder()\n",
    "            .label_from_func(map_to_hr))\n",
    "    return src\n",
    "\n",
    "def _gaussian_noise_gray(x, gauss_sigma=1.):\n",
    "    c,h,w = x.shape\n",
    "    noise = torch.zeros((1,h,w))\n",
    "    noise.normal_(0, gauss_sigma)\n",
    "    img_max = np.minimum(1.1 * x.max(), 1.)\n",
    "    x = np.minimum(np.maximum(0,x+noise.repeat((3,1,1))), img_max)\n",
    "    return x\n",
    "\n",
    "gaussian_noise_gray = TfmPixel(_gaussian_noise_gray)\n",
    "\n",
    "\n",
    "def get_data(bs, size, tile_size=None, noise=None, max_zoom=8.):\n",
    "    if tile_size is None: tile_size = size\n",
    "    src = get_src(tile_size)\n",
    "    \n",
    "    tfms = [[rand_resize_crop(size=size)],[]]\n",
    "    tfms = get_transforms(flip_vert=True, max_zoom=max_zoom)\n",
    "    y_tfms = [[t for t in tfms[0]], [t for t in tfms[1]]]\n",
    "    \n",
    "    if not noise is None:\n",
    "        tfms[0].append(gaussian_noise_gray(gauss_sigma=noise))\n",
    "    data = (src\n",
    "            .transform(tfms, size=size)\n",
    "            .transform_y(y_tfms, size=size)\n",
    "            .databunch(bs=bs).normalize(imagenet_stats, do_y=True))\n",
    "    data.c = 3\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_loss = F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_fit(save_name, lrs=slice(lr), pct_start=0.9, cycle_len=10):\n",
    "    learn.fit_one_cycle(cycle_len, lrs, pct_start=pct_start,\n",
    "                        callbacks=[SaveModelCallback(learn, name=save_name)])\n",
    "    #learn.save(save_name)\n",
    "    num_rows = min(learn.data.batch_size, 3)\n",
    "    learn.show_results(rows=num_rows, imgsize=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_from_tiles(learn, img, tile_sz=128, scale=4):\n",
    "    pimg = PIL.Image.fromarray((img*255).astype(np.uint8), mode='L').convert('RGB')\n",
    "    cur_size = pimg.size\n",
    "    new_size = (cur_size[0]*scale, cur_size[1]*scale)\n",
    "    in_img = Image(pil2tensor(pimg.resize(new_size, resample=PIL.Image.BICUBIC),np.float32).div_(255))\n",
    "    c, w, h = in_img.shape\n",
    "    \n",
    "    in_tile = torch.zeros((c,tile_sz,tile_sz))\n",
    "    out_img = torch.zeros((c,w,h))\n",
    "    \n",
    "    for x_tile in range(math.ceil(w/tile_sz)):\n",
    "        for y_tile in range(math.ceil(h/tile_sz)):\n",
    "            x_start = x_tile\n",
    "\n",
    "            x_start = x_tile*tile_sz\n",
    "            x_end = min(x_start+tile_sz, w)\n",
    "            y_start = y_tile*tile_sz\n",
    "            y_end = min(y_start+tile_sz, h)\n",
    "            \n",
    "            \n",
    "            in_tile[:,0:(x_end-x_start), 0:(y_end-y_start)] = in_img.data[:,x_start:x_end, y_start:y_end]\n",
    "\n",
    "            out_tile,_,_ = learn.predict(Image(in_tile))\n",
    "\n",
    "            out_x_start = x_start\n",
    "            out_x_end = x_end\n",
    "            out_y_start = y_start\n",
    "            out_y_end = y_end\n",
    "\n",
    "            #print(\"out: \", out_x_start, out_y_start, \",\", out_x_end, out_y_end)\n",
    "            in_x_start = 0\n",
    "            in_y_start = 0\n",
    "            in_x_end = x_end-x_start\n",
    "            in_y_end = y_end-y_start\n",
    "            #print(\"tile: \",in_x_start, in_y_start, \",\", in_x_end, in_y_end)\n",
    "           \n",
    "            out_img[:,out_x_start:out_x_end, out_y_start:out_y_end] = out_tile.data[:,\n",
    "                                                                                  in_x_start:in_x_end, \n",
    "                                                                                  in_y_start:in_y_end]\n",
    "    return out_img\n",
    "\n",
    "\n",
    "def tif_predict_movie(learn, tif_in, orig_out='orig.tif', pred_out='pred.tif', size=128):\n",
    "        data = libtiff.TiffFile(tif_in)\n",
    "        data = data.get_tiff_array()\n",
    "        depths = data.shape[0]\n",
    "        img_max = None\n",
    "        preds = []\n",
    "        origs = []\n",
    "        for depth in progress_bar(list(range(depths))):\n",
    "            img = data[depth].astype(np.float32)\n",
    "            if img_max is None: img_max = img.max() * 1.0\n",
    "            img /= img_max\n",
    "            out_img = image_from_tiles(learn, img, tile_sz=size).permute([1,2,0])\n",
    "            pred = (out_img[None]*255).cpu().numpy().astype(np.uint8)\n",
    "            pred_img_out = pred_out+f'_slice{depth}.tif'\n",
    "            skimage.io.imsave(pred_img_out,pred[0,:,:,:])\n",
    "            \n",
    "            #preds.append(pred)\n",
    "            #orig = (img[None]*255).astype(np.uint8)\n",
    "            #origs.append(orig)\n",
    "\n",
    "#        all_y = np.concatenate(preds)\n",
    "        #print(all_y.shape)\n",
    "#        imageio.mimwrite(pred_out, all_y) #, fps=30, macro_block_size=None) # for mp4\n",
    "#        all_y = np.concatenate(origs)\n",
    "        #print(all_y.shape)\n",
    "#        imageio.mimwrite(orig_out, all_y) #, fps=30, macro_block_size=None)\n",
    "\n",
    "\n",
    "def czi_predict_movie(learn, czi_in, orig_out='orig.tif', pred_out='pred.tif', size=128):\n",
    "    with czifile.CziFile(czi_in) as czi_f:\n",
    "        proc_axes, proc_shape = get_czi_shape_info(czi_f)\n",
    "        channels = proc_shape['C']\n",
    "        depths = proc_shape['Z']\n",
    "        times = proc_shape['T']\n",
    "        x,y = proc_shape['X'], proc_shape['Y']\n",
    "        data = czi_f.asarray()\n",
    "        preds = []\n",
    "        origs = []\n",
    "        img_max = None\n",
    "        for t in progress_bar(list(range(times))):\n",
    "            idx = build_index(proc_axes, {'T': t, 'C': 0, 'Z':0, 'X':slice(0,x),'Y':slice(0,y)})\n",
    "            img = data[idx].astype(np.float32)\n",
    "            if img_max is None: img_max = img.max() * 1.0\n",
    "            img /= img_max\n",
    "            out_img = image_from_tiles(learn, img, tile_sz=size).permute([1,2,0])\n",
    "            pred = (out_img[None]*255).cpu().numpy().astype(np.uint8)\n",
    "            #preds.append(pred)\n",
    "            orig = (img[None]*255).astype(np.uint8)\n",
    "            origs.append(orig)\n",
    "            pred_img_out = pred_out+f'_slice{t}.tif'\n",
    "            skimage.io.imsave(pred_img_out,pred[0,:,:,:])\n",
    "            \n",
    "        #all_y = np.concatenate(preds)\n",
    "        #print(all_y.shape)\n",
    "        #imageio.mimwrite(pred_out, all_y) #, fps=30, macro_block_size=None) # for mp4\n",
    "        #all_y = np.concatenate(origs)\n",
    "        #print(all_y.shape)\n",
    "        #imageio.mimwrite(orig_out, all_y) #, fps=30, macro_block_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/bpho/datasets/transfer_learning_neuron_002/lr_up\n"
     ]
    }
   ],
   "source": [
    "bs=1\n",
    "size=380*4\n",
    "scale = 4\n",
    "\n",
    "data = get_data(bs, size, tile_size=128)\n",
    "\n",
    "arch = models.resnet18\n",
    "wd = 1e-3\n",
    "learn = unet_learner(data, arch, wd=wd, loss_func=feat_loss, \n",
    "                     metrics=superres_metrics, callback_fns=LossMetrics, \n",
    "                     blur=True, blur_final=True, norm_type=NormType.Weight, \n",
    "                     self_attention=True, last_cross=True, bottle=True,\n",
    "                     #y_range=(0.,1.),\n",
    "                     model_dir=model_path)\n",
    "gc.collect()\n",
    "learn = learn.load(model).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in test_files:\n",
    "    pred_name = f'{fn.stem}_pred'\n",
    "    orig_name = f'{fn.stem}_orig.tif'\n",
    "    tif_predict_movie(learn, fn, size=size, orig_out=orig_name, pred_out=pred_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in test_files:\n",
    "    #pred_name = f'{fn.stem}_pred.tif'\n",
    "    pred_name = f'{fn.stem}_pred'\n",
    "    orig_name = f'{fn.stem}_orig.tif'\n",
    "    czi_predict_movie(learn, fn, size=size, orig_out=orig_name, pred_out=pred_name )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
