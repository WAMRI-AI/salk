{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#import fastai\n",
    "from fastai import *          # Quick access to most common functionality\n",
    "from fastai.vision import *   # Quick access to computer vision functionality\n",
    "from fastai.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_ssim as ssim\n",
    "from superres import *\n",
    "from torchvision.models import vgg16_bn\n",
    "import czifile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/DATA/WAMRI/salk/uri/BPHO/')\n",
    "path_processed = path/'processed'\n",
    "path_hr = path/'hires'\n",
    "path_lr = path/'lores'\n",
    "\n",
    "path_hr.mkdir(exist_ok=True)\n",
    "path_lr.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_czi_shape_info(czi):\n",
    "    shape = czi.shape\n",
    "    axes = czi.axes\n",
    "    axes_dict = {axis:idx for idx,axis in enumerate(czi.axes)}\n",
    "    shape_dict = {axis:shape[axes_dict[axis]] for axis in czi.axes}\n",
    "    return axes_dict, shape_dict\n",
    "\n",
    "\n",
    "def build_index(axes, ix_select):\n",
    "    idx = [ix_select.get(ax, 0) for ax in axes]\n",
    "    return tuple(idx)\n",
    "\n",
    "\n",
    "def process_czi(proc_fn):\n",
    "    with czifile.CziFile(proc_fn) as proc_czf:\n",
    "        proc_axes, proc_shape = get_czi_shape_info(proc_czf)\n",
    "        channels = proc_shape['C']\n",
    "        depths = proc_shape['Z']\n",
    "        x,y = proc_shape['X'], proc_shape['Y']\n",
    "        data = proc_czf.asarray()\n",
    "        for channel in range(channels):\n",
    "            for depth in range(depths):\n",
    "                idx = build_index(proc_axes, {'C': channel, 'Z':depth, 'X':slice(0,x),'Y':slice(0,y)})\n",
    "                img = data[idx]\n",
    "                save_proc_fn = path_hr/f'{proc_fn.stem}_{channel:02d}_{depth:03d}.npy'\n",
    "                np.save(save_proc_fn, img)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_fns = list(path_processed.glob('*.czi'))\n",
    "#for fn in progress_bar(proc_fns):\n",
    "#    process_czi(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_one(fn,i):\n",
    "    dest = path_lr/fn.relative_to(path_hr)\n",
    "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    data = np.load(fn)\n",
    "    data = data.astype(float) / 8000.0\n",
    "    data *= 255\n",
    "    data = data.astype(np.uint8)\n",
    "    \n",
    "    img = PIL.Image.fromarray(data, mode='L')\n",
    "    targ_sz = resize_to(img,96,use_min=True)\n",
    "    img = img.resize(targ_sz, resample=PIL.Image.BILINEAR)\n",
    "    img.save(str(dest).replace('.npy','.jpg'), quality=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "        \t/* Turns off some styling */\n",
       "        \tprogress {\n",
       "\n",
       "            \t/* gets rid of default border in Firefox and Opera. */\n",
       "            \tborder: none;\n",
       "\n",
       "            \t/* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "            \tbackground-size: auto;\n",
       "            }\n",
       "\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1124' class='' max='1124', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1124/1124 00:03<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hr_fns = list(path_hr.glob('*.npy'))\n",
    "parallel(resize_one, hr_fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcImageList(ImageImageList):\n",
    "    def open(self, fn):\n",
    "        data = np.load(fn)\n",
    "        x = torch.from_numpy(data[None,:,:].astype(np.float32))\n",
    "        x.div_(8000.)\n",
    "        return Image(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basename(x):\n",
    "    return x.stem.split('_')[0]\n",
    "\n",
    "base_names = list(set([get_basename(x) for x in list(path_lr.iterdir())]))\n",
    "train_names, valid_names = random_split(0.15, base_names)\n",
    "valid_names = list(valid_names[0])\n",
    "\n",
    "def is_validation_basename(x):\n",
    "    xbase = get_basename(x)\n",
    "    return xbase in valid_names\n",
    "\n",
    "src = (ImageItemList\n",
    "       .from_folder(path_lr, label_cls=ProcImageList, extensions=\".jpg\", mode='L')\n",
    "       .split_by_valid_func(is_validation_basename))\n",
    "\n",
    "def get_data(src,bs,size, **kwargs):\n",
    "    def lr_to_hr_fn(x):\n",
    "        x_hr = path_hr/str(x.stem + \".npy\")\n",
    "        return x_hr\n",
    "    \n",
    "    data = (src.label_from_func(lr_to_hr_fn)\n",
    "            .transform(get_transforms(), size=size, tfm_y=True)\n",
    "            .databunch(bs=bs,**kwargs))\n",
    "    data.c = 3\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 16\n",
    "size = 4*96\n",
    "data = get_data(src, bs, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Image (3, 384, 384), Image (1, 384, 384))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = data.train_ds[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
