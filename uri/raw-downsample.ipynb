{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#import fastai\n",
    "from fastai import *          # Quick access to most common functionality\n",
    "from fastai.vision import *   # Quick access to computer vision functionality\n",
    "from fastai.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_ssim as ssim\n",
    "from superres import *\n",
    "from torchvision.models import vgg16_bn\n",
    "import czifile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/DATA/WAMRI/salk/uri/BPHO/')\n",
    "path_processed = path/'processed'\n",
    "model_dir = path/'models'\n",
    "path_hr = path/'hires'\n",
    "path_mr = path/'midres'\n",
    "path_lr = path/'lores'\n",
    "path_test = path/'test'\n",
    "\n",
    "path_hr.mkdir(exist_ok=True)\n",
    "path_mr.mkdir(exist_ok=True)\n",
    "path_lr.mkdir(exist_ok=True)\n",
    "path_test.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_czi_shape_info(czi):\n",
    "    shape = czi.shape\n",
    "    axes = czi.axes\n",
    "    axes_dict = {axis:idx for idx,axis in enumerate(czi.axes)}\n",
    "    shape_dict = {axis:shape[axes_dict[axis]] for axis in czi.axes}\n",
    "    return axes_dict, shape_dict\n",
    "\n",
    "\n",
    "def build_index(axes, ix_select):\n",
    "    idx = [ix_select.get(ax, 0) for ax in axes]\n",
    "    return tuple(idx)\n",
    "\n",
    "\n",
    "def process_czi(proc_fn):\n",
    "    with czifile.CziFile(proc_fn) as proc_czf:\n",
    "        proc_axes, proc_shape = get_czi_shape_info(proc_czf)\n",
    "        channels = proc_shape['C']\n",
    "        depths = proc_shape['Z']\n",
    "        x,y = proc_shape['X'], proc_shape['Y']\n",
    "        data = proc_czf.asarray()\n",
    "        for channel in range(channels):\n",
    "            for depth in range(depths):\n",
    "                idx = build_index(proc_axes, {'C': channel, 'Z':depth, 'X':slice(0,x),'Y':slice(0,y)})\n",
    "                img = data[idx]\n",
    "                save_proc_fn = path_hr/f'{proc_fn.stem}_{channel:02d}_{depth:03d}.npy'\n",
    "                np.save(save_proc_fn, img)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proc_fns = list(path_processed.glob('*.czi'))\n",
    "#for fn in progress_bar(proc_fns):\n",
    "#    process_czi(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_one(fn,i):\n",
    "    dest = path_lr/fn.relative_to(path_hr)\n",
    "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    data = np.load(fn)\n",
    "    data = data.astype(float) / 8000.0\n",
    "    data *= 255\n",
    "    data = data.astype(np.uint8)\n",
    "    \n",
    "    img = PIL.Image.fromarray(data, mode='L')\n",
    "    targ_sz = resize_to(img,96,use_min=True)\n",
    "    img = img.resize(targ_sz, resample=PIL.Image.BILINEAR)\n",
    "    img.save(str(dest).replace('.npy','.jpg'), quality=100)\n",
    "    \n",
    "def resize_two(fn,i):\n",
    "    dest = path_mr/fn.relative_to(path_hr)\n",
    "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    data = np.load(fn)\n",
    "    data = data.astype(float) / 8000.0\n",
    "    data *= 255\n",
    "    data = data.astype(np.uint8)\n",
    "    \n",
    "    img = PIL.Image.fromarray(data, mode='L')\n",
    "    targ_sz = resize_to(img,256,use_min=True)\n",
    "    img = img.resize(targ_sz, resample=PIL.Image.BILINEAR)\n",
    "    img.save(str(dest).replace('.npy','.jpg'), quality=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "        \t/* Turns off some styling */\n",
       "        \tprogress {\n",
       "\n",
       "            \t/* gets rid of default border in Firefox and Opera. */\n",
       "            \tborder: none;\n",
       "\n",
       "            \t/* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "            \tbackground-size: auto;\n",
       "            }\n",
       "\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1124' class='' max='1124', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1124/1124 00:02<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hr_fns = list(path_hr.glob('*.npy'))\n",
    "# parallel(resize_two, hr_fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "        \t/* Turns off some styling */\n",
       "        \tprogress {\n",
       "\n",
       "            \t/* gets rid of default border in Firefox and Opera. */\n",
       "            \tborder: none;\n",
       "\n",
       "            \t/* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "            \tbackground-size: auto;\n",
       "            }\n",
       "\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1124' class='' max='1124', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1124/1124 00:01<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hr_fns = list(path_hr.glob('*.npy'))\n",
    "# parallel(resize_one, hr_fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcImageList(ImageImageList):\n",
    "    def open(self, fn):\n",
    "        data = np.load(fn)\n",
    "        x = torch.from_numpy(data[None,:,:].astype(np.float32))\n",
    "        x.div_(8000.)\n",
    "        return Image(x.repeat([3,1,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basename(x):\n",
    "    return x.stem.split('_')[0]\n",
    "\n",
    "base_names = list(set([get_basename(x) for x in list(path_lr.iterdir())]))\n",
    "train_names, valid_names = random_split(0.15, base_names)\n",
    "valid_names = list(valid_names[0])\n",
    "\n",
    "def is_validation_basename(x):\n",
    "    xbase = get_basename(x)\n",
    "    return xbase in valid_names\n",
    "\n",
    "src = (ImageItemList\n",
    "       .from_folder(path_lr, label_cls=ProcImageList, extensions=\".jpg\", mode='L')\n",
    "       .split_by_valid_func(is_validation_basename))\n",
    "\n",
    "src_mr = (ImageItemList\n",
    "       .from_folder(path_mr, label_cls=ProcImageList, extensions=\".jpg\", mode='L')\n",
    "       .split_by_valid_func(is_validation_basename))\n",
    "\n",
    "def get_data(src,bs,size, **kwargs):\n",
    "    def lr_to_hr_fn(x):\n",
    "        x_hr = path_hr/str(x.stem + \".npy\")\n",
    "        return x_hr\n",
    "    \n",
    "    data = (src.label_from_func(lr_to_hr_fn)\n",
    "            .transform(get_transforms(max_zoom=2.), size=size, tfm_y=True)\n",
    "            .databunch(bs=bs,**kwargs).normalize(imagenet_stats, do_y=True))\n",
    "    data.c = 3\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = models.resnet34\n",
    "bs,size = 4,512\n",
    "data = get_data(src_mr, bs, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Image (3, 512, 512), Image (3, 512, 512))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.show_batch(ds_type=DatasetType.Valid, rows=2, figsize=(9,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    n,c,h,w = x.size()\n",
    "    x = x.view(n, c, -1)\n",
    "    return (x @ x.transpose(1,2))/(c*h*w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_loss = F.l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_m = vgg16_bn(True).features.cuda().eval()\n",
    "requires_grad(vgg_m, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([5, 12, 22, 32, 42],\n",
       " [ReLU(inplace), ReLU(inplace), ReLU(inplace), ReLU(inplace), ReLU(inplace)])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks = [i-1 for i,o in enumerate(children(vgg_m)) if isinstance(o,nn.MaxPool2d)]\n",
    "blocks, [vgg_m[i] for i in blocks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureLoss(nn.Module):\n",
    "    def __init__(self, m_feat, layer_ids, layer_wgts):\n",
    "        super().__init__()\n",
    "        self.m_feat = m_feat\n",
    "        self.loss_features = [self.m_feat[i] for i in layer_ids]\n",
    "        self.hooks = hook_outputs(self.loss_features, detach=False)\n",
    "        self.wgts = layer_wgts\n",
    "        self.metric_names = ['pixel',] + [f'feat_{i}' for i in range(len(layer_ids))\n",
    "              ] + [f'gram_{i}' for i in range(len(layer_ids))]\n",
    "\n",
    "    def make_features(self, x, clone=False):\n",
    "        self.m_feat(x)\n",
    "        return [(o.clone() if clone else o) for o in self.hooks.stored]\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        out_feat = self.make_features(target, clone=True)\n",
    "        in_feat = self.make_features(input)\n",
    "        self.feat_losses = [base_loss(input,target)]\n",
    "        self.feat_losses += [base_loss(f_in, f_out)*w\n",
    "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
    "        self.feat_losses += [base_loss(gram_matrix(f_in), gram_matrix(f_out))*w**2 * 5e3\n",
    "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
    "        self.metrics = dict(zip(self.metric_names, self.feat_losses))\n",
    "        return sum(self.feat_losses)\n",
    "    \n",
    "    def __del__(self): self.hooks.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_loss = FeatureLoss(vgg_m, blocks[2:5], [5,15,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = 1e-3\n",
    "learn = unet_learner(data, arch, wd=wd, loss_func=feat_loss, \n",
    "                     callback_fns=LossMetrics, blur=True, norm_type=NormType.Weight,\n",
    "                     metrics=superres_metrics, model_dir=model_dir)\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.lr_find()\n",
    "# learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "def do_fit(save_name, lrs=slice(lr), pct_start=0.9):\n",
    "    learn.fit_one_cycle(10, lrs, pct_start=pct_start)\n",
    "    learn.save(save_name)\n",
    "    learn.show_results(rows=1, imgsize=5)\n",
    "    learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "        \t/* Turns off some styling */\n",
       "        \tprogress {\n",
       "\n",
       "            \t/* gets rid of default border in Firefox and Opera. */\n",
       "            \tborder: none;\n",
       "\n",
       "            \t/* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "            \tbackground-size: auto;\n",
       "            }\n",
       "\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      30.00% [3/10 09:34<22:20]\n",
       "    </div>\n",
       "    \n",
       "<table style='width:975px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>mse_loss</th>\n",
       "    <th>ssim</th>\n",
       "    <th>psnr</th>\n",
       "    <th>pixel</th>\n",
       "    <th>feat_0</th>\n",
       "    <th>feat_1</th>\n",
       "    <th>feat_2</th>\n",
       "    <th>gram_0</th>\n",
       "    <th>gram_1</th>\n",
       "    <th>gram_2</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>2.973625</th>\n",
       "    <th>2.588928</th>\n",
       "    <th>1.067484</th>\n",
       "    <th>0.517662</th>\n",
       "    <th>-0.278924</th>\n",
       "    <th>0.922366</th>\n",
       "    <th>0.201913</th>\n",
       "    <th>0.212321</th>\n",
       "    <th>0.011464</th>\n",
       "    <th>0.701248</th>\n",
       "    <th>0.536879</th>\n",
       "    <th>0.002739</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>1.203431</th>\n",
       "    <th>0.890976</th>\n",
       "    <th>0.007507</th>\n",
       "    <th>0.787360</th>\n",
       "    <th>23.374224</th>\n",
       "    <th>0.035363</th>\n",
       "    <th>0.152004</th>\n",
       "    <th>0.165918</th>\n",
       "    <th>0.009526</th>\n",
       "    <th>0.260825</th>\n",
       "    <th>0.265155</th>\n",
       "    <th>0.002185</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.850613</th>\n",
       "    <th>0.911786</th>\n",
       "    <th>0.005997</th>\n",
       "    <th>0.873294</th>\n",
       "    <th>24.903582</th>\n",
       "    <th>0.029191</th>\n",
       "    <th>0.143298</th>\n",
       "    <th>0.151363</th>\n",
       "    <th>0.007771</th>\n",
       "    <th>0.348884</th>\n",
       "    <th>0.229287</th>\n",
       "    <th>0.001992</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "\n",
       "  </tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "        \t/* Turns off some styling */\n",
       "        \tprogress {\n",
       "\n",
       "            \t/* gets rid of default border in Firefox and Opera. */\n",
       "            \tborder: none;\n",
       "\n",
       "            \t/* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "            \tbackground-size: auto;\n",
       "            }\n",
       "\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='60' class='' max='205', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      29.27% [60/205 00:46<01:51 0.8494]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "do_fit('1a', slice(lr*10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit('1b', slice(1e-4,1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = get_data(src, bs//2,size*2)\n",
    "learn.data = data\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit('2a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit('2b', slice(1e-5,1e-3), pct_start=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs,size = 2,512\n",
    "data = get_data(src_mr, bs, size)\n",
    "learn = learn.load('2b')\n",
    "do_fit('3', slice(1e-4,1e-2), pct_start=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.data = data\n",
    "tst_imgs  = list(Path('/DATA/WAMRI/salk/uri/Image_restoration_data/newimg/').iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = tst_imgs[1]\n",
    "img = open_grayscale(fn)\n",
    "\n",
    "a,b,c = learn.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agray = Image(a.data[0:1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agray.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim.ssim(agray.data[None], img.data[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
