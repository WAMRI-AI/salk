{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from torchvision.models import vgg16_bn\n",
    "import PIL\n",
    "import imageio\n",
    "from superres import *\n",
    "from superres.helpers import czi_predict_movie\n",
    "import skimage\n",
    "from skimage.util import random_noise\n",
    "from skimage import filters\n",
    "from scipy.ndimage.interpolation import zoom as npzoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = Path('/scratch/bpho/datasets/synth_newcrap_001/')\n",
    "model_path = Path('/scratch/bpho/models')\n",
    "nb_name = \"synth_newcrap_0001_unet_mse_stability\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from numbers import Integral\n",
    "\n",
    "class MultiImage(ItemBase):\n",
    "    def __init__(self, img_list):\n",
    "        self.img_list = img_list\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'MultiImage: {[str(img) for img in self.img_list]}'\n",
    "\n",
    "    @property\n",
    "    def size(self):\n",
    "        return [img.size for img in self.img_list]\n",
    "    \n",
    "    @property\n",
    "    def data(self):\n",
    "        img_data = torch.stack([img.data for img in self.img_list])\n",
    "        data = tensor(img_data)\n",
    "        return data\n",
    "\n",
    "    def apply_tfms(self, tfms, **kwargs):\n",
    "        first_time = True\n",
    "\n",
    "        save_img_list = []\n",
    "        for img in self.img_list:\n",
    "            new_img = img.apply_tfms(tfms, do_resolve=first_time, **kwargs)\n",
    "            first_time = False\n",
    "            save_img_list.append(new_img)\n",
    "        self.img_list = save_img_list\n",
    "        return self\n",
    "    \n",
    "    def _repr_png_(self): return self._repr_image_format('png')\n",
    "    def _repr_jpeg_(self): return self._repr_image_format('jpeg')\n",
    "\n",
    "    def _repr_image_format(self, format_str):\n",
    "        #return self.img_lists[0]._repr_image_format(format_str)\n",
    "        with BytesIO() as str_buffer:\n",
    "            img_data = np.concatenate([image2np(img.px) for img in self.img_list], axis=1)\n",
    "            plt.imsave(str_buffer, img_data, format=format_str)\n",
    "            return str_buffer.getvalue()\n",
    "\n",
    "    def show(self, **kwargs):\n",
    "        self.img_list[0].show(**kwargs)\n",
    "\n",
    "        \n",
    "class MultiImageList(ImageList):\n",
    "    \"`ItemList` suitable for computer vision.\"\n",
    "    _bunch,_square_show,_square_show_res = ImageDataBunch,True,True\n",
    "    def __init__(self, *args, map_fns=None,  **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        if map_fns is None: map_fns = [lambda x: x]\n",
    "        self.map_fns =  map_fns\n",
    "        \n",
    "    def open(self, fn):\n",
    "        \"Open image in `fn`, subclass and overwrite for custom behavior.\"\n",
    "        fns = [map_fn(fn) for map_fn in self.map_fns]\n",
    "        img_lists = [open_image(fn, convert_mode=self.convert_mode, after_open=self.after_open) for fn in fns]\n",
    "        return MultiImage(img_lists)\n",
    "    \n",
    "    def __getitem__(self,idxs:int)->Any:\n",
    "        idxs = try_int(idxs)\n",
    "        if isinstance(idxs, Integral): return self.get(idxs)\n",
    "        else: return self.new(self.items[idxs], inner_df=index_row(self.inner_df, idxs), map_fns=self.map_fns)\n",
    "        \n",
    "    def reconstruct(self, t:Tensor):\n",
    "        n, c, h, w = t.shape\n",
    "        one_img = t.view(c,n*h,w)\n",
    "        return Image(one_img.float().clamp(min=0,max=1))\n",
    "\n",
    "                \n",
    "\n",
    "class MultiImageImageList(MultiImageList):\n",
    "    \"`ItemList` suitable for `Image` to `Image` tasks.\"\n",
    "    _label_cls,_square_show,_square_show_res = ImageList,False,False\n",
    "\n",
    "    def show_xys(self, xs, ys, imgsize:int=4, figsize:Optional[Tuple[int,int]]=None, **kwargs):\n",
    "        \"Show the `xs` (inputs) and `ys`(targets)  on a figure of `figsize`.\"\n",
    "        axs = subplots(len(xs), 2, imgsize=imgsize, figsize=figsize)\n",
    "        for i, (x,y) in enumerate(zip(xs,ys)):\n",
    "            x.show(ax=axs[i,0], **kwargs)\n",
    "            y.show(ax=axs[i,1], **kwargs)\n",
    "        plt.tight_layout()\n",
    "\n",
    "    def show_xyzs(self, xs, ys, zs, imgsize:int=4, figsize:Optional[Tuple[int,int]]=None, **kwargs):\n",
    "        \"Show `xs` (inputs), `ys` (targets) and `zs` (predictions) on a figure of `figsize`.\"\n",
    "        title = 'Input / Prediction / Target'\n",
    "        axs = subplots(len(xs), 3, imgsize=imgsize, figsize=figsize, title=title, weight='bold', size=14)\n",
    "        for i,(x,y,z) in enumerate(zip(xs,ys,zs)):\n",
    "            x.show(ax=axs[i,0], **kwargs)\n",
    "            y.show(ax=axs[i,2], **kwargs)\n",
    "            z.show(ax=axs[i,1], **kwargs)\n",
    "            \n",
    "class MultiXModel(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        all_ys = []\n",
    "        for i in range(x.shape[1]):\n",
    "            all_ys.append(self.model(x[:,i]))\n",
    "        ys = torch.stack(all_ys, dim=1)\n",
    "        return ys\n",
    "    \n",
    "class MultiYStabilityLoss(nn.Module):\n",
    "    def __init__(self, base_loss=F.mse_loss, stable_wt=0.15):\n",
    "        super().__init__()\n",
    "        self.base_loss = base_loss\n",
    "        self.stable_wt = stable_wt\n",
    "        self.base_loss_wt = (1-stable_wt)\n",
    "        self.metric_names = ['pixel','stable','ssim','psnr']\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        num_y = input.shape[1]\n",
    "        base_loss = 0.\n",
    "        stable_loss = 0.\n",
    "        last_y = None\n",
    "        for i in range(num_y):\n",
    "            y = input[:,i]\n",
    "            base_loss += self.base_loss(y, target)\n",
    "            if not last_y is None:\n",
    "                stable_loss += F.mse_loss(last_y, y)\n",
    "            last_y = y\n",
    "            \n",
    "        base_loss /= num_y\n",
    "        stable_loss /= (num_y-1)\n",
    "        loss = base_loss * self.base_loss_wt + self.stable_wt * stable_loss\n",
    "        self.metrics = {\n",
    "            'pixel': base_loss,\n",
    "            'stable': stable_loss,\n",
    "            'ssim': ssim.ssim(last_y, target),\n",
    "            'psnr': psnr(last_y, target)\n",
    "        }\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_src(size=128):\n",
    "    hr_tifs = img_data/f'hr'\n",
    "    lr_tifs = img_data/f'lr'\n",
    "\n",
    "    def map_to_hr(x):\n",
    "        hr_name = x.relative_to(lr_tifs)\n",
    "        return hr_tifs/hr_name\n",
    "    print(lr_tifs)\n",
    "    src = (MultiImageImageList\n",
    "            .from_folder(lr_tifs, map_fns=[lambda x:x, lambda x:x])\n",
    "            .split_by_folder()\n",
    "            .label_from_func(map_to_hr))\n",
    "    return src\n",
    "\n",
    "\n",
    "def new_crappify(x, scale=4):\n",
    "    c,h,w = x.shape\n",
    "    def apply_crap(x):\n",
    "        h,w = x.shape\n",
    "        x = npzoom(x, 1/scale, order=1)\n",
    "        x = random_noise(x, mode='salt', amount=0.005)\n",
    "        x = random_noise(x, mode='pepper', amount=0.005)\n",
    "        lvar = filters.gaussian(x, sigma=1) + 1e-6\n",
    "        x = random_noise(x, mode='localvar', local_vars=lvar*0.05)\n",
    "        x = npzoom(x, scale, order=1)\n",
    "        return x.reshape(1,h,w).astype(np.float32)\n",
    "    \n",
    "    x1 = apply_crap(x[0,:,:].numpy().reshape(h,w))\n",
    "    x2 = apply_crap(x[0,:,:].numpy().reshape(h,w))\n",
    "    x_out = np.stack([x1,x2])\n",
    "    return tensor(x_out)\n",
    "\n",
    "crappify = TfmPixel(new_crappify)\n",
    "\n",
    "\n",
    "def get_data(bs, size, tile_size=None, noise=None, max_zoom=4., scale=4):\n",
    "    if tile_size is None: tile_size = size\n",
    "    src = get_src(tile_size)\n",
    "    \n",
    "    tfms = get_transforms(flip_vert=True, max_zoom=max_zoom)\n",
    "    y_tfms = [[t for t in tfms[0]], [t for t in tfms[1]]]\n",
    "\n",
    "    #tfms[0].insert(0, crappify(scale=scale))\n",
    "    #tfms[0].append(crappify(scale=scale))\n",
    "    data = (src\n",
    "            .transform(tfms, size=size)\n",
    "            .transform_y(y_tfms, size=size)\n",
    "            .databunch(bs=bs).normalize(imagenet_stats, do_y=True))\n",
    "    data.c = 3\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bs = 4\n",
    "size = 128\n",
    "data = get_data(bs, size, max_zoom=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(3)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrameStableLoss(nn.Module):\n",
    "    def __init__(self, model, base_loss=F.mse_loss, stable_wt=0.15):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.base_loss = base_loss\n",
    "        self.stable_wt = stable_wt\n",
    "        self.base_loss_wt = (1-stable_wt)/2\n",
    "        if hasattr(base_loss, 'metric_names'):\n",
    "            metric_names = base_loss.metric_names\n",
    "        else:\n",
    "            metric_names = []\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        base_loss = self.base_loss\n",
    "        \n",
    "        if self.model.training:\n",
    "            num_chan = input.shape[1] // 2\n",
    "            y1 = input[:,0:num_chan,:,:]\n",
    "            y2 = input[:,num_chan:,:,:]\n",
    "            base_2 = base_loss(y2, target)\n",
    "            base_1 = base_loss(y1, target)\n",
    "            stable_err = F.mse_loss(y1,y2)\n",
    "            loss = (base_1 * self.base_loss_wt +\n",
    "                    base_2 * self.base_loss_wt +\n",
    "                    stable_err * self.stable_wt)\n",
    "        else:\n",
    "            loss = base_loss(input, target)\n",
    "            \n",
    "        if hasattr(self.base_loss, 'metrics'):\n",
    "            self.metrics = self.base_loss.metrics\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "class FrameStableModel(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def noise(self, x, pct_destroy=0.15, shift=0.3):\n",
    "        x1 = x[:,0,:,:]\n",
    "        b,c,h,w = x1.shape\n",
    "        perm1 = torch.randperm(c*b*h*w)\n",
    "        perm2 = torch.randperm(c*b*h*w)\n",
    "        idx1 = perm1[:int(pct_destroy*perm1.shape[0])]\n",
    "        idx2 = perm2[:int(pct_destroy*perm2.shape[0])]\n",
    "        x.view(-1)[idx1] *= shift\n",
    "        x.view(-1)[idx2] *= -shift\n",
    "        return x1.repeat((1,3,1,1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            x1, x2 = self.noise(x), self.noise(x)\n",
    "            y1 = self.model(x1)\n",
    "            y2 = self.model(x2)\n",
    "            return torch.cat((y1,y2))\n",
    "        else:\n",
    "            return self.model(x)\n",
    "    \n",
    "    def get_old_model(self):\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = models.resnet18\n",
    "wd = 1e-3\n",
    "learn = unet_learner(data, arch, wd=wd, loss_func=feat_loss,\n",
    "                     metrics=superres_metrics, #callback_fns=[VideoStability], \n",
    "                     blur=True, blur_final=True, norm_type=NormType.Weight, \n",
    "                     self_attention=True, last_cross=True, bottle=True,\n",
    "                     #y_range=(0.,1.),\n",
    "                     model_dir=model_path)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model = MultiXModel(learn.model)\n",
    "learn.loss_func = MultiYStabilityLoss(learn.loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_fit(save_name, lrs=slice(lr), pct_start=0.9, cycle_len=10):\n",
    "    orig_model = learn.model\n",
    "    orig_loss = learn.loss_func\n",
    "    #learn.model = FrameStableModel(orig_model)\n",
    "    #learn.loss_func = FrameStableLoss(learn.model, orig_loss)\n",
    "    learn.fit_one_cycle(cycle_len, lrs, pct_start=pct_start)\n",
    "    #learn.model = learn.model.get_old_model()\n",
    "    #learn.loss_func = orig_loss\n",
    "    learn.save(save_name)\n",
    "    num_rows = min(learn.data.batch_size, 3)\n",
    "    learn.show_results(rows=num_rows, imgsize=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit(f'{nb_name}.0', lr, cycle_len=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit(f'{nb_name}.1', slice(1e-5,lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_fit(f'{nb_name}.2', lr/100, cycle_len=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_fit(f'{nb_name}.3', slice(1e-5,lr/10), cycle_len=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('cool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 4\n",
    "size = 512\n",
    "data = get_data(bs, size, max_zoom=2.)\n",
    "\n",
    "arch = models.resnet18\n",
    "wd = 1e-3\n",
    "learn = unet_learner(data, arch, wd=wd, loss_func=feat_loss, \n",
    "                     metrics=superres_metrics, #callback_fns=LossMetrics, \n",
    "                     blur=True, blur_final=True, norm_type=NormType.Weight, \n",
    "                     self_attention=True, last_cross=True, bottle=True,\n",
    "                     #y_range=(0.,1.),\n",
    "                     model_dir=model_path)\n",
    "\n",
    "learn = learn.load(f'{nb_name}.3')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_fit(f'{nb_name}.4', lr/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "do_fit(f'{nb_name}.5', slice(1e-6,lr/100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 2\n",
    "size = 1024\n",
    "data = get_data(bs, size, max_zoom=2.)\n",
    "\n",
    "arch = models.resnet18\n",
    "wd = 1e-3\n",
    "learn = unet_learner(data, arch, wd=wd, loss_func=feat_loss, \n",
    "                     metrics=superres_metrics, callback_fns=LossMetrics, \n",
    "                     blur=True, blur_final=True, norm_type=NormType.Weight, \n",
    "                     self_attention=True, last_cross=True, bottle=True,\n",
    "                     #y_range=(0.,1.),\n",
    "                     model_dir=model_path)\n",
    "gc.collect()\n",
    "\n",
    "learn = learn.load(f'{nb_name}.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit(f'{nb_name}.6', lr/100, cycle_len=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_fit(f'{nb_name}.7', slice(1e-6,lr/100), cycle_len=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('cool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /scratch/bpho/models/{nb_name}*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movie_files = list(Path('/scratch/bpho/datasets/movies_001/test').glob('*.czi'))\n",
    "movie_files = list(Path('/scratch/bpho/datasources/low_res_test/').glob('low res confocal*.czi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = movie_files[0]\n",
    "len(movie_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with czifile.CziFile(fn) as czi_f:\n",
    "    proc_axes, proc_shape = get_czi_shape_info(czi_f)\n",
    "    channels = proc_shape['C']\n",
    "    depths = proc_shape['Z']\n",
    "    times = proc_shape['T']\n",
    "    x,y = proc_shape['X'], proc_shape['Y']\n",
    "    data = czi_f.asarray()\n",
    "    preds = []\n",
    "    origs = []\n",
    "    idx = build_index(proc_axes, {'T': 0, 'C': 0, 'Z':0, 'X':slice(0,x),'Y':slice(0,y)})\n",
    "    img = data[idx].astype(np.float32)\n",
    "    img /= (img.max() * 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_from_tiles(learn, img, tile_sz=128, scale=4):\n",
    "    pimg = PIL.Image.fromarray((img*255).astype(np.uint8), mode='L').convert('RGB')\n",
    "    cur_size = pimg.size\n",
    "    new_size = (cur_size[0]*scale, cur_size[1]*scale)\n",
    "    in_img = Image(pil2tensor(pimg.resize(new_size, resample=PIL.Image.BICUBIC),np.float32).div_(255))\n",
    "    c, w, h = in_img.shape\n",
    "    \n",
    "    in_tile = torch.zeros((c,tile_sz,tile_sz))\n",
    "    out_img = torch.zeros((c,w,h))\n",
    "    \n",
    "    for x_tile in range(math.ceil(w/tile_sz)):\n",
    "        for y_tile in range(math.ceil(h/tile_sz)):\n",
    "            x_start = x_tile\n",
    "\n",
    "            x_start = x_tile*tile_sz\n",
    "            x_end = min(x_start+tile_sz, w)\n",
    "            y_start = y_tile*tile_sz\n",
    "            y_end = min(y_start+tile_sz, h)\n",
    "            \n",
    "            \n",
    "            in_tile[:,0:(x_end-x_start), 0:(y_end-y_start)] = in_img.data[:,x_start:x_end, y_start:y_end]\n",
    "            \n",
    "            out_tile,_,_ = learn.predict(Image(in_tile))\n",
    "\n",
    "            out_x_start = x_start\n",
    "            out_x_end = x_end\n",
    "            out_y_start = y_start\n",
    "            out_y_end = y_end\n",
    "\n",
    "            #print(\"out: \", out_x_start, out_y_start, \",\", out_x_end, out_y_end)\n",
    "            in_x_start = 0\n",
    "            in_y_start = 0\n",
    "            in_x_end = x_end-x_start\n",
    "            in_y_end = y_end-y_start\n",
    "            #print(\"tile: \",in_x_start, in_y_start, \",\", in_x_end, in_y_end)\n",
    "           \n",
    "            out_img[:,out_x_start:out_x_end, out_y_start:out_y_end] = out_tile.data[:,\n",
    "                                                                                  in_x_start:in_x_end, \n",
    "                                                                                  in_y_start:in_y_end]\n",
    "    return out_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def czi_predict_movie(learn, czi_in, orig_out='orig.tif', pred_out='pred.tif', size=128):\n",
    "    with czifile.CziFile(czi_in) as czi_f:\n",
    "        proc_axes, proc_shape = get_czi_shape_info(czi_f)\n",
    "        channels = proc_shape['C']\n",
    "        depths = proc_shape['Z']\n",
    "        times = proc_shape['T']\n",
    "        x,y = proc_shape['X'], proc_shape['Y']\n",
    "        data = czi_f.asarray()\n",
    "        preds = []\n",
    "        origs = []\n",
    "        img_max = None\n",
    "        for t in progress_bar(list(range(times))):\n",
    "            idx = build_index(proc_axes, {'T': t, 'C': 0, 'Z':0, 'X':slice(0,x),'Y':slice(0,y)})\n",
    "            img = data[idx].astype(np.float32)\n",
    "            if img_max is None: img_max = img.max() * 1.0\n",
    "            img /= img_max\n",
    "            out_img = image_from_tiles(learn, img, tile_sz=size).permute([1,2,0])\n",
    "            pred = (out_img[None]*255).cpu().numpy().astype(np.uint8)\n",
    "            preds.append(pred)\n",
    "            orig = (img[None]*255).astype(np.uint8)\n",
    "            origs.append(orig)\n",
    "\n",
    "        all_y = np.concatenate(preds)\n",
    "        #print(all_y.shape)\n",
    "        imageio.mimwrite(pred_out, all_y) #, fps=30, macro_block_size=None) # for mp4\n",
    "        all_y = np.concatenate(origs)\n",
    "        #print(all_y.shape)\n",
    "        imageio.mimwrite(orig_out, all_y) #, fps=30, macro_block_size=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=1\n",
    "size=1024\n",
    "scale = 4\n",
    "\n",
    "data = get_data(bs, size, tile_size=128)\n",
    "\n",
    "arch = models.resnet18\n",
    "wd = 1e-3\n",
    "learn = unet_learner(data, arch, wd=wd, loss_func=feat_loss, \n",
    "                     metrics=superres_metrics, callback_fns=LossMetrics, \n",
    "                     blur=True, blur_final=True, norm_type=NormType.Weight, \n",
    "                     self_attention=True, last_cross=True, bottle=True,\n",
    "                     #y_range=(0.,1.),\n",
    "                     model_dir=model_path)\n",
    "gc.collect()\n",
    "learn = learn.load(f'{nb_name}.5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.export(model_path/'paired_001_unet.8.pkl')\n",
    "#learn = load_learner(model_path, 'paired_001_unet.8.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in movie_files:\n",
    "    pred_name = f'{fn.stem}_pred.tif'\n",
    "    orig_name = f'{fn.stem}_orig.tif'\n",
    "    czi_predict_movie(learn, fn, size=size, orig_out=orig_name, pred_out=pred_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.pred_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.util as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.img_as_ubyte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_ssim.ssim??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
