{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai import *          # Quick access to most common functionality\n",
    "from fastai.vision import *   # Quick access to computer vision functionality\n",
    "from fastai.layers import Lambda\n",
    "from fastai.callbacks import *\n",
    "import pytorch_ssim as ssim\n",
    "from superres import *\n",
    "from torchvision.models import vgg16_bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/DATA/WAMRI/salk/uri/Image_restoration_data/')\n",
    "train_lr = path/'train_LR'\n",
    "train_hr = path/'train_HR'\n",
    "test_lr = path/'test_LR'\n",
    "test_hr = path/'test_HR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_id(fn):\n",
    "    return fn.split('#')[-1].split('.')[0]\n",
    "\n",
    "def match_hr_fn(x):\n",
    "    return hr_names_by_id[pull_id(x.name)]\n",
    "\n",
    "lr_names_full = list(train_lr.glob('*.tif'))\n",
    "lr_names_full.sort()\n",
    "hr_names_by_id = {pull_id(hrfn.name):hrfn for hrfn in train_hr.glob('*.tif')}\n",
    "test_label = list(hr_names_by_id.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = (GrayImageItemList\n",
    "       .from_folder(train_lr, '*.tif', label_class=GrayImageItemList)\n",
    "       .split_by_valid_func(lambda x: x.stem[-3] == '0')\n",
    "       .label_from_func(match_hr_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    n,c,h,w = x.size()\n",
    "    x = x.view(n, c, -1)\n",
    "    return (x @ x.transpose(1,2))/(c*h*w)\n",
    "\n",
    "base_loss = F.l1_loss\n",
    "vgg_m = vgg16_bn(True).features.cuda().eval()\n",
    "requires_grad(vgg_m, False)\n",
    "blocks = [i-1 for i,o in enumerate(children(vgg_m)) if isinstance(o,nn.MaxPool2d)]\n",
    "blocks, [vgg_m[i] for i in blocks]\n",
    "\n",
    "class FeatureLoss(nn.Module):\n",
    "    def __init__(self, m_feat, layer_ids, layer_wgts):\n",
    "        super().__init__()\n",
    "        self.m_feat = m_feat\n",
    "        self.loss_features = [self.m_feat[i] for i in layer_ids]\n",
    "        self.wgts = layer_wgts\n",
    "        self.metric_names = (['pixel',] + \n",
    "                             [f'feat_{i}' for i in range(len(layer_ids))] + \n",
    "                             [f'gram_{i}' for i in range(len(layer_ids))])\n",
    "\n",
    "    def make_features(self, hooks, x, clone=False):\n",
    "        self.m_feat(x.repeat([1,3,1,1]))\n",
    "        return [(o.clone() if clone else o) for o in hooks.stored]\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        hooks = hook_outputs(self.loss_features, detach=False)\n",
    "        out_feat = self.make_features(hooks, target, clone=True)\n",
    "        in_feat = self.make_features(hooks, input)\n",
    "        hooks.remove()\n",
    "        \n",
    "        self.feat_losses = [F.mse_loss(input,target)]\n",
    "        self.feat_losses += [base_loss(f_in, f_out)*w\n",
    "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
    "        self.feat_losses += [base_loss(gram_matrix(f_in), gram_matrix(f_out))*w**2 * 5e3\n",
    "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
    "        self.metrics = dict(zip(self.metric_names, self.feat_losses))\n",
    "        return sum(self.feat_losses)\n",
    "\n",
    "feat_loss = FeatureLoss(vgg_m, blocks[2:5], [5,15,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale=4\n",
    "n_resblocks=16\n",
    "n_feats=128\n",
    "res_scale= 1.\n",
    "model = WDSR(scale, n_resblocks, n_feats, res_scale, n_colors_in=1)\n",
    "model = nn.DataParallel(model) #.eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz_lr = 72\n",
    "scale,bs = 4,24\n",
    "sz_hr = sz_lr*scale\n",
    "loss = combo_edge_mse\n",
    "#loss=feat_proj_loss\n",
    "#loss=combo2\n",
    "loss = feat_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn = build_learner(model, bs, sz_lr, sz_hr, src, loss=loss, callback_fns=LossMetrics)\n",
    "# learn.lr_find()\n",
    "# learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs, lr = 10, 2e-4\n",
    "learn = batch_learn(model, bs, sz_lr, sz_hr, lr, epochs, src, save='wdsr_1.0', loss=loss, callback_fns=[LossMetrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(learn.model.module, \"wdsr_model_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load: wdsr_1.0_best\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='30', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      3.33% [1/30 01:08<33:15]\n",
       "    </div>\n",
       "    \n",
       "<table style='width:450px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>mse_loss</th>\n",
       "    <th>ssim</th>\n",
       "    <th>psnr</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.996772</th>\n",
       "    <th>0.882731</th>\n",
       "    <th>0.009071</th>\n",
       "    <th>0.692020</th>\n",
       "    <th>20.427378</th>\n",
       "  </tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='29' class='' max='56', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      51.79% [29/56 00:31<00:29 0.9784]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sz_lr = 128\n",
    "scale,bs = 4,8\n",
    "sz_hr = sz_lr*scale\n",
    "epochs, lr = 30, 1e-4\n",
    "learn = batch_learn(model, bs, sz_lr, sz_hr, lr, epochs, src, load='wdsr_1.0_best', save='wdsr_1.1', loss=loss, callback_fns=[LossMetrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load('wdsr_1.1')\n",
    "torch.save(learn.model.module,'wdsr_model_1.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz_lr = 256\n",
    "scale,bs = 4,4\n",
    "sz_hr = sz_lr*scale\n",
    "epochs, lr = 50, 1e-3\n",
    "learn = batch_learn(model, bs, sz_lr, sz_hr, lr, epochs, src, load='wdsr_1.1', save='wdsr_1.2', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load('wdsr_1.2')\n",
    "torch.save(learn.model.module,'wdsr_model_1.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz_lr = 256\n",
    "scale,bs = 4,4\n",
    "sz_hr = sz_lr*scale\n",
    "epochs, lr = 50, 1e-4\n",
    "learn = batch_learn(model, bs, sz_lr, sz_hr, lr, epochs, src, load='wdsr_1.2', save='wdsr_1.3', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load('wdsr_1.3')\n",
    "torch.save(learn.model.module,'wdsr_model_1.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load('wdsr_1.3_best')\n",
    "torch.save(learn.model.module,'wdsr_model_1.3_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load('wdsr_1.3_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz_lr = 506\n",
    "scale,bs = 4,1\n",
    "sz_hr = sz_lr*scale\n",
    "data = get_data(src, bs, sz_lr, sz_hr)\n",
    "learn = Learner(data, model, loss_func=F.mse_loss)\n",
    "preds, ys = learn.get_preds(DatasetType.Valid)\n",
    "preds = torch.clamp(preds, 0.,1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 9\n",
    "ys[idx].std(), preds[idx].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[idx].min(),preds[idx].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr = Image(ys[idx])\n",
    "hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = Image(preds[idx])\n",
    "sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = learn.data.valid_ds[idx][0]\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim.ssim(sr.data[None],hr.data[None]), psnr(sr.data[None],hr.data[None]), F.mse_loss(sr.data[None],hr.data[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('wdsr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load('wdsr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_tfm, val_tfm = get_transforms()\n",
    "test_bs = 2\n",
    "test_sz = 512 \n",
    "test_out_sz = 4*test_sz\n",
    "test_data = get_data(src, test_bs, test_sz, test_out_sz, test_folder=path/'newimg')\n",
    "test_learn = Learner(test_data, model, loss_func=F.mse_loss).load('wdsr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds, ys = test_learn.get_preds(DatasetType.Test)\n",
    "test_preds = torch.clamp(test_preds, 0.,1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_imgs = []\n",
    "for idx in range(test_preds.shape[0]):\n",
    "    img = Image(test_preds[idx])\n",
    "    sr_imgs.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_imgs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_learn.save('wdsr_keep_edge3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_learn.save('wdsr_keep_edge3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
